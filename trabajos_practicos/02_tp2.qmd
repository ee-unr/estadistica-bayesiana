---
title: "TP2: El Dibu de la vida"
practica: "Trabajo Práctico 2"
---

```{r}
#| echo: false
#| include: false
library(dplyr)
library(ggplot2)
library(patchwork)

colores <- c("#644296","#F08533", "#3B78B0", "#D1352C")

semilla <- strsplit("metropolis hastings", "")[[1]] |>
    match(c(letters), nomatch = 0) |>
    sum()

set.seed(semilla)
```

## Introducción

El ozono (O₃) es un gas cuya molécula está formada por tres átomos de oxígeno y se encuentra tanto
en la atmósfera como en la superficie terrestre. Seguramente, lo han escuchado nombrar en
relación con la capa de ozono, una región de la estratófera que se encuentra unos 15-30 kilómetros
sobre la superficie terrestre, donde abunda el ozono, y que filtra los rayos ultravioletas del sol.

La capa de ozono permite que exista la vida en la Tierra tal como la conocemos y que una escapada de
verano a la isla no se convierta en un viaje solo de ida. En otras palabras, la capa de ozono es
como un Dibu Martínez de la vida: ataja los rayos ultravioletas que, si lograran pasar, más de una
vida arruinarían.

Pero no todo lo que brilla es oro. A nivel del suelo, el ozono se convierte en un contaminante
atmosférico dañino tanto para la salud humana como para el medio ambiente. Puede deteriorar la
función pulmonar, desencadenar ataques de asma, causar irritación en los ojos, la nariz y la
garganta, e incluso dañar la vegetación. Entonces, ¿todo mal con el ozono?

Quien se planteó esa pregunta fue Brian Tarkington, del _California Primate Research Center_ de la
Universidad de California en Davis. Preocupado por la presencia de ozono en el _smog_ californiano,
decidió llevar a cabo un estudio para evaluar el efecto del ozono en el crecimiento de ratas.
Tomó un grupo de 46 ratas jóvenes y de la misma edad, las pesó, las dividió aleatoriamente en 2
grupos de igual tamaño y las dejó en 2 ambientes distintos, el primero rico en ozono y el segundo
libre del mismo. Luego de 7 días las pesó nuevamente y registró la diferencia entre los pesos.

El archivo `tarkington.csv` contiene, para cada una de las ratas, el diferencial de peso en gramos y
el grupo al que pertenece. Interesa conocer si la exposición prolongada a un ambiente contaminado
con ozono se asocia a un deterioro en el desarrollo de las ratas, es decir, a un menor incremento de
peso.

## Modelización estadística

La estadística ofrece una amplia variedad de técnicas para dar respuesta a la inquietud de
Tarkington. En el contexto de esta materia, naturalmente, abordaremos el problema mediante el uso
modelos bayesianos.

Y dado que el entusiasmo en esta materia es lo que sobra, aprovecharemos la oportunidad para
utilizar no uno, sino dos modelos, sutilmente distintos. Esto nos permitirá no solo evaluar el
efecto del ozono en el crecimiento de las ratas, sino también profundizar en esos pequeños
detalles que hacen que la inferencia estadística sea tan interesante.

### Modelo normal

El primer modelo que proponemos es el clásico caballito de batalla de innumerables análisis
estadísticos: el viejo y confiable modelo normal. Aquí, el cambio en el peso de las ratas en cada
grupo se modela mediante una distribución normal, permitiendo medias y varianzas específicas para
cada grupo.

$$
\begin{aligned}
Y_{O, i} &\sim \text{Normal}(\mu_O, \sigma_O^2) & i = 1, \dots, N_O \\
Y_{C, j} &\sim \text{Normal}(\mu_C, \sigma_C^2) & j = 1, \dots, N_C \\
\mu_O, \mu_C &\sim \text{Normal}(0, 5^2) \\
\sigma_O, \sigma_C & \sim \text{Gamma}(\alpha=6, \beta=2)
\end{aligned}
$$
donde $Y_{O, i}$ representa el cambio en el peso de la $i$-ésima rata en el grupo expuesto al
ozono e $Y_{C, j}$ representa el cambio en el peso de la $j$-ésima rata en el grupo control.

### Modelo T de Student

El segundo modelo se parece demasiado al primero. La única —y, en principio, sutil— diferencia es
que, en lugar de modelar la variable respuesta en cada grupo con una distribución normal,
utilizamos una T de Student con 3 grados de libertad.

$$
\begin{aligned}
Y_{O, i} &\sim \text{Student-T}(\mu_O, \sigma_O^2, \nu=3) & i = 1, \dots, N_O \\
Y_{C, i} &\sim \text{Student-T}(\mu_C, \sigma_C^2, \nu=3) & j = 1, \dots, N_C \\
\mu_O, \mu_C &\sim \text{Normal}(0, 5^2) \\
\sigma_O, \sigma_C & \sim \text{Gamma}(\alpha=6, \beta=2)
\end{aligned}
$$

## Un _deep dive_ bien profundo en Metropolis-Hastings

Además de brindarle una respuesta al de pobre Brian Tarkington, que hace décadas que espera que
alguien le ayude a resolver su problema, otro objetivo de este trabajo práctico es profundizar en el
uso de Metropolis-Hastings (MH) como algoritmo para hacer inferencia bayesiana.

El algoritmo de Metropolis-Hastings permite generar muestras (pseudo-)aleatorias a partir de una
distribución de probabilidad $P$ que no necesariamente pertence a una familia de distribuciones
conocida. El único requisito es que se pueda evaluar la función de densidad (o de masa de
probabilidad) $p^*(\boldsymbol{\theta})$ en cualquier valor de $\boldsymbol{\theta}$,
incluso cuando $p^*(\boldsymbol{\theta})$ sea impropia (es decir, incluso aunque sea desconocida la
constante de normalización que hace que la integral en el soporte de la función sea igual a uno).


::: {.callout-tip}
## Algoritmo de Metropolis-Hastings

Se desea generar una muestra de valores $\{y^{(1)}, y^{(2)}, \cdots, y^{(n)} \}$ a partir
de una distribución de probabilidad $P$ con función de densidad $p$.

1. Seleccionar un punto inicial $y^{(1)}$.

1. Para cada $t\in \{1, \cdots, n\}$, repetir:

  i.  **Realizar propuesta**  
    Obtener un valor aleatorio $y'$ de una variable $Y'$ cuya distribución está
    dada por la distribución de propuesta $Q$, centrada en el valor de la última muestra obtenida:
    $$
    Y' \sim Q(y^{(t)})
    $$

  i.  **Calcular la probabilidad de aceptación**  
    Calcular el cociente entre la función de densidad en el punto propuesto y en el punto
    actual, ponderando por la densidad de la distribución de propuesta. La probabilidad de
    aceptación es igual a este cociente si es menor a 1, caso contrario es igual a 1.
    $$
    \alpha = \min \left\{ 1, \frac{p(y')q(y^{(t)} \mid y')}{p(y)q(y' \mid y^{(t)})} \right\}
    $$

  i.  **Seleccionar el nuevo valor**  
    Generar un valor aleatorio $u$ de una distribución $\mathcal{U}(0, 1)$ y determinar
    $y^{(t + 1)}$ de la siguiente manera:
    $$
    y^{(t + 1)} = \left\{
    \begin{array}{ll}
    y' & \text{si} \quad u \le \alpha \\
    y^{(t)} & \text{si} \quad u > \alpha
    \end{array}\right.
    $$
:::

### Metropolis-Hastings en espacios paramétricos acotados

La distribución normal suele ser una elección conveniente a la hora de proponer saltos,
pero presenta desventajas cuando el espacio paramétrico es acotado: inevitablemente,
algunas propuestas caerán fuera del dominio y rechazaremos más que de costumbre.

Para abordar este problema, existen dos estrategias principales. Una opción es utilizar
distribuciones cuyo soporte coincida con el espacio objetivo. Sin embargo, encontrar
parametrizaciones basadas en la media para todas ellas no es trivial.

La otra alternativa, más general, consiste en aplicar una transformación de variables para
trabajar en un espacio no acotado, permitiendo así seguir utilizando una distribución de propuesta
normal. Esta estrategia requiere conocer la densidad objetivo en el nuevo espacio, lo que implica
calcular el determinante del jacobiano de la transformación. A su favor, muchas de las
transformaciones más utilizadas permiten un cálculo sencillo, y este proceso puede automatizarse 
con herramientas de diferenciación automática existentes.

::: {.callout-tip}
## Transformación de variables aleatorias

Sean $X$ e $Y = g(X)$ variables aleatorias continuas, donde $g$ es una función uno a uno
y $X$ tiene función de densidad $f_X(x)$ conocida. Luego, la función de densidad de $Y$ es:
$$
f_Y(y) = f_X(g^{-1}(y)) \left\lvert \frac{d}{dy}g^{-1}(y) \right\rvert
$$

donde $\left\lvert \frac{d}{dy}g^{-1}(y) \right\rvert$ es el determinante del jacobiano de la
transformación. Por ejemplo, en el caso de la función $g(x) = \text{logit}(x)$, se tiene:
$$
\begin{aligned}
g : (0, 1) \to \mathbb{R} & = \text{logit}(x) = \log\left(\frac{x}{1 - x}\right) \\
g^{-1} : \mathbb{R} \to (0, 1) &= \text{expit}(x) =  \frac{1}{1 + \exp(-x)}
\end{aligned}
$$

y luego:
$$
f_Y(y) = f_X(\text{expit}(y)) \cdot \text{expit}(y) \cdot ( 1 - \text{expit}(y))
$$
:::


### Metropolis-Hastings en escala logarítmica

Sin importar cuán moderna y potente sea nuestra computadora, siempre tendremos que lidiar con el
talón de Aquiles del cálculo computacional: los problemas de subdesbordamiento y sobredesbordamiento
(conocidos como _underflow_ y _overflow_ en inglés). Por ejemplo, si intentamos multiplicar
100 números del orden de `0.0001` en R, la computadora podría interpretar el resultado como 0,
aunque matemáticamente esto no sea cierto.

El _underflow_ es un problema frecuente en el cómputo estadístico. Un caso típico ocurre al evaluar
funciones de verosimilitud, donde se multiplican densidades correspondientes a cada observación.
Dado que estas densidades suelen ser valores muy pequeños, es común enfrentarse a un
subdesbordamiento. Este riesgo aumenta con la cantidad de observaciones y la dimensionalidad de la
distribución objetivo.

El problema se agrava al utilizar algoritmos como Metropolis-Hastings, ya que la densidad objetivo
se evalúa miles de veces en diferentes puntos del espacio paramétrico.
Además, en inferencia bayesiana, esta función suele involucrar la multiplicación de una gran
cantidad de números pequeños, lo que incrementa aún más las chances de que el cómputo resulte
en un _underflow_.

Si nuestro algoritmo de muestreo encuentra un problema de _underflow_, pueden ocurrir dos situaciones:

* Se genera un error que detiene la ejecución del programa.
* Se ignora la propuesta problemática y se realiza una nueva, pero nuestro programa ya no sigue la
cadena de Markov deseada.

Entonces, ¿cómo solucionamos este problema?
La respuesta es sencilla: realizar todos los cálculos en escala logarítmica.

```{r}
metropolis_hastings <- function(logp, x, n, sigma = NULL) {
  # Algortimo de Metropolis Hastings en escala logarítmica
  #
  # Parámetros
  #  ------------------------------------------------------------------------
  # | logp     | Función de densidad objetivo, normalizada o sin normalizar, |
  # |          | en escala logarítmica.                                      |
  # | x        | Posición inicial del algoritmo.                             |
  # | n        | Cantidad de muestras a obtener.                             |
  # | sigma    | Matriz de varianzas y covarianzas para la distribución de   |
  # |          | propuesta. Por defecto, es NULL y usa la matriz identidad.  |
  #  ------------------------------------------------------------------------
  #
  # Salida
  #  ------------------------------------------------------------------------
  # | muestras | Matriz con las muestras obtenidas.                          |
  #  ------------------------------------------------------------------------

  # Obtener dimensionalidad de la distribución objetivo a partir del punto inicial
  p <- length(x)

  # Inicializar matriz donde se guardan las muestras
  muestras <- matrix(NA, nrow = n, ncol = p)

  # Usar matriz diagonal unitaria para la distribución de propuesta cuando no se especifica
  if (is.null(sigma)) {
    sigma <- diag(p)
  }

  # Almacenar el punto inicial en la matriz de muestras
  muestras[1, ] <- x

  for (i in 1:(n - 1)) {
    # Obtener el valor de la muestra actual
    muestra_actual <- muestras[i, ]

    # Proponer un nuevo valor
    muestra_propuesta <- mvtnorm::rmvnorm(1, mean = muestra_actual, sigma = sigma)

    # Evaluar la log densidad en el valor actual y en el propuesto
    logp_propuesta <- logp(muestra_propuesta)
    logp_actual <- logp(muestra_actual)

    # Log densidad al pasar de muestra_propuesta a muestra_actual y viceversa
    # Pregunta: ¿Es necesario este paso?
    logq_actual <- mvtnorm::dmvnorm(muestra_actual, mean = muestra_propuesta, sigma = sigma, log = TRUE)
    logq_propuesta <- mvtnorm::dmvnorm(muestra_propuesta, mean = muestra_actual, sigma = sigma, log = TRUE)

    # Calcular log probabilidad de aceptación
    log_alpha <- (logp_propuesta + logq_actual) - (logp_actual + logq_propuesta)

    # Simular aceptación o rechazo
    log_u <- log(runif(1))

    aceptar <- log_u < log_alpha

    # Determinar siguiente paso en base al criterio de selección
    if (aceptar) {
      muestras[i + 1, ] <- muestra_propuesta
    } else {
      muestras[i + 1, ] <- muestra_actual
    }
  }
  # Convertir 'muestras' a vector si se trata de una distrbución univariada
  if (p == 1) {
    muestras <- as.vector(muestras)
  }

  return(muestras)
}
```

## Ahora sí, a trabajar

**ESCRIBIR BIEN!**

Después de larguísimo preambulo, llega la hora de trabajar.

La función `metropolis_hastings()` es una herramienta poderosa que, en teoría, permite obtener
muestras de cualquier distribución _a posteriori_ que se pueda implementar en R en escala
logarítmica. Pero, ¿de qué sirve tener una herramienta tan potente si no está claro cómo usarla?

Como bien dice el refrán, la práctica hace al maestro.
Y quienes conocen de primera mano la verdad de estas palabras son los pilotos de Fórmula 1.
Por ejemplo, antes de cada Gran Premio, Franco Colapinto corre entre
400 y 500 vueltas en el circuito... ¡pero en un simulador!

De esta manera, en preparación a la aplicación final en este trabajo, nuestro Gran Premio,
vamos a utilizar el algoritmo de Metropolis-Hastings en escala logarítmica,
con transformación de variables, en un escenario más sencilo.

### 1. Precalentamos: ensayos con la distribución Gamma

1. Implementar la función de densidad de $Y = \log(X)$
1. Obtener muestras de $Y$.
1. Transformar muestras $x_i = \exp(y_i)$.

### 2. Me fui mundial: múltiples dimensiones, transformaciones y escala logarítmica

Dado el siguiente modelo:
$$
\begin{aligned}
Y_i & \sim \text{Normal}(\mu, \sigma^2) \\
\mu & \sim \text{Normal}(0, 1^2) \\
\sigma & \sim \text{Gamma}(\alpha=2, \beta=2) \\
\end{aligned}
$$

con $i = 1, \dots, N$.

1. Implemente en R una función que permita calcular la densidad a _posteriori_ en escala
logarítmica. Esta función tendrá `y`, `mu` y `sigma` como parámetros de entrada.
1. Utilice los valores de $y_i$ en el archivo `precalentamiento-mh.txt` para obtener muestras
del _posterior_ de $\boldsymbol{\theta} = \{\mu, \sigma\}$. Utilice dos cadenas de Markov.
Evalúe mezcla y convergencia de manera gráfica.

### 3. Última parada: ¿qué le decimos a Brian?

1. Explorar los datos. ¿Encuentra datos atípicos?
¿Qué consecuencias tendrían en la comparación de los incrementos medios de peso?
1. Comparación de medias. Se quiere saber si la exposición al ozono se asocia a menor ganancia de peso.
Utilice el modelo normal. Luego utilice el modelo basado en la distribución T de Student.
En ambos casos:
  1. Escriba la función de densidad en escala logaritmica.
  1. Obtenga muestras, utilizando 2 cadenas de Markov. Utilice medidsa de diagnóstico numéricas y gráficas
      para determinar la fiabilidad de las muestras obtenidas.
  1. Concluir en términos del problema (que calculen alguna probabilidad).
      ¿Se llega a la misma conclusión con ambos modelos? ¿Por qué?


¿Cuántos parámetros hay que estimar en cada modelo?

Para una media y una varianza dada, ¿en qué se diferencia la distribución normal de la distribución
T de Student?

