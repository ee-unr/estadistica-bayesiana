---
title: "TP2: Metropolis-Hastings [WIP]"
practica: "Trabajo Práctico 2"
---

```{r}
#| echo: false
#| include: false
library(dplyr)
library(ggplot2)
library(patchwork)

colores <- c(
    "#644296",
    "#F08533",
    "#3B78B0",
    "#D1352C"
)

semilla <- strsplit("metropolis hastings", "")[[1]] |>
    match(c(letters), nomatch = 0) |>
    sum()

set.seed(semilla)
```

# Metropolis-Hastings en 1D

El algoritmo de Metropolis-Hastings (MH) permite generar muestras (pseudo-)aleatorias a 
partir de una distribución de probabilidad $P$ que no necesariamente pertence a una 
familia de distribuciones conocida. El único requisito es que se pueda evaluar la función
de densidad (o de masa de probabilidad) $p^*(\theta)$ en cualquier valor de $\theta$,
incluso cuando $p^*(\theta)$ sea impropia (es decir, incluso aunque sea
desconocida la constante de normalización que hace que la integral en el soporte de la 
función sea igual a uno).

<!-- NOTA: No estoy seguro si haría esto -->

1.  Escriba una función que implemente el algoritmo de Metropolis-Hastings para tomar 
    muestras de una distribución de probabilidad unidimensional a partir de su función de 
    densidad. Separe en funciones cada uno de los pasos del procedimiento. 
    Otorgue flexibilidad al algoritmo permitiendo elegir entre un punto de inicio arbitrario
    o al azar y utilizar distribuciones de propuesta de transición arbitrarias 
    (por defecto, se utiliza una distribución normal estándar).

1.  Utilice la función implementada en el punto anterior para obtener muestras de una 
    distribución normal de parámetros $\mu=5$ y $\sigma=3$. 
    ¿Obtiene una representación fiel de la distribución objetivo?

## Metropolis-Hastings en espacios paramétricos acotados

* La distribución normal es conveniente para proponer saltos.
* La distribución normal presenta desventajas cuando el espacio paramétrico es acotado.
  * Se realizarán propuestas que caen fuera del espacio parámetrico.
* Soluciones posibles:
  * Utilizar distribuciones cuyo espacio parámetrico sea acotado e igual al de la distribución objetivo.
    * Dificultad: No es sencillo encontrar parametrizaciones adecuadas en la media para todas ellas.
  * Utilizar transfomación de variables para muestrear en un espacio paramétrico no acotado, lo que permite utilizar siempre la distribución normal.
    * Dificultad: Se necesita la función de densidad objetivo en el nuevo espacio paramétrico, es decir, en el espacio de la variable transformada. 
    Esto implica el cálculo del determinante del jacobiano de la transormación.
    * Ventaja: El procedimiento es sencillo para las transformaciones de variables más utilizadas. 
    Además, este proceso puede ser automatizado mediante sistemas de diferenciación automática (simbólica) existentes.
    * Imágen Homero^3?
  
### Transformación de variables aleatorias

Sean $X$ e $Y = g(X)$ variables aleatorias continuas, donde $g$ es una función uno a uno
y $X$ tiene función de densidad $f_X(x)$. Luego, la función de densidad de $Y$ es:
$$
f_Y(y) = f_X(g^{-1}(y)) \left\lvert \frac{d}{dy}g^{-1}(y) \right\rvert
$$

Por ejemplo, en el caso de la función $g(x) = \log(x)$, se tiene:
$$
\begin{aligned}
g : \mathbb{R}^+ \to \mathbb{R} & = \log(x) \\
g^{-1} : \mathbb{R} \to \mathbb{R}^+ &= \exp(x)
\end{aligned}
$$

y luego:
$$
f_Y(y) = f_X(\exp(y)) \exp(y)
$$

### Transformacion de v.a. Gamma

Sea $X \sim \text{Gamma}(\alpha=2, \beta=2)$ e $Y = \log(X)$. 
Se tiene que:
$$
f_Y = f_X(\exp(y)) \exp(y)
$$

donde $f_X$ es la función de densidad de una variable aleatoria $\text{Gamma}(\alpha=2, \beta=2)$.

La distribución de $Y = log(X)$ puede visualizarse mediante:

* La evaluación de la función de densidad $f_Y$ en una grilla de valores de $y$.
* La transformación de muestras aleatorias: se obtienen muestras de $X$ a las que luego
se les calcula el logaritmo.

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 12
#| fig-height: 5
#| fig-cap: leyenda...

x_grid <- seq(0, 5.5, length.out = 200)
x_pdf <- dgamma(x_grid, shape = 2, rate = 2)

y_grid <- log(x_grid)
y_pdf <- dgamma(exp(y_grid), shape = 2, rate = 2) * exp(y_grid)

p1 <- data.frame(x = x_grid, densidad = x_pdf) |>
  ggplot() +
  geom_line(
    aes(x = x, y = densidad),
    color = "grey30",
    linewidth = 1.5,
  ) +
  labs(x = "X", y = "Densidad") +
  lims(x = c(0, 5.5), y = c(0, 0.8)) +
  theme_bw()

p2 <- data.frame(x = y_grid, densidad = y_pdf) |>
  ggplot() +
  geom_line(
    aes(x = x, y = densidad),
    color = "grey30",
    linewidth = 1.5,
  ) +
  labs(x = "Y = log(X)", y = "Densidad") +
  lims(y = c(0, 0.8)) +
  theme_bw()

p1 | p2
```

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 12
#| fig-height: 5
#| fig-cap: otra leyenda...

x_rvs <- rgamma(5000, shape = 2, rate = 2)
y_rvs <- log(x_rvs)

p1_hist <- ggplot() +
  geom_histogram(
    aes(x = x, y = after_stat(density)),
    bins = 50,
    fill = colores[2],
    color = NA,
    alpha = 0.7,
    data = data.frame(x = x_rvs)
  ) + 
  geom_line(
    aes(x = x, y = densidad),
    color = "grey30",
    size = 1.5,
    data = data.frame(x = x_grid, densidad = x_pdf)
  ) +
  labs(x = "X", y = "Densidad") +
  lims(x = c(0, 5.5), y = c(0, 0.8)) +
  theme_bw()

p2_hist <- ggplot() +
  geom_histogram(
    aes(x = x, y = after_stat(density)),
    bins = 50,
    fill = colores[2],
    color = NA,
    alpha = 0.7,
    data = data.frame(x = y_rvs)
  ) + 
  geom_line(
    aes(x = x, y = densidad),
    color = "grey30",
    size = 1.5,
    data = data.frame(x = y_grid, densidad = y_pdf)
  ) +
  labs(x = "Y = log(X)", y = "Densidad") +
  lims(y = c(0, 0.8)) +
  theme_bw()

p1_hist | p2_hist
```

### Obtención de muestras de v.a. Gamma con Metropolis-Hastings 

1. Implementar la función de densidad de $Y = \log(X)$
1. Obtener muestras de $Y$.
1. Transformar muestras $x_i = \exp(y_i)$.

# Metropolis-Hastings en espacios paramétricos generales

Como veremos en esta sección del trabajo práctico, la verdadera utilidad del algoritmo de
Metropolis-Hastings se aprecia cuando se obtienen muestras de distribuciones en más de 
una dimensión, incluso cuando no se conoce la constante de normalización. 
Paradójicamente, los ejemplos trabajados a continuación también serán los que nos 
permitirán advertir sus limitaciones y motivarán la búsqueda de mejores alternativas.

* Extensión a espacios paramétricos multidimensionales.
* Utilización de transformaciones 
  * Ergo, siempre se muestrea en $\mathbb{R}^p$ y por lo tanto se pueden realizar
  propuestas con una normal multivariada.

## Metropolis-Hastings en escala logarítmica

* Posiblidad de subdesbordamiento (_underflow_)
* Utilización de escala logarítmica para estabilizar y robustecer los cálculos.
* Mostrar implementación multivariada en escala logaritmica, usando normal multivariada como propuesta.

```{r}
metropolis_hastings <- function(logp, x, n, sigma = NULL, mensajes = FALSE) {
  # ------------------------------------------------------------------------ #
  # Algortimo de Metropolis Hastings en escala logaritmica                   #
  #                                                                          #
  # Parámetros                                                               # 
  # ------------------------------------------------------------------------ #  
  # | logp     | Función de densidad objetivo, normalizada o sin normalizar, | 
  # |          | en escala logarítmica.                                      |
  # | x        | Posición inicial del algoritmo.                             |
  # | n        | Cantidad de muestras a obtener.                             |
  # | sigma    | Matriz de varianzas y covarianzas para la distribución de   |
  # |          | propuesta. Por defecto, es NULL y usa la matriz identidad.  |
  # | mensajes | Indica si se imprimen mensajes con información del          |
  # |          | algoritmo en cada paso. Por defecto, es FALSE.              |
  # ------------------------------------------------------------------------ # 
  #                                                                          #
  # Salida                                                                   #
  # ------------------------------------------------------------------------ #
  # | muestras | Matriz con las muestras obtenidas.                          |
  # ------------------------------------------------------------------------ #
  

  # Obtener dimensionalidad de la distribución objetivo a partir del punto inicial
  p <- length(x)

  # Inicializar matriz donde se guardan las muestras
  muestras <- matrix(NA, nrow = n, ncol = p)

  # Usar matriz diagonal unitaria para la distribución de propuesta cuando no se especifica
  if (is.null(sigma)) {
    sigma <- diag(p)
  }

  # Almacenar el punto inicial en la matriz de muestras
  muestras[1, ] <- x

  for (i in 1:(n - 1)) {
    # Obtener el valor de la muestra actual
    muestra_actual <- muestras[i, ]

    # Proponer un nuevo valor
    muestra_propuesta <- mvtnorm::rmvnorm(1, mean = muestra_actual, sigma = sigma)

    # Evaluar la log densidad en el valor actual y en el propuesto
    logp_propuesta <- logp(muestra_propuesta)
    logp_actual <- logp(muestra_actual)

    # Log densidad al pasar de muestra_propuesta a muestra_actual y viceversa
    # Pregunta: ¿Es necesario este paso?
    logq_actual <- mvtnorm::dmvnorm(muestra_actual, mean = muestra_propuesta, sigma = sigma, log = TRUE)
    logq_propuesta <- mvtnorm::dmvnorm(muestra_propuesta, mean = muestra_actual, sigma = sigma, log = TRUE)

    # Calcular log probabilidad de aceptación
    log_alpha <- (logp_propuesta + logq_actual) - (logp_actual + logq_propuesta)

    # Simular aceptación o rechazo
    log_u <- log(runif(1))

    aceptar <- log_u < log_alpha

    if (mensajes) {
      estado <- if (aceptar) "ACEPTAR" else "RECHAZAR"
      log_step_info(i, estado, logp_actual, logp_propuesta, logq_actual, logq_propuesta, log_alpha, log_u)
    }

    # Determinar siguiente paso en base al criterio de selección
    if (aceptar) {
      muestras[i + 1, ] <- muestra_propuesta
    } else {
      muestras[i + 1, ] <- muestra_actual
    }
  }
  # Devolver un vector si se trata de una distrbución univariada
  if (p == 1) {
    muestras <- as.vector(muestras)
  }
  return(muestras)
}

# Función auxiliar
log_step_info <- function(
  i, estado, logp_actual, logp_propuesta, logq_actual, logq_propuesta, log_alpha, log_u
) {
  cat(
    "Paso", i, estado,
    "\n---------------\n",
    "  logp actual:", logp_actual, "\n",
    "  logp propuesta:", logp_propuesta, "\n",
    "  logq actual:", logq_actual, "\n",
    "  logq propuesta:", logq_propuesta, "\n",
    "  log_alpha", log_alpha, "\n",
    "  log_u", log_u, "\n"
  )
}
```

## Precalentamiento

Para toda batalla que uno enfrente en la vida, ya sea literal o figurada, es importante
estar bien preparados. Por ejemplo, un montañista necesita entre seis meses y dos años de 
preparación antes de intentar subir el Aconcagua; Rocky Balboa se entrenó durante aproximadamente
cuatro meses en una cabaña en Siberia para enfrentar a Iván Drago y vengar la muerte de Apollo; 
y también son cuatro los duros meses que suele necesitar un estudiante para aprobar Estadística Bayesiana.

Motivados por los ejemplos mencionados, y en preparación a nuestro desafío final, 
primero aplicaremos el algoritmo de Metropolis-Hastings en escala logarítmica,
con transformación de variables, en un escenario más sencillo que el que supone la resolución
de un problema verdadero y con datos de del mundo real.

Sea el siguiente modelo:
$$
\begin{aligned}
Y_i & \sim \text{Normal}(\mu, \sigma^2) \\
\mu & \sim \text{Normal}(0, 1^2) \\
\sigma & \sim \text{Gamma}(\alpha=2, \beta=2) \\
\end{aligned}
$$

con $i = 1, \dots, N$.

  1. Implemente en R una función que permita calcular la densidad a _posteriori_ en escala 
  logarítmica. Esta función tendrá `y`, `mu` y `sigma` como parámetros de entrada.
  1. Utilice los valores de $y_i$ en el archivo `precalentamiento-mh.csv` para obtener muestras 
  del _posterior_ de $\boldsymbol{\theta} = \{\mu, \sigma\}$. Utilice dos cadenas de Markov.
  Evalúe mezcla y convergencia de manera gráfica.

## Aplicación: Ozono, te quiero (no tan) cerca.

El ozono (O₃) es un gas cuya molécula está formada por tres átomos de oxígeno y se encuentra
tanto en la atmósfera como en la superficie terrestre.

Seguramente, lo han escuchado en relación con la capa de ozono, 
una región de la estratófera que se encuentra unos 15-30 kilómetros sobre la superficie terrestre,
donde abunda el ozono, y que filtra los rayos ultravioletas del sol. 

Esta capa permite que exista la vida tal como la conocemos y que una escapada a la isla
no se convierta en un viaje solo de ida. 
En otras palabras, la capa de ozono es como un Dibu Martinez de la vida, 
atajando rayos ultravioletas que, de pasar, tan tristes nos harían.

Pero no todo lo que brilla es oro. A nivel del suelo, el ozono es un contaminante atmosférico, 
es perjudicial para la salud humana y ambiental. 
Puede deteriorar la función pulmonar, generar ataques de asma, irritación ocular, nasal y de garganta, 
y dañar la vegetación.

En ese sentido, los científicos Doksum and Sievers (FALTAN NOMBRES) llevaron a cabo un estudio
para evaluar el efecto del ozono en el incremento de peso en ratas. Tomaron un grupo de
46 ratas de la misma edad, las pesaron, las dividieron aleatoriamente en 2 grupos de igual tamaño y las dejaron
en dos ambientes disintos, el primero rico en ozono y el segundo libre de ozono. 
Luego de 7 días pesaron a las ratas nuevamente. 

El archivo X contiene la ganancia de peso, en gramos, para cada una de las ratas, y el grupo
al que pertenecen.

1.  Explorar los datos. ¿Encuentra datos atípicos?
1.  Comparación de medias. Se quiere saber si la exposición al ozono se asocia a menor ganancia de peso.
    Utilice el modelo normal. Luego utilice el modelo basado en la distribución T de Student.
    En ambos casos:

    1. Escriba la función de densidad en escala logaritmica.
    1. Obtenga muestras, utilizando 2 cadenas de Markov. Utilice medidsa de diagnóstico numéricas y gráficas
    para determinar la fiabilidad de las muestras obtenidas.
    1. Concluir en términos del problema (que calculen alguna probabilidad). 
    ¿Se llega a la misma conclusión con ambos modelos? ¿Por qué?

### Modelo normal

$$
\begin{aligned}
Y_{O, i} &\sim \text{Normal}(\mu_O, \sigma_O^2) \\
Y_{C, i} &\sim \text{Normal}(\mu_C, \sigma_C^2) \\
\mu_O, \mu_C &\sim \text{Normal}(0, 5^2) \\
\sigma_O, \sigma_C & \sim \text{Gamma}(\alpha=6, \beta=2)
\end{aligned}
$$


### Modelo robusto

$$
\begin{aligned}
Y_{O, i} &\sim \text{Student-T}(\mu_O, \sigma_O^2, \nu=3) \\
Y_{C, i} &\sim \text{Student-T}(\mu_C, \sigma_C^2, \nu=3) \\
\mu_O, \mu_C &\sim \text{Normal}(0, 5^2) \\
\sigma_O, \sigma_C & \sim \text{Gamma}(\alpha=6, \beta=2)
\end{aligned}
$$
