---
title: "TP2: Implementación del algoritmo de Metropolis-Hastings"
pdf_file: https://github.com/estadisticaunr/estadistica-bayesiana/raw/pdf/trabajos_practicos/02_tp2.pdf
---

::: {.content-visible when-format="html"}
[Descargar PDF](%7B%7B%3C%20meta%20pdf_file%20%3E%7D%7D)
:::

# Metropolis-Hastings en 1D

El algoritmo de Metropolis-Hastings permite obtener muestras de una distribución de probabilidad $f^*(\theta)$, incluso aunque esta sea impropia (es decir, incluso aunque sea desconocida la constante de normalización que hace que la integral en el soporte de la función sea nula). Basta con que podamos evaluar $f^*(\theta)$ en cualquier valor de $\theta$.

1.  Escriba una función que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una función de probabilidad unidimensional dada. Separe en funciones cada una de los pasos del algoritmo. Otorgue flexibilidad al algoritmo permitiendo elegir diferentes distribuciones de propuesta de transición: normal de una varianza dada y beta de una determinada concentración.

2.  Utilizando la función propuesta, obtener 3000 muestras de la distribución dada por

    $$
    g^*(x) = 
    \left\{
    \begin{array}{ll}
    x^4 e^{-x} && \text{si } x\geq0 \\
    0 && \text{si } x<0
    \end{array}
    \right.
    $$

    Compare las cadenas obtenidas al utilizar diversas distribuciones de propuesta de transición: tres normales de varianzas diferentes y tres betas de concentración diferente. Compare utilizando histogramas, funciones de autocorrelación, Elegir como punto inicial...

3.  Utilizando cada una de las seis cadenas anteriores, compute la media de la distribución, los percentiles 5 y 95 , y la esperanza de $\sqrt{X}$ sabiendo que $X$ se distribuye según $g^*(x)$

4.  Estimar el MCSE de los valores de $\mathbb{E}(X)$ para cada una de las seis cadenas anteriores.

5.  Calcular el estadístico de Gelman-Rubin

    <!--# https://bookdown.org/rdpeng/advstatcomp/monitoring-convergence.html -->

6.  Elija la mejor distribución de probabilidad para transiciones que le permita tomar muestras de la función

    $$
    h^*(x) = 
    $$

7.  Considere un experimento binomial a partir del cual se quiere determinar la probabilidad de éxito $\theta$. Se realiza el experimento se obtienen 6 éxitos en 10 intentos. Obtenga la distribución *a posteriori* de $\theta$ y la creencia *a priori* viene dada por

    $$
    p(\theta) = 2\theta\qquad \theta\in[0,1]
    $$

## Metropolis-Hastings en 2D

Se desean tomar muestras de una normal bivariada asimétrica cuya función de densidad viene dada por

$$
f(\mathbf{x}) = 2\ \phi_2(\mathbf{x}\mid\mathbf{0},\mathbf{\Omega})\ \Phi(\mathbf{\alpha}^T\mathbf{x}) \qquad \mathbf{x} \in \mathbb{R}^2
$$siendo $\phi_2(\mathbf{x}\mid\mathbf{0},\mathbf{\Omega})$ la función de densidad de la normal bivariada de media $\mathbf{0}$ y matriz de covarianza $\mathbf{\Omega}$, $\Phi(\mathbf{\alpha}^T\mathbf{x})$ es la función de probabilidad acumulada de la normal estándar $\mathcal{N}(0,1)$ y $\alpha\in\mathbb{R}^2$ es un vector de parámetros.

<!--# http://gregorygundersen.com/blog/2020/12/29/multivariate-skew-normal/ -->

En este caso, se tiene:

$$
\mathbf{\Omega} = \begin{bmatrix}1.5 & 0.6 \\ 0.6 & 1.5 \end{bmatrix}
$$ y

$$
\mathbf{\alpha} = [2\quad 0]
$$

```{r}
#| warning: false
#| cache: true
#| echo: false
#| fig.cap: "Función de densidad de la que se desean obtener muestras"
library(ggplot2)
library(dplyr)
data <- tidyr::crossing(x1 = seq(-3,3,0.1),
                 x2 = seq(-3,3,0.1))

data %>%
  mutate(f = 2*
           purrr::map2_dbl(x1,x2,~mvtnorm::dmvnorm(c(.x,.y),c(0,0),sigma=matrix(c(1.5,0.6,0.6,1.5),nrow = 2)))*
           pnorm(x1*2+x2*0)) %>%
  ggplot() + 
  geom_raster(aes(x=x1,y=x2,fill=f)) +
  stat_contour(aes(x=x1,y=x2,z=f), col="white") +
  viridis::scale_fill_viridis()
```

1.  Escriba una función que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una función de probabilidad bivariada dada. Separe en funciones cada una de los pasos del algoritmo. La probabilidad de salto será normal bivariada de matriz de covarianza variable. Otorgue flexibilidad al algoritmo haciendo que reciba como argumento la matriz de covarianza de la probabilidad de transición.

Se utilizará una normal bivariada para proponer un salto en el algoritmo de Metropolis-Hastings. Se explorará el efecto de diferentes distribuciones de probabilidad de salto, en función de diferentes matrices de covarianza $\mathbf{\Sigma}$. Si pensamos en escribir

$$
\mathbf{\Sigma} = \begin{bmatrix} \sigma_1 & 0 \\ 0 & \sigma_2 \end{bmatrix} \begin{bmatrix} 1 & \rho \\ \rho & 1\end{bmatrix}  \begin{bmatrix} \sigma_1 & 0 \\ 0 & \sigma_2 \end{bmatrix}
$$

con $\sigma_i$, la varianza de la componente $i$ y $\rho$ la correlación entre las variables $X_1$ y $X_2$, entonces se deberán ensayar diferentes casos: $\sigma_1=\sigma_2$ y $\rho = 0$, $\sigma_1 > \sigma_2$ y $\rho=0$, $\sigma_1<\sigma_2$ y $\rho =0$, $\sigma_1=\sigma_2$ y $\rho > 0$, $\sigma_1=\sigma_2$ y $\rho < 0$. **TO DO** Hacer gráficos:

2.  Para al menos dos variantes de cada uno de los cinco casos anteriores, comparar las trayectorias seguidas por las cadenas al obtener muestras de $f(x)$.

## Aplicación: ¿tiempo de reacción humano? ¿proponer un prior para sigma y uno para mu?
