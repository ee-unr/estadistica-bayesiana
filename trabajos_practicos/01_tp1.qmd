---
title: "TP1: The Multiarmed Bandit"
practica: "Trabajo Pr√°ctico 1"
---

```{r}
#| echo: false
#| include: false

is_html <- knitr::is_html_output()
options("knitr.graphics.error" = FALSE)
captions <- list()
captions[["slotmachines2"]] <- "Tres maquinitas con diferentes probabilidades de ganar"
```


# Introducci√≥n

La vida nos enfrenta constantemente a decisiones que nos obligan a equilibrar entre la seguridad de lo familiar y la promesa de lo desconocido, un dilema conocido como *"explore vs. exploit"*. Esta dicotom√≠a, se manifiesta en una multitud de escenarios cotidianos. Por ejemplo, consideremos la elecci√≥n de una cafeter√≠a para una merienda. ¬øOptamos por un lugar al que hemos ido muchas veces, conocido por su calidad constante (*'exploit'*), o probamos uno de los nuevos locales que abrieron en Rosario con el furor del caf√© de especialidad que podr√≠a ofrecer una experiencia culinaria incre√≠ble o decepcionante (*'explore'*)? Esta elecci√≥n representa una encrucijada entre lo seguro y lo novedoso, entre el confort de lo familiar y la emoci√≥n de la novedad.

Este dilema tambi√©n se extiende a decisiones m√°s significativas en nuestras vidas, como la elecci√≥n de una carrera, donde *'exploit'* implicar√≠a seguir en un campo donde ya tenemos habilidades y experiencia, mientras que *'explore'* nos llevar√≠a a aventurarnos en un nuevo dominio, potencialmente m√°s gratificante pero tambi√©n m√°s arriesgado. Esta tensi√≥n entre explorar y explotar no es solo una curiosidad te√≥rica; es un principio fundamental que gu√≠a nuestras decisiones diarias. Navegar entre estas dos opciones requiere una comprensi√≥n profunda de nuestras metas, recursos y el entorno en el que operamos, y es una habilidad esencial para la adaptaci√≥n y el √©xito en un mundo en constante cambio.

Estos p√°rrafos de *coaching emocional* sirven como la introducci√≥n a este trabajo pr√°ctico, donde estudiaremos el problema del _multi-armed bandit_, que pone √©nfasis en el dilema *"explore vs. exploit"*. La traducci√≥n de _multi-armed bandit_ es bandido multibrazo por lo que, por motivos obvios, nos quedaremos con la expresi√≥n en ingl√©s.

# El _multi-armed bandit_

El _multi-armed bandit_ nos enfrenta a tres m√°quinas tragamonedas, tragaperras (si es por usar traducciones poco felices) o simplemente maquinitas (como les decimos en Rosario). El juego de las maquinitas consiste en hacer girar sus rodillos (anal√≥gicos o digitales) con el objetivo de obtener una combinaci√≥n de s√≠mbolos ganadora y obtener un premio monetario üí∞ (¬°a esto s√≠ que se le puede llamar √©xito!).

```{r}
#| echo: false
#| out-width: 70%
#| fig-align: center
#| fig-cap: !expr captions[["slotmachines2"]]
if (is_html) knitr::include_graphics(file.path("imgs", "slotmachines2.png"))
```

Cada m√°quina tiene una probabilidad de √©xito desconocida y potencialmente diferente, es decir, una probabilidad distinta de entregar un premio. El desaf√≠o consiste en decidir a cu√°l m√°quina dedicar nuestras tiradas con el objetivo de maximizar las ganancias totales. Aqu√≠ es donde entra el dilema: ¬øconviene _"explotar"_ la m√°quina que hasta ahora ha dado mejores resultados, o _"explorar"_ otras m√°quinas que podr√≠an tener una tasa de √©xito mayor pero a√∫n desconocida?

En la fase inicial, cuando se sabe poco sobre las m√°quinas, podr√≠a ser m√°s prudente _"explorar"_, probando cada m√°quina varias veces para obtener una estimaci√≥n aproximada de sus probabilidades de √©xito. A medida que se acumulan datos sobre el rendimiento de cada m√°quina, la estrategia podr√≠a cambiar a _"explotar"_ la m√°quina que ha demostrado ser la m√°s rentable. Sin embargo, siempre existe la incertidumbre y la posibilidad de que una de las m√°quinas menos utilizadas tenga en realidad una tasa de √©xito mayor. Este problema se complica a√∫n m√°s por el hecho de que cada elecci√≥n de m√°quina proporciona informaci√≥n que podr√≠a alterar nuestra comprensi√≥n de cu√°l es la mejor opci√≥n. La soluci√≥n √≥ptima a este problema involucra un equilibrio cuidadoso entre explorar para ganar informaci√≥n y explotar esa informaci√≥n para maximizar las ganancias.

En este trabajo pr√°ctico consideraremos la situaci√≥n simplificada e imaginaria en la que no cuesta dinero jugar con una m√°quina. Es decir, si obtenemos una combinaci√≥n ganadora, sumamos una unidad monetaria ü§ë, pero si no, no perdemos nada. Supondremos, adem√°s, un escenario ficticio en que el deseo por descubrir cual es la m√°quina ganadora nos tendr√° jugando los 366 d√≠as del a√±o 2024 üçÄ. Lo que s√≠, cada d√≠a jugaremos con una sola m√°quina üé∞ y volveremos al d√≠a siguiente...

El objetivo del trabajo consiste en evaluar y comparar diferentes estrategias de juego. Se analizar√°n mediante simulaciones diferentes estrategias de exploraci√≥n y explotaci√≥n de la m√°quina. ¬øD√≥nde aparece la inferencia bayesiana? Partiremos de una creencia _a priori_ para la probabilidad de √©xito de cada m√°quina y la iremos actualizando con cada jugada. 

Para el estudio mediante simulaciones, consideraremos que las probabilidades de √©xito de las tres m√°quinas son $\theta_a = 0.30$, $\theta_b = 0.55$ y $\theta_c = 0.45$. Recordemos que estas probabilidades son desconocidas (no podemos basar nuestras estrategias en esos valores, sino en las estimaciones que vamos haciendo de ellos).

1. Simule 1000 repeticiones de una persona que tiene informaci√≥n confidencial y privilegiada y juega 366 d√≠as con la mejor m√°quina. Realice un histograma del dinero acumulado al finalizar el per√≠odo. ¬øCu√°nto se espera que gane en promedio?

# Estrategias 

Utilizando nuestro ingenio e imaginaci√≥n podr√≠amos inventarnos al menos un par de estrategias
que nos ayuden a determinar la m√°quina mas pagadora. Sin embargo, el g√©nero humano ya se 
ha inventado y debatido un sinf√≠n de estrategias y nosotros podemos aportar nuestro 
granito de arena a la discusi√≥n mientras aprendemos estad√≠stica bayesiana y ponemos
a ejercitar nuestras habilidades en `R`, ¬°qu√© ofert√≥n!. 

Por lo tanto, para cada una de las estrategias presentadas debajo:

1.  Construya una funci√≥n en `R` que elija una m√°quina siguiendo el m√©todo indicado, 
    obtenga un resultado (√©xito o fracaso) y actualice la credibilidad sobre los posibles 
    valores de la probabilidad de √©xito correspondiente. 
2.  Utilice esa funci√≥n para simular una secuencia de 366 d√≠as de juego. 
    Registre la evoluci√≥n diaria del dinero acumulado cada d√≠a, la cantidad de veces que 
    se juega en cada m√°quina, y la distribuci√≥n _a posteriori_ de cada probabilidad de 
    √©xito. Muestre gr√°ficamente los resultados.
3.  Simule 1000 secuencias de 366 d√≠as de juego y analice los resultado
4.  ¬øPodr√≠a considerarse bayesiano este m√©todo de elecci√≥n de m√°quina?

Consideraremos, en todos los escenarios, que la creencia _a priori_ para 
$\theta_a$, $\theta_b$ y $\theta_c$ se corresponde con una distribuci√≥n $\mathrm{Beta}(2, 2)$

## Completamente al azar

Esta es la estrategia (o no-estrategia) m√°s elemental: cada d√≠a, jugar con una m√°quina seleccionada al azar con probabilidad uniforme. 

## _Greedy_ con tasa observada

Se elige la m√°quina que tenga la mayor tasa de √©xito observada hasta el momento.

## _Greedy_ con probabilidad _a posteriori_

Se elige la m√°quina que tenga, hasta el momento, mayor probabilidad de √©xito promedio _a posteriori_.

## _$\epsilon$-greedy_ (con tasa observada)

Se selecciona la mejor m√°quina (la de mayor tasa de √©xito observada seg√∫n los datos actuales) con una probabilidad de $1-\epsilon$ y se elige una m√°quina al azar con una probabilidad $\epsilon$. 

## _Softmax_

Dada la tasa observada para cada m√°quina $i$, $\pi_i$, se calcula una probabilidad de elegir cada m√°quina utilizando la funci√≥n _softmax_:

$$
\mathrm{Pr}(i) = \frac{e^{\pi_i/\tau}}{\sum_{j=1}^3 e^{\pi_i/\tau}}
$$

donde $\tau$ es un par√°metro de "temperatura" que controla el grado de exploraci√≥n. Luego, se elige la m√°quina $i$ con probabilidad $\mathrm{Pr}(i)$.

Adem√°s:

i. Implemente la funci√≥n _softmax_ que, dadas tres tasas observadas, devuelva la probabilidad de elegir cada m√°quina. La funci√≥n debe recibir la "temperatura" como argumento.
ii. Explique qu√© funci√≥n cumple el par√°metro de "temperatura" en t√©rminos de explorar versus explotar.

## _Upper-bound_

Se selecciona la m√°quina que tenga el mayor extremo derecho de un intervalo de 
credibilidad (construido a partir de la distribuci√≥n _a posteriori_ de la probabilidad de √©xito).

## _Thompson sampling_

Para seleccionar una m√°quina, se toma una muestra de la distribuci√≥n _a posteriori_ de las probabilidades de √©xito de cada m√°quina y se elige la m√°quina correspondiente a la muestra m√°s grande.