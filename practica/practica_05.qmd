---
title: "Práctica - Unidad 5"
bibliography: ../references.bib
nocite: |
    @Reich2020
pdf_file: https://github.com/estadisticaunr/estadistica-bayesiana/raw/pdf/practica/practica_05.pdf
---

::: {.content-visible when-format="html"}

[Descargar PDF]({{< meta pdf_file >}})

:::

1.  Utilice el conjunto de datos de las elecciones presidenciales de Estados Unidos del año 2016
    que se provee en @Reich2020. Elabore un modelo de regresión lineal bayesiano donde la 
    variable respuesta es la diferencia porcentual entre el porcentaje de votos que obtuvo
    el candidato Republicano en el 2016 versus los que tuvo en el 2012 en cada condado y utilice
    todas las demás variables como predictoras.

    i. Utilice distribuciones a priori normales no informativas. Interprete las distribuciones
    a posteriori marginales de los coeficientes de regresión.
    i. Calcule los residuos $\mathbf{r} = \mathbf{y} - \mathbf{X}\hat{\boldsymbol{\beta}}$ donde
    $\hat{\boldsymbol{\beta}}$ es la media a posteriori del vector de coeficientes de regresión. 
    ¿Puede concluir que los residuos sigan una distribución normal? ¿Qué condados presentan los 
    residuos más grandes y más pequeños? ¿Qué puede indicar sobre estos condados?
    i. To Do: Compartir datos de forma accesible
    <!-- 4.6.3 @Reich2020 sin efectos aleatorios -->

1.  Utilice el conjunto de datos sobre el control de armas en Estados Unidos. Estos datos provienen
    de un estudio transversal. Para el estado $i$, sea $Y_i$ el numero de homicios y $N_i$ el tamaño
    de la población.

    i. Ajuste el modelo $Y_i | \boldsymbol{\beta} \sim \text{Poisson}(N_i\lambda_i)$ donde
    $\text{log}(\lambda_i) = \mathbf{X}_i\boldsymbol{\beta}$. Use distribuciones a priori no 
    informativas y $p = 7$ de las covariables en $\mathbf{X}_i$: el intercepto, los cinco 
    "confounders" $\mathbf{Z}_i$, y el número de leyes relacionadas a armas. 
    Justifique que el _sampler_ ha convergido y explorado suficientemente la distribución a 
    posteriori y resuma la distribución a posteriori de $\boldsymbol{\beta}$.
    i. To Do: No puse los puntos (b) y (c) porque no se si estan dentro del plan
    i. To Do: Ver como presentamos el tema de las variables a incorporar en el modelo

1.  Descargue el conjunto de datos `babynames` en `R` y calcule el log-odds de un bebé llamado
    "Sophia" en cada año luego de 1950.

    ```r
    library(babynames)
    dat <- babynames
    dat <- dat[dat$name == "Sophia" & dat$sex == "F" & dat$year > 1950, ]
    yr <- dat$year
    p <- dat$prop
    t <- dat$year - 1950
    Y <- log(p / (1 - p))
    ```

    Sea $Y_t$ el log-odds muestral en el año $t + 1950$. 
    Ajuste el siguiente modelo auto-regresivo de orden 1:

    $$
    \begin{aligned}
    Y_t   &= \mu_t + \rho(Y_{t - 1} + \mu_{t - 1}) + \varepsilon_t \\
    \mu_t &= \alpha + \beta t \\
    \varepsilon &\underset{iid}{\sim} \text{Normal}(0, \sigma^2) \\
    \alpha, \beta &\sim \text{Normal}(0, 100^2) \\ 
    \rho &\sim \text{Uniforme}(-1, 1) \\ 
    \sigma^2 &\sim \text{InvGamma}(0.1, 0.1)
    \end{aligned}
    $$

    i. Interprete los parámetros del modelo ($\alpha$, $\beta$, $\rho$ y $\sigma^2$)
    i. Ajuste el modelo utilizando `RStan` para $t > 1$. Verifique la convergencia y reporte
    la media a posteriori e intervalos del 95% para los parámetros.
    i. Grafique la distribución predictiva a posteriori para $Y_t$ en el año 2020.
    <!-- @Reich2020 -->

1.  En este ejercicio se llevará a cabo un meta-análisis, es decir, un análisis que combina
    el resultado de varios estudios. Los datos provienen del paquete `rmeta` en `R`.

    ```r
    library(rmeta)
    data(cochrane)
    cochrane
    ```
    ```
              name ev.trt n.trt ev.ctrl n.ctrl
    1     Auckland     36   532      60    538
    2        Block      1    69       5     61
    3        Doran      4    81      11     63
    4        Gamsu     14   131      20    137
    5     Morrison      3    67       7     59
    6 Papageorgiou      1    71       7     75
    7      Tauesch      8    56      10     71
    ```

    Los datos provienen de siete ensayos aleatorizados que evalúan el efecto de 
    la terapia con corticosteroides en la muerte neonatal. 
    Para el ensayo $i \in \{1, \dots, 7 \}$ $Y_{i0}$ representa el número de eventos 
    que ocurren en el grupo de control de tamaño $N_{i0}$ y $Y_{i1}$ representa
    el número de eventos que ocurren en el grupo tratado de tamaño $N_{i1}$.

    i. Ajuste el modelo $Y_{ij} | \theta_j \underset{indep}{\sim} \text{Binomial}(N_{ij}, \theta_j)$
    con $\theta_0, \theta_1 \sim \text{Uniforme}(0, 1)$. ¿Se puede concluir que el tratamiento 
    está asociado a una reducción de la tasa de muerte?
    i. Ajuste el modelo $Y_{ij} | \theta_j \underset{indep}{\sim} \text{Binomial}(N_{ij}, \theta_j)$
    con 
        * $\text{logit}(\theta_{ij}) = \alpha_{ij}$
        * $\boldsymbol{\alpha}_i = (\alpha_{i0}, \alpha_{i1})^T \underset{iid}{\sim} \text{Normal}(\boldsymbol{\mu}, \boldsymbol{\Sigma})$
        * $\boldsymbol{\mu} \sim \text{Normal}(0, 10^2I_2)$
        * $\boldsymbol{\Sigma} \sim \text{InvWishart}(3, I_2)$  
    
        Interprete los resultados indicando si estos sugieren que el tratamiento está asociado a una
        reducción en la tasa de muerte.
    i. Dibuje un DAG para ambos modelos.
    i. Discuta las ventajas y desventajas de ambos modelos.
    i. ¿Cuál modelo es el preferido para estos datos?
    <!-- @Reich2020 -->

1.  Utilice el conjuto de datos `airquality` que viene con el paquete `datasets` que se carga
    automáticamente al crear una sesión de `R`.
    ```r
    head(airquality)
    ```
    ```
      Ozone Solar.R Wind Temp Month Day
    1    41     190  7.4   67     5   1
    2    36     118  8.0   72     5   2
    3    12     149 12.6   74     5   3
    4    18     313 11.5   62     5   4
    5    NA      NA 14.3   56     5   5
    6    28      NA 14.9   66     5   6
    ```
    Compare los siguientes modelos utilizando _5-fold cross-validation_:

    $$
    \begin{array}{l}
    \mathcal{M}_1: \text{Ozone}_i \sim \text{Normal}(\beta_1 + \beta_2 \text{Solar.R}_i, \sigma^2) \\
    \mathcal{M}_2: \text{Ozone}_i \sim \text{Normal}(\beta_1 + \beta_2 \text{Solar.R}_i + \beta_3 \text{Temp}_i + \beta_4 \text{Wind}_i, \sigma^2)
    \end{array}
    $$

    Elija _priors_ para ambos modelos explicando su elección.
    <!-- @Reich2020 -->

1.  Curvas de crecimiento de tiranosáuridos

    Analizaremos datos de 20 fósiles para estimar las curvas de crecimiento de cuatro
    especies: Albertosaurio, Daspletosaurio, Gorgosaurio y Tiranosaurio. 
    Los datos se toman de la Tabla 1 de @Erickson2004 y se muestran en el grafico @fig-dinos
    El objetivo es determinar la curva de crecimiento, esto es, determinar 
    la masa corporal esperada por edad, para todas las especies.

    Se puede observar que hay una relación no lineal entre la edad y el peso, además de 
    ciertos patrones comunes entre las especies. 
    
    Sea $Y_{ij}$ el peso y $X_{ij}$ y la edad de la muestra $i$ de la especie $j$, con 
    $j = 1, 2, 3, 4$. Se propone el siguiente modelo

    $$
    Y_{ij} = f_j(X_{ij})\epsilon_{ij}
    $$

    donde $f_j$ es la verdadera curva de crecimiento para la especie $j$ y $\epsilon_{ij} > 0$ 
    es un error multiplicativo con media uno. Se utiliza un error multiplicativo en vez de
    uno aditivo porque es de esperar que la variabilidad se incremente a medida que se
    el peso o la edad sean mayores. Si se asume una distribución log-normal para el error
    con $\log(\epsilon_{ij}) \sim \text{Normal}(-\sigma_j^2/2, \sigma_j^2)$, luego 
    $\mathbb{E}(\epsilon_{ij}) = 1$ tal como se requiere. El modelo resulta

    $$
    \log Y_{ij} \sim \text{Normal}(\log [f_j(X_{ij})] - \sigma_j^2/2, \sigma_j^2)
    $$
    
    y $\mathbb{E}(Y_{ij}) = f_j(X_{ij})$, donde $\sigma_j^2$ controla la varianza del error para
    la especie $j$.

    El panel izquierdo de @fig-dinos muestra que la relacion entre las variables es no lineal.
    Sin embargo, luego de transformas ambas variables con la transformación logarítmica, la 
    relación se ve aproximadamente lineal. De esta manera, vale la pena considerar el modelo
    siguiente log lineal

    $$
    \log [f_j(X)] = a_j + b_j \log(X)
    $$

    donde $a_j$ y $b_j$ representan al intercepto y pendiente de la especie $j$, respectivamente.
    La curva de crecimiento en la escala original es $f_j(X) = \exp (a_j)X^{b_j}$.
    Si $b_j$ es positivo, como se espera, la curva de crecimiento crece indefinidamente, lo que
    resulta muy poco realista. Luego, se compara el modelo log-lineal con la curva de crecimiento
    logística

    $$
    f_j(X) = a_j + b_j \frac{\exp [d_j (x - c_j)]}{1 + \exp [d_j(x - c_j)]}
    $$

    donde $x = \log(X)$. Este modelo tiene cuatro parámetros:

    1.  $a_j$ es el peso esperado cuando la edad es 0
    1.  $b_j$ es el peso máximo esperado (o la cota superior del peso)
    1.  $\log (c_j)$ es la edad a la que la especie $j$ alcanza la mitad del peso máximo
    1.  $d_j > 0$ determina la tasa de crecimiento del peso conforme aumenta la edad

    Continuar...


    ```{r grafico-tiranosauridos}
    #| warning: false
    #| cache: true
    #| echo: false
    #| fig.cap: "Agregar algo de texto..."
    #| label: fig-dinos

    library(dplyr)
    library(ggplot2)
    library(patchwork)

    data <- readr::read_csv(here::here("datos", "Erickson.csv"))
    data$Escala <- "original"

    data <- data |> 
        bind_rows(
            data |>
                mutate(
                    Age = log(Age), 
                    Mass = log(Mass), 
                    Escala = "log"
                )
        )

    plt_1 <- data |> 
        filter(Escala == "original") |> 
        ggplot(aes(x = Age, y = Mass, color = Taxon)) +
        #geom_smooth(method = "gam", se = FALSE, linewidth = 0.8) + 
        geom_point(aes(shape = Taxon), size = 2) +
        scale_x_continuous(name = "Edad (años)", seq(5, 25, by = 5)) +
        scale_y_continuous(name = "Peso (kilos)", seq(0, 5000, by = 1000)) +
        scale_shape_manual(values = c(15, 16, 17, 18)) +
        guides(
            color = guide_legend(title="Especie"), 
            shape = guide_legend(title="Especie")
        )

    plt_2 <- data |> 
        filter(Escala == "log") |> 
        ggplot(aes(x = Age, y = Mass, color = Taxon)) +
        #geom_smooth(method = "lm", se = FALSE, linewidth = 0.8) + 
        geom_point(aes(shape = Taxon), size = 2) +
        scale_x_continuous(name = "Log Edad (años)", seq(1, 3, by = 0.5)) +
        scale_y_continuous(name = "Log Peso (kilos)", seq(4, 8, by = 1)) +
        scale_shape_manual(values = c(15, 16, 17, 18)) +
        guides(
            color = guide_legend(title="Especie"), 
            shape = guide_legend(title="Especie")
        )
    plt <- (plt_1 | plt_2) + plot_layout(guides = "collect") & theme(legend.position = "top")
    plt
    ```

    i. **Nota:** Vamos a llegar a cubrir modelos no lineales y modelos jerárquicos? 
 
    i. En consecuencia, se decide construir un modelo no-lineal jerárquico.