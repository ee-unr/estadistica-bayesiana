---
title: Práctica - Unidad 3
nocite: "@Martin2021, @Downey2021"
practica: "Práctica 3"
---

```{r}
#| echo: false
#| include: false
library(dplyr)
library(ggplot2)
library(patchwork)
pdf_file <- paste0(
    "https://github.com/estadisticaunr/estadistica-bayesiana/raw/pdf/practica/",
    paste0(sub("\\..*$", "", knitr::current_input()), ".pdf")
)
is_html <- knitr::is_html_output()
options("knitr.graphics.error" = FALSE)
source(here::here("scripts", "utils.R"))
captions <- list()
captions[["monty_hall"]] <- "Las 3 puertas del problema de Monty Hall"
```

::: {.content-visible when-format="html"}
[Descargar PDF](`r pdf_file`)
:::

## Métodos Computacionales

Esta sección contiene una lista exhaustiva de ejercicios que requieren el uso de 
herramientas computacionales para resolver problemas que involucran una variedad de 
cálculos, como el cálculo de probabilidades y el cálculo de integrales. 
Se vuelve indispensable el uso de `R` y se promueve el uso de buenas prácticas de 
programación científica, como el uso de funciones compartimentar los componentes de un 
programa. 

1.  **¡A calcular probabilidades! (I)**

    Sea $X \sim \text{Normal}(\mu=3, \sigma=1.2)$.

    i. Elabore un gráfico que permita visualizar la función de densidad de probabilidad 
    de $X$.
    i. ¿Cuál es la probabilidad de que $X$ sea menor a 2.5?
    i. ¿Cuál es la probabilidad de que $X$ sea mayor a 4?
    i. ¿Cuál es la probabilidad de que $X$ sea mayor 2 y menor 3?

1.  **¡A calcular probabilidades! (II)**

    Sea $X \sim \text{Beta}(\alpha=10, \beta=2)$.

    i. Elabore un gráfico que permita visualizar la función de densidad de probabilidad 
    de $X$.
    i. ¿Cuál es la probabilidad de que $X$ sea menor a 0.5?
    i. ¿Cuál es la probabilidad de que $X$ sea mayor a 0.8?
    i. ¿Cuál es la probabilidad de que $X$ sea mayor 0.25 y menor 0.75?

1.  **Magia blanca: Obtener probabilidades mediante simulación**

    Responda los dos puntos anteriores sin evaluar la función de densidad ni la función
    de distribución de las variables aleatorias mencionadas. Para eso genere muestras
    que provengan de las correspondientes distribuciones y utilícelas para responder las 
    preguntas mencionadas. Reflexione sobre las ventajas y desventajas de utilizar un 
    enfoque basado en la simulación para resolver problemas.

1.  **Media y varianza de una variable aleatoria**

    Una variable aleatoria $X$ toma valores en el conjunto $\{2, 4, 6, 8, 10\}$ con igual
    probabilidad. Encuentre la media y el desvío estándar de las variables $X$ e 
    $Y = 2X + 1$.
    <!-- Tal vez se puede hacer un poco más difícil si hacemos que la función sea no-lineal -->

1.  **Probabilidades _a posteriori_**

    En un problema determinado la distribución _a posteriori_ de la parámetro de inteŕes
    $\alpha$ es $\Gamma(k=3, \theta=1.5)$, donde $k$ es el parámetro de forma y $\theta$ 
    es el parámetro de escala. Calcule la probabilidad de que $\alpha^2$ sea mayor a 10.
    <!-- https://stats.stackexchange.com/questions/154135/square-of-gamma-random-variable -->

1.  **Probabilidades con dos variables aleatorias**

    Sean $X$ e $Y$ dos variables aleatorias independientes con distribución uniforme en el
    intervalo $[0, 1]$. 

    i.  ¿Cuál es la probabilidad de que $X \le Y$?
    i.  Grafique los puntos muestreados coloreando de acuerdo a si la muestra satisface
    el evento antes mencionado o no.

1.  **Te veo en la fotocopiadora**
    
    Dos estudiantes de estadística deciden encontrarse en la fotocopiadora de la Facultad
    entre las 10 y las 11 de la mañana, eligiendo el tiempo de llegada al azar. 
    La estudiante A esperará 10 minutos luego de llegar. Si el estudiante B no llega en
    ese intervalo, se irá. Lo mismo hace el estudiante B, pero este decide esperar
    14 minutos. ¿Cuál es la probabilidad de que se produzca el encuentro en la 
    fotocopiadora entre la estudiante A y el estudiante B?

1.  **Armando celulares en Tierra del Fuego**

    Una máquina que se utiliza para ensamblar teléfonos celulares en una fábrica en 
    Tierra del Fuego cuenta con tres componentes críticos para su funcionamiento. 
    Ante una falla en cualquiera de estos componentes, la máquina se detiene. 
    Las probabilidades de que estos elementos operen correctamente durante un día 
    cualquiera  son $p_1 = 0.8$, $p_2 = 0.9$ y $p_3 = 0.7$. 
    Responda las siguientes preguntas utilizando técnicas de simulación:

    i.  ¿Cuál es la probabilidad de que la máquina falle en el primer día de uso?
    i.  ¿Cuál es la probabilidad de que la máquina siga funcionando luego de 10 días?
    i.  ¿Cuál es la probabilidad de que la máquina falle en el día 7 de uso?
    i.  Sea $T=$ Cantidad de días que la máquina funciona ininterrumpidamente. 
    Grafique la función de densidad de probabilidad de $T$.

1.  **Bolas infinitas**

    [Este tuit](https://twitter.com/pgroisma/status/1616137795180822528) propone un
    problema muy interesante. Una urna contiene una bola azul y una amarilla. 
    Se elije una bola al azar y se la vuelve a colocar junto con otra bola adicional 
    del mismo color. Se repite este proceso indefinidamente. 
    ¿Qué ocurre con la proporción de bolas azules en la urna a medida que 
    repetimos más y más veces?

    i. Tiende a 1/2.
    i. Tiende a 0 ó a 1.
    i. No se estabiliza.
    i. Ninguna de las anteriores.

    Escriba un programa en `R` para responder esta pregunta utilizando simulaciones.
    Genere gráficos que faciliten la comprensión del resultado.
    <!-- https://twitter.com/pgroisma/status/1616820135313932288 -->

1.  **Estimando el valor de** $\pi$

    Imagine un círculo de radio $r$ y un cuadrado de lado $2r$, ambos centrados en el 
    mismo punto, que de manera arbitraria puede ser el punto $(0, 0)$. Obtenga muestras
    de una distribución uniforme en el plano $(x, y)$, cuyo dominio está acotado por 
    el cuadrado antes mencionado. Para cada muestra extraida, determine si se encuentra 
    dentro del círculo o no -- todos las muestras se encontrarán dentro del cuadrado. 
    Utilice esta información para estimar el valor de $\pi$.
    
    ```{r circulo-cuadrado-pi}
    #| warning: false
    #| echo: false
    #| fig-width: 4.5
    #| fig-height: 4.5
    #| fig-align: center
    centro <- c(0, 0)
    radio <- 1
    angulos <- seq(0, 2 * pi, length.out = 512)

    x_circulo <- centro[1] + radio * cos(angulos)
    y_circulo <- centro[2] + radio * sin(angulos)

    x_cuadrado <- c(
        seq(-1, 1, length.out = 128),
        rep(1, 128),
        seq(1, -1, length.out = 128),
        rep(-1, 128)
    )
    y_cuadrado <- c(
        rep(1, 128), 
        seq(1, -1, length.out = 128), 
        rep(-1, 128), 
        seq(-1, 1, length.out = 128)
    )

    x <- c(x_circulo)
    y <- c(y_circulo)
    figura <- rep(c("circulo", "cuadrado"), each = 512)
        
    df <- data.frame(x = x, y = y, figura = figura)
    ggplot(df) + 
        geom_hline(yintercept = 0, linetype = "dashed", color = "#999999") +
        geom_vline(xintercept = 0, linetype = "dashed", color = "#999999") +
        geom_path(aes(x = x, y = y), size = 1.25, color = "#0984C0") +
        geom_rect(
            xmin = -1, xmax = 1, ymin = -1, ymax = 1, 
            fill = NA, color = "#999999", size = 1.25
        )
    ```

    Algunos datos útiles

    * Area de un círculo: $\pi \cdot r^2$.
    * Area de un cuadrado: $a^2$, donde $a$ es la longitud del lado.

1.  **Los puntos uniformes**

    Se seleccionan dos puntos de manera uniforme e independiente dentro de un círculo. 
    ¿Cuál es la probabilidad de que la distancia entre dos puntos sea menor al radio?

    i.  Resuelva el problema utilizando `R`.
    i.  Elabore una visualización que facilite la comunicación de los resultados.

1.  **Sobre el histórico 7 a 1 del 2014**

    En la Copa del Mundo de la FIFA 2014, Alemania jugó contra Brasil en la semifinal. 
    Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23.
    Asuma que el tiempo entre goles sigue una distribución exponencial. 
    Elija una distribución _a priori_ para el tiempo entre goles (puede ser conjugada o 
    no). En ese momento del partido,

    i. ¿Cuál es la distribución _a posteriori_ del tiempo entre goles de Alemania?
    i. ¿Cuántos goles cabría esperar que Alemania hiciera al finalizar los 90 minutos?
    i. ¿Cuál era la probabilidad de que Alemania hiciera más de 5 goles (cosa que ocurrió)?
    <!-- http://allendowney.github.io/ThinkBayes2/chap08.html -->

1.  **¿Tendré que esperar mucho?**

    El tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene
    distribución exponencial con media 30 minutos. Los tiempos de duración de cada 
    entrevista se pueden considerar independientes entre sí. 
    Las entrevistas a postulantes para un trabajo están programadas cada 15 minutos, 
    comenzando desde las 8. Es válido considerar que todos los postulantes llegan 
    puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina

    i. ¿Cuál es la probabilidad de que tenga que esperar antes de ser entrevistada?
    i. ¿Cuál es el horario esperado al que terminará su entrevista?
    <!-- Modern Data Science with R -->

1.  **¡Qué casualidad!**
    
    Dos personas se conocen en la fila de embarque para un vuelo en un avión Airbus A330-300. Considere que el Airbus A330-300 tiene 30 filas de 2-4-2 asientos.

    i. ¿Cuál es la probabilidad de que tengan asientos en la misma fila?
    i. ¿Cuál es la probabilidad de que estén sentados en asientos adyacentes?

1.  **El Problema de Monty Hall**

    El Problema de Monty Hall es un problema de probabilidad basado en un juego del
    concurso televisivo estadounidense "Trato hecho". 
    En este problema, el concursante debe elegir una puerta entre tres, todas cerradas. 
    El premio consiste en llevarse lo que se encuentra detrás de la elegida. 
    Se sabe con certeza que tras una de ellas se oculta un automóvil, y tras las otras dos 
    hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elección a 
    los presentes, el presentador, que sabe lo que hay detrás de cada puerta, abrirá una de las
    otras dos en la que haya una cabra. A continuación, le da la opción al concursante de 
    cambiar, si lo desea, de puerta (tiene dos opciones). 
    ¿Debe el concursante mantener su elección original o escoger la otra puerta? 
    ¿Hay alguna diferencia? Resuelva este ejercicio utilizando simulaciones.
    <!-- Modern Data Science with R -->

    ```{r}
    #| echo: false
    #| out-width: 70%
    #| fig-align: center
    #| fig-cap: !expr captions[["monty_hall"]]
    if (is_html) knitr::include_graphics(file.path("imgs", "monty_hall.png"))
    ```

1.  **Que los cumplan feliz**

    Basándose en el [siguiente tuit](https://twitter.com/Kit_Yates_Maths/status/1542767039814713346)
    y conociendo el problema del cumpleaños (¿cuántas personas debe
    haber en una habitación para que la probabilidad de que dos de ellas
    cumplan años el mismo día sea mayor a X%?) construir un gráfico
    similar al del tuit donde se grafique la probabilidad de que haya
    $n$ personas que cumplan años el mismo día para $K$ personas
    presentes en la habitación.

1.  **Qué suerte, ¿no?**
    
    Previo a la final de la Copa América 2021, los jugadores de la Selección Argentina se
    reúnen en la habitación del hotel como se describe en 
    [este tuit](https://twitter.com/PlanetaDeCABJ/status/1587925636869300224).

    i. ¿Cuál es la probabilidad de que un jugador adivine una de diez cartas?
    i. ¿Cuál es la probabilidad de que tres de ellos adivinen una de diez cartas?

1.  **El álbum del Campeón**

    El álbum oficial del Mundial de Fútbol de Qatar 2022 consta de 638 figuritas. 
    Cada paquete trae cinco figuritas.

    i. Comprando cinco paquetes, ¿cuál es la probabilidad de tener a Messi?
    i. Comprando cinco paquetes, ¿cuál es la probabilidad de sacar a Messi repetido?
    i. ¿Cuántos paquetes se necesitan, en promedio, para completar el álbum?
    i. Si a una persona le faltan diez figuritas para completar el álbum, 
    ¿cuántos paquetes tiene que comprar para asegurarse de lograrlo?

1.  **¿Que tán raras son estas secuencias raras?**

    Si se arroja una moneda $n$ veces, ¿cuál es la probabilidad de que no haya secuencias 
    de $k$ caras?

1.  **Un viaje por el elevador**

    ¿Cuál es la probabilidad de que tres personas en un ascensor con doce pisos presionen 
    para ir a tres pisos consecutivos? ¿Qué supuestos realiza para resolver el problema?
    Escríbalos en una lista de manera explícita.
   
1.  **La vida es muy corta como para perderla ordenando medias**
    
    Un cajón contiene 10 pares de medias. No hay dos pares iguales. 
    Por fiaca, el dueño de las medias no las agrupa después de lavarlas y simplemente las
    pone en el cajón. Al momento de necesitar un par de medias, saca una tras una hasta 
    que se forma un par. En promedio, ¿cuántas medias sacará hasta encontrar un par?
    <!-- https://fivethirtyeight.com/features/can-you-find-a-matching-pair-of-socks/ -->
    
1.  **¿Vale la pena hacer un ensayo clínico a gran escala?**

    Dados los resultados de un estudio piloto, la probabilidad _a posteriori_ de que la droga
    desarrollada por tu compañía sea mas efectiva que el tratamiento actual es $\theta \in [0, 1]$.
    Tu compañía está considerando realizar un ensayo clínico a gran escala para confirmar que
    la droga que desarrollan es de hecho mejor. El costo del estudio es **\$X**. 
    Si la droga es mejor, la probabilidad de que esto se confirme en el ensayo es del 80%.
    Si la droga no es mejor, hay una probabilidad del 5% de que el estudio confirme que es mejor.
    Si el ensayo sugiere que tu droga es mejor, ganarás **\$cX**. 
    ¿Para qué valores de $\theta$ y $c$ tiene sentido realizar el estudio?
    <!-- @Reich2020 -->

1.  **El problema de concordancia**

    Resuelva el problema de concordancia de de Montmort presentado en la **Práctica 0**
    utilizando simulaciones.
    <!-- Blitzstein, Introdudction to Probability -->

1.  **El problema de los sobres**

    Resuelva el problema de los dos sobres presentado en la **Práctica 0** utilizando 
    simulaciones.

1.  **Integración por muestreo**

    Calcule las siguientes integrales utilizando muestras.

    i. $\displaystyle \int_{-\infty}^{\infty}{\frac{x^2}{\sqrt{2\pi}}\exp \left(-\frac{x^2}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{\infty}{\frac{x^3}{\sqrt{2\pi}}\exp \left(-\frac{x^2}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{\infty}{\frac{x^6}{\sqrt{2\pi}}\exp \left(-\frac{x^2 - 4x}{2} \right)dx}$
    i. $\displaystyle \int_{1}^{10}{x^6\frac{e^{-x^4/2}}{\sqrt{2\pi}}dx}$
    <!-- @Lambert2018 Capitulo 9 -->

1.  ¿Cuál es la distribución de muestreo aproximada al usar muestreo independiente para 
    evaluar integrales?
    <!-- @Lambert2018 Capitulo 9 -->

## Aproximación de una distribución mediante una grilla

En esta parte de la práctica se comienza a utilizar técnicas computacionales que se 
asocian directamente a la práctica de la estadística bayesiana. Los problemas tienen como 
objetivo la familiarización con el uso práctico de estas técnicas y la comprensión de sus 
características principales.

1. **Aproximación de grilla**

    Se tiene un experimento binomial donde $n=80$ y se observan $y=7$ éxitos. 
    Considere que el _prior_ de la probabilidad de éxito $\theta$ es $\text{Beta}(2, 10)$.

    i. Obtenga la distribución _a posteriori_ de $\theta$ de manera analítica y grafíquela.
    i. Obtenga la distribución _a posteriori_ de $\theta$ utilizando el método de la 
    grilla en base a una grilla de 10 puntos y dibuje la curva obtenida en el gráfico 
    creado anteriormente.
    i. Repita el proceso del punto anterior utilizando una grilla de 100 puntos.
    i. Concluya sobre la fidelidad de las aproximaciones. ¿Considera que es necesario
    utilizar una grilla más densa? ¿Cuáles serían las ventajas y desventajas?

1. **Cálculo de probabilidades en base a la grilla (I)**

    En base al _posterior_ obtenido en el ejercicio anterior mediante el método de la 
    grilla calcule las siguientes probabilidades

    * $P(\theta < 0.7)$.
    * $P(\theta > 0.05)$.
    * $P(0.05 < \theta < 0.15)$.

    De ser necesario, obtenga el _posterior_ mediante una grilla de mayor densidad.

1. **Cálculo de probabilidades en base a la grilla (II)**

    Utilice los valores de la grilla y sus probabilidades _a posteriori_ para obtener
    muestras del _posterior_ y calcular las mismas probabilidades que en el ejercicio
    anterior en base a muestras. Ayuda: Para obtener muestras utilice la función `sample()`.

1.  **Aproximación de grilla en 2 dimensiones**

    Sean dos variables aleatorias continuas $X$ e $Y$ tales que $(X, Y) \in \mathbb{R}^2$,
    y sea el siguiente modelo de regresión lineal simple:

    $$
    \begin{aligned}
    \alpha &\sim \text{Normal}(0, 1.5) \\
    \beta  &\sim \text{Normal}(0, 2) \\
    Y      &\sim \text{Normal}(\alpha + \beta X, 0.8)
    \end{aligned}
    $$

    i. Obtenga el _posterior_ conjunto del vector de parámetros $[\alpha, \beta]^T$ 
    mediante el método de la grilla. Elabore un gráfico que permita visualizar esta 
    distribución.
    i. Obtenga el _posterior_ marginal de $\alpha$ y grafíquelo.
    i. Obtenga el _posterior_ marginal de $\beta$ y grafíquelo.
    i. Calcule la probabilidad de que el intercepto sea mayor a 0.5.
    i. Calcule la probabilidad de que la pendiente sea menor a -3.
    
    Para responder las consignas utilice los datos simulados que se obtienen con el 
    siguiente bloque de código:

    ```{r}
    set.seed(121195)
    alpha <- 1
    beta <- -2
    sigma <- 0.8
    n <- 80
    x <- rnorm(n)
    y <- rnorm(n, alpha + beta * x, sigma)
    df <- data.frame(x = x, y = y)
    ```

    **Bonus:** ¿Cómo podría responder las consignas (ii)-(v) utilizando muestras del 
    _posterior_? 

    ```{r scatterplot-lin-reg}
    #| eval: false
    #| warning: false
    #| echo: false
    #| fig.width: 5.5
    #| fig.height: 4.5
    #| fig.align: center
    # Generar gráfico de dispersión para ver los datos
    plt <- ggplot(df, aes(x = x, y = y)) +
        geom_point(alpha = 0.6, fill = "gray60", size = 2)
    plt
    ```

    ```{r}
    #| eval: false
    #| warning: false
    #| echo: false
    #| fig.width: 5.5
    #| fig.height: 4.5
    #| fig.align: center

    # Esto es una posible solución a la primera parte
    grid_a <- seq(0.5, 1.5, length.out = 50)
    grid_b <- seq(-2.5, -1.5, length.out = 50)
    grid_df <- expand.grid(grid_a, grid_b)

    names(grid_df) <- c("a", "b")
    likelihood <- numeric(nrow(grid_df))
    posterior <- numeric(nrow(grid_df))

    # No se que problema hay si lo hago con `mutate()` que todo queda en 0.
    for (i in seq_along(likelihood)) {
        likelihood[i] <- prod(dnorm(y, grid_df$a[i] + grid_df$b[i] * x, sigma))
    }
    posterior <- (
        likelihood 
        * dnorm(grid_df$a, mean = 0, sd = 1.5) # alpha ~ Normal(0, 1.5)
        * dnorm(grid_df$b, mean = 0, sd = 2)   # beta ~ Normal(0, 2)
    )

    grid_df$likelihood <- likelihood
    grid_df$posterior <- posterior

    plt <- ggplot(grid_df, aes(x = a, y = b)) +
        geom_raster(aes(fill = posterior)) +
        stat_contour(aes(z = posterior), col = "white", bins = 5) +
        geom_point(x = alpha, y = beta, color = "black", fill = "red", size = 3, pch = 21) + 
        labs(x = expression(alpha), y = expression(beta)) +
        viridis::scale_fill_viridis() + 
        theme(legend.position = "none")
    plt
    ```

1.  **Escalando la aproximación de la grilla**

    Suponga que se tiene que estimar un _posterior_ utilizando la aproximación mediante
    una grilla de 200 puntos en cada dimensión. Calcule cúantas veces se tiene que evaluar
    el posterior en cada uno de los siguientes escenarios:

    i. 1 dimensión.
    i. 2 dimensiones.
    i. 3 dimensiones.
    i. 5 dimensiones.
    i. 10 dimensiones.

    Concluya sobre las ventajas y desventajas de la aproximación de la grilla teniendo
    en cuenta sus características conforme se incrementa el número de dimensiones del
    _posterior_.

1.  **_Benchmark_ de la aproximación de la grilla**
    
    El siguiente bloque de código define una función llamada `create_and_eval_grid()` 
    que evalúa la función de densidad normal en una cantidad arbitraria dimensiones. 
    El argumento `dimension_n` indica la dimensionalidad de la distribución normal, y 
    `grid_n` indica la cantidad de puntos en la grilla de cada dimensión. Debajo, 
    se utiliza la función `mark()` del paquete `{bench}` para comparar el desempeño de la
    función `create_and_eval_grid()` con diferentes números de dimensiones.

    ```{r}
    #| eval: false
    create_and_eval_grid <- function(dimension_n, grid_n = 100) {
        grid <- seq(-3, 3, length.out = grid_n)
        grids <- replicate(dimension_n, grid, simplify = FALSE)
        df <- expand.grid(grids, KEEP.OUT.ATTRS = FALSE)
        Mu <- rep(0, dimension_n)
        Sigma <- diag(dimension_n)
        mvtnorm::dmvnorm(df, mean = Mu, sigma = Sigma)
    }
    bench::mark(
        create_and_eval_grid(1),
        create_and_eval_grid(2),
        check = FALSE,
        max_iterations = 500
    )
    ```

    Modifique el código brindado para evaluar la función de densidad en hasta un máximo
    de 10 dimensiones. Concluya sobre el tiempo de ejecución, el consumo de memoria, y 
    otras cantidades que se encuentren en la salida y crea adecuadas para el análisis.

<!-- 
TO DO

1.  Grid approximation para una _skew-normal_. Estimar los parámetros $\xi$ (posición), 
    $\omega$ (escala) y $\alpha$ (asimetría).
    
    $$
    f(x) = \frac{2}{\omega} \phi\left(\frac{x-\xi}{\omega}\right)\Phi\left( \alpha \frac{x-\xi}{\omega} \right)
    $$
    https://en.wikipedia.org/wiki/Skew_normal_distribution 

-->

## **Metropolis-Hastings** {#sec-mh}
<!--
Copio algunos pasajes del libro porque la verdad me parece super claro. 
Puede ser útil para la presentación de teoría.
Although not as efficient as independent sampling, dependent sampling is easier to 
implement, and only requires calculation of the un-normalised posterior, avoiding the 
troublesome denominator term

We also know that MCMC is typically used to do dependent sampling. It is called Monte Carlo 
because the decision of where to step next involves a random component

In this chapter we see that there are two components to this decision: 
in the first, we choose _where_ to propose a next step from the current position; 
in the second, we choose _whether_ we accept this step or stay where we are
@Lambert2018
-->

<!--
El algoritmo Metropolis es un caso especial del algoritmo general Metropolis-Hastings 
(Hoff, 2009). La principal diferencia es que el algoritmo Metropolis-Hastings no tiene el 
requisito de distribución simétrica.
-->

En esta sección, se profundiza en la práctica de uno de los algoritmos fundamentales de la
inferencia estadística bayesiana: el algoritmo de Metropolis-Hastings. 

1.  **Muestreo utilizando el algoritmo de Metropolis-Hastings (I)** 

    Use el algoritmo de Metropolis-Hastings y una distribución de propuesta 
    $\text{Normal}(0, 0.1)$ para obtener 5000 muestras de las siguientes distribuciones 
    de probabilidad:

    i. $\text{Normal}(\mu = 3, \sigma = 6)$.
    i. $\text{StudentT}(\nu = 5)$.
    i. $\frac{2}{3}\text{Normal}(\mu = 0, \sigma = 0.5) + \frac{1}{3}\text{Normal}(\mu = 3, \sigma = 2)$.

    Grafique las distribuciones obtenidas utilizando un histograma o una estimación
    de densidad y superponga la función de densidad verdadera para realizar una
    comparación. Concluya sobre la similitud de las mismas y la aptitud de la distribución
    de propuesta utilizada.

1.  **Simplificando el algoritmo de Metropolis-Hastings**
    
    La distribución de propuesta utilizada en el ejercicio anterior goza de una propiedad
    que permite simplificar el algoritmo de Metropolis-Hastings.

    i. ¿Cuál es esta propiedad?
    i. ¿Qué simplificación se puede hacer?
    i. ¿Qué nombre recibe la versión simplificada del algoritmo?
    i. Implemente la versión simplificada del algoritmo de Metropolis-Hastings y obtenga
    nuevamente 5000 muestras para las distribuciones presentadas en el ejercicio anterior
    utilizando la nueva implementación.

1.  **Muestreo utilizando el algoritmo de Metropolis-Hastings (II)**

    Use el algoritmo de Metropolis-Hastings y una distribución de propuesta que crea
    conveniente para obtener 5000 muestras de las siguientes distribuciones de 
    probabilidad:

    i. $\text{Beta}(\alpha=4, \beta=8)$.
    i. $\text{Gamma}(k = 3, \theta = 2)$.
    i. $\frac{1}{2}\text{Beta}(\alpha=10, \beta=3) + \frac{1}{2}\text{Beta}(\alpha=3, \beta=10)$.

    Realice un análisis similar al realizado en el Ejercicio 1.

1.  **¡A jugar con la distribución de propuesta!**

    Suponga que se desea obtener muestras de una distribución $\text{Normal}(4, 1)$ 
    utilizando Metropolis-Hastings y la siguiente distribución de propuesta:

    $$
    \mu' | \mu \sim \text{Uniforme}(\mu - w, \mu + w)
    $$

    Obtenga $n=5000$ muestras con $w \in \{0.01, 1, 100\}$ y compute la probabilidad de
    aceptación. Luego, para cada $w$, grafique la distribución obtenida y visualice la 
    cadena de Markov utilizando un _traceplot_.

    * ¿Cómo se relaciona $w$ con el desempeño del muestreo?
    * ¿Cómo se relaciona $w$ con la probabilidad de aceptación? Justifique su respuesta
    utilizando la ecuación del criterio de aceptación.


1.  [**Modelo Normal-Normal**]{#ex-mh-mm}

    Se desea estudiar el tiempo promedio que los estudiantes de estadística dedican por
    semana a la materia Estadística Bayesiana. Para eso se propone utilizar un
    modelo Normal-Normal, con $\sigma=1.2$ conocido.

    i. Elija una distribución _a priori_ para el parámetro $\mu$. 
    i. Describa el modelo matemáticamente.
    i. Determine una distribución de propuesta adecuada para este problema. Explique.
    i. Obtenga 2000 muestras del _posterior_ de $\mu$. Ajuste los parámetros de la 
    distribución de propuesta hasta que los resultados se vean adecuados.
    i. Grafique un histograma de las muestras obtenidas y concluya sobre el desempeño 
    de la aproximación.

    Para resolver este problema utilice los datos que se leen con el siguiente codigo:

    ```{r}
    #| eval: false
    url <- paste0(
        "https://raw.githubusercontent.com/estadisticaunr/",
        "estadistica-bayesiana/main/datos/tiempo-estudio-eb.csv"
    )
    df_estudio <- readr::read_csv(url)
    ```

1.  [**Modelo Beta-Binomial**]{#ex-mh-bb}

    Se desea estimar el _posterior_ del parámetro $\pi$ en el siguiente modelo 
    Beta-Binomial:

    $$
    \begin{aligned}
    Y &\sim \text{Binomial}(n, \pi) \\
    \pi &\sim \text{Beta}(2, 3)
    \end{aligned}
    $$

    Se observan $n=10$ ensayos de Bernoulli y se registran $y=3$ éxitos. Determine una 
    distribución de propuesta adecuada y obtenga muestras de la distribución 
    _a posteriori_ del parámetro $\pi$ utilizando el algoritmo de Metropolis-Hastings.

    De ser necesario, ajuste los parámetros de la distribución de propuesta. 

1.  **Modelo Poisson**

    En el ejercicio **¡Ostras! ¡Estoy haciendo inferencia bayesiana!** de la Práctica 1
    se reportó que la cantidad de especies marinas bivalvas descubiertas cada año entre 
    2010 y 2015 fue 64, 13, 33, 18, 30 y 20.

    Sea $Y_t$ la cantidad de especies descubiertas en el año $2009 + t$ (e.g. $Y_1 = 64$ 
    es el conteo para el año 2010) y el siguiente modelo:

    $$
    \begin{aligned}
    Y_t        &\sim \text{Poisson}(\lambda_t) \\
    \lambda_t  &= \exp (\alpha + \beta t) \\
    \alpha     &\sim \text{Normal}(0, 10^2) \\
    \beta      &\sim \text{Normal}(0, 10^2)
    \end{aligned}
    $$

    Ajuste el siguiente modelo utilizando Metropolis-Hastings y verifique la convergencia
    de las cadenas de Markov.
    <!-- @Reich2020 3.10/3.11  -->

1.  **Metropolis-Hastings multivariado**

    Use el algoritmo de Metropolis Hastings para obtener 1000 muestras de la distribución
    $\text{MVN}(\pmb{\mu}, \pmb{\Sigma})$ donde

    $$
    \begin{array}{cc}
        \pmb{\mu} = \begin{bmatrix}1.2 \\ 0.8 \end{bmatrix}, &
        \pmb{\Sigma} = \begin{bmatrix}3 & 0.2 \\ 0.2 & 2 \end{bmatrix}
    \end{array}
    $$

    Utilice una distribución de propuesta $\text{MVN}(\mathbf{0}_2, \mathbf{I}_2\sigma)$
    con $\sigma = 0.2$.

1.  **Metropolis-Hastings para regresión**

    Repita el ejercicio **Aproximación de grilla en 2 dimensiones** pero utilice 
    Metropolis-Hastings para obtener muestras del _posterior_ en vez del método de
    la grilla.

1.  **Demostración sobre la distribución estacionaria**
    
    Demostrar que la distribución estacionaria del algoritmo de Metropolis-Hastings es
    la distribución objetivo $p(\pmb{\theta} | \mathbf{y})$

<!--
TO DO

## **Hamiltonian Monte Carlo (HMC) y el Not-U-Turn Sampler (NUTS)**

Tenemos que completarlo...
-->

## **Diagnósticos**

El uso de algoritmos de MCMC provee de un gran poder que conlleva una gran responsabilidad.
En los ejercicios de esta sección ya se cuenta con un _posterior_ y se busca evaluar
la fiabilidad de las muestras utilizando diferentes medidas de diagnóstico análiticas
y gráficas.

1.  **Describir medidas de diagnóstico (I)**
    
    En sus propias palabras, explique que son $\text{ESS}$, $\hat{R}$ y $\text{MCSE}$. 
    Considere:

    * ¿Qué miden?
    * ¿Qué potencial problema de MCMC detectan?
    <!-- @Martin2021 2E2 -->

1.  **Describir medidas de diagnóstico (II)**

    En sus propias palabras, explique por qué las técnicas de estimación del _posterior_
    basadas en MCMC necesitan diagnósticos de convergencia.
    En particular, contraste estos con los métodos conjugados descritos en la Unidad 2 
    que no necesitan esos diagnósticos. 
    ¿Qué es diferente entre los dos métodos de inferencia?
    <!-- @Martin2021 2E8 -->

1.  **Problemitas de MCMC**

    Para cada escenario de simulación mediante MCMC descrito a continuación, explique 
    cómo el escenario podría afectar la aproximación del _posterior_.

    * La cadena se mezcla muy lentamente.
    * La cadena presenta alta auto-correlación.
    * La cadena tiende a quedarse "trabada".
    <!-- @Johnson2021 Exercise 6.3  -->

1.  **Vamos de paseo**

    Elabore _traceplots_ que le permitan visualizar la traza de la cadena de Markov
    utilizada en el ejercicio [**Modelo Normal-Normal**](#ex-mh-mm) de la sección 
    [**Metropolis-Hastings**](#sec-mh). 
    
    Luego, repita el ejercicio utilizando 4 cadenas independientes y grafique sus trazas
    en un mismo gráfico. ¿Qué puede concluir sobre la convergencia y la mezcla de las 
    cadenas?

1.  [**Primeros pasitos con $\hat{R}$**]{#ex-diag-pprhat}

    Repita lo realizado en el ejercicio [**Modelo Beta-Binomial**](#ex-mh-bb) de la 
    sección [**Metropolis-Hastings**](#sec-mh) utilizando 4 cadenas independientes. Luego:

    i. Calcule la varianza intra-cadenas $W$.
    i. Calcule la varianza entre-cadenas $B$.
    i. Calcule $\hat{R}$ y concluya sobre el resultado obtenido.

    <!-- **NOTA:** No hay una única alternativa de $\hat{R}$ dando vueltas por ahí. Está
    la versión de BDA3, que entiendo que es la misma que la del libro de Lambert, pero hoy
    se está recomendando una versión "rank-normalized". Ver [este paper](https://projecteuclid.org/journals/bayesian-analysis/advance-publication/Rank-Normalization-Folding-and-Localization--An-Improved-R%CB%86-for/10.1214/20-BA1221.full)
    y esta [discusión](https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/) -->

1.  **$\hat{R}$ para un muestreo independiente**

    En un determinado problema se encuentra que el _posterior_ del parámetro $\pi$ de un
    modelo con verosimilitud binomial está dado por

    $$
    \pi | \mathbf{y} \sim \text{Beta}(12, 6)
    $$

    i. Obtenga 4 conjuntos independientes de 1000 muestras independientes de esta 
    distribución.
    i. Calcule $W$, $B$, y $\hat{R}$ considerando que cada conjunto representa una cadena.
    i. Explique el resultado de $\hat{R}$.

    **Bonus**

    i. ¿Se puede concluir que cada uno de los muestreos realizados representan 
    realizaciones de una cadena de Markov? ¿Por qué?
    i. ¿Por qué no fue necesario descartar un conjunto de muestras de _warm-up_?

1.  **Función de autocorrelación**

    Utilice las 4 cadenas obtenidas en el ejercicio 
    [**Primeros pasitos con $\hat{R}$**](#ex-diag-pprhat) y grafique la función de 
    autocorrelación y calcule el coeficiente de autocorrelación utilizando un rezago
    unitario. Concluya sobre la dependencia entre las muestras obtenidas.

1.  **Tamaño de muestra efectivo**

    Utilice las muestras obtenidas en el ejercicio anterior para calcular el tamaño
    de muestra efectivo. 

1.  **Experimentos con el tamaño de muestra efectivo**

    Suponga una distribución $\text{Normal}(0, 1^2)$. Obtenga $n$ muestras independientes
    utilizando `rnorm()` y $n$ muestras dependientes utilizando Metropolis-Hastings 
    con $n \in \{10, 50, 100, 500, 1000, 10000\}$. 
    
    i. Calcule el temaño de muestra efectivo en todos los escenarios simulados.
    i. Describa el comportamiento del tamaño de muestra efectivo conforme se incrementa
    el número de muestras.
    i. ¿Por qué se observan los comportamientos descritos?

1.  **¡Rompan todo! Un caso simulado**

    Los siguientes gráficos muestran las trazas y las distribuciones que resultan al 
    obtener muestras de un _posterior_ utilizando dos cadenas de Markov independientes. 
    Estos muestreos fueron realizados de manera que presenten algunos problemas. 
    Describa cuales son los problemas que puede observar en los siguientes gráficos y 
    explique por qué no utilizaría estas muestras para obtener conclusiones sobre
    el _posterior_.
    
    ```{r}
    #| warning: false
    #| echo: false
    set.seed(121195)
    STEPS <- 200
    x <- rep(seq(STEPS), times = 2)

    plot_trace_and_histogram <- function(df) {
        plt_lines <- ggplot(df, aes(x = x, y = y, color = chain)) +
            geom_line(size = 1.2) + 
            labs(x = "Número de muestra", y = "Valor") + 
            guides(color = guide_legend(title = NULL)) +
            theme(
            legend.position = "top",
            legend.text = element_text(size = 12)
            )
        
        plt_hist <- ggplot(df, aes(y = y, fill = chain)) +
            geom_histogram(bins = 40, alpha = 0.7, position = "identity") +
            theme(
            axis.title = element_blank(),
            axis.text = element_blank(),
            axis.ticks = element_blank(),
            legend.position = "none"
            )
        plt <- plt_lines + plt_hist + plot_layout(widths = c(5, 1))
        return(plt)
    } 
    ```

    ```{r trace-and-histogram-1}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: Gráfico 1
    y1 <- rnorm(STEPS)
    y2 <- rnorm(STEPS) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-2}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: Gráfico 2
    y1 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4)
    y2 <- -0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-3}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: Gráfico 3
    y1 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4)
    y2 <- 0.035 * seq(STEPS) + rnorm(STEPS, sd = 0.4) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

    ```{r trace-and-histogram-4}
    #| warning: false
    #| echo: false
    #| fig-width: 8
    #| fig-height: 4.5
    #| fig-align: center
    #| fig-cap: Gráfico 4
    set.seed(121195)
    y1 <- cumsum(rnorm(STEPS, sd = 0.5))
    y2 <- cumsum(rnorm(STEPS, sd = 0.15)) + 5
    chain <- rep(c("Cadena 1", "Cadena 2"), each = STEPS)
    df <- data.frame(x = x, y = c(y1, y2), chain = chain)
    plot_trace_and_histogram(df)
    ```

1.  **¡Rompan todo! Un caso real**

    Al igual que en el ejercicio anterior, se presentan _traceplots_ donde el muestreo del
    _posterior_ presenta problemas. En este caso, los gráficos que se observan fueron 
    obtenidos en el marco de un problema real, y se usan 4 cadenas en vez de 2. 
    Nuevamente, describa cuales son los problemas que puede observar en los siguientes 
    gráficos y explique por qué no utilizaría estas muestras para obtener conclusiones 
    sobre el _posterior_.

    ```{r}
    #| echo: false
    #| out-width: 100%
    #| fig-align: center
    #| fig-cap: Gráfico 1
    knitr::include_graphics(file.path("imgs", "posterior_rota.png"))
    ```
    
    ```{r}
    #| echo: false
    #| out-width: 100%
    #| fig-align: center
    #| fig-cap: Gráfico 2
    knitr::include_graphics(file.path("imgs", "posterior_rota_2.png"))
    ```

    Además, responda:

    i. ¿Cuál gráfico se asocia a un mayor tamaño de muestra efectivo?
    i. ¿Qué grafico muestra peor mezcla entre cadenas?
    i. ¿En qué gráfico se puede observar que las cadenas convergen a la misma distribución?

## **Programación probabilística - Stan y RStan**

En esta sección se comienza a utilizar Stan para realizar los cálculos relacionados a la
inferencia bayesiana. Stan es uno de los lenguajes de programación probabilística mas 
potentes y populares en la actualidad. Los ejercicios contienen modelos estadísticos que
deben ser resueltos con la interface de `Stan` a `R`, `{RStan}`.

1.  **MCMC con RStan: Precalentamiento (I)**

    Utilice la información proporcionada para definir la estructura del modelo bayesiano 
    utilizando `{RStan}`. No es necesario ejecutar nada, solo necesita proporcionar el 
    código correcto.

    i. $Y | \pi \sim \text{Binomial}(\pi, 20)$ con $\pi \sim \text{Beta}(1, 1)$.
    i. $Y | \lambda \sim \text{Poisson}(\lambda)$ con $\lambda \sim \text{Gamma}(4, 2)$.
    i. $Y | \mu \sim \text{Normal}(\mu, 1^2)$ con $\mu \sim \text{Normal}(0, 10^2)$.
    <!-- @Johnson2021 6.11 -->

1.  **MCMC con RStan: Precalentamiento (II)**

    Utilice la información proporcionada para (1) definir la estructura del modelo 
    bayesiano y (2) obtener muestras del _posterior_ utilizando `{RStan}`. 
    No es necesario ejecutar nada, solo necesita proporcionar el 
    código correcto.

    i. $Y | \pi \sim \text{Binomial}(\pi, 20)$ con $\pi \sim \text{Beta}(1, 1)$ e $y = 12$.
    i. $Y | \lambda \sim \text{Poisson}(\lambda)$ con $\lambda \sim \text{Gamma}(4, 2)$ e 
    $y = 3$.
    i. $Y | \mu \sim \text{Normal}(\mu, 1^2)$ con $\mu \sim \text{Normal}(0, 10^2)$ e 
    $y = 12.2$.
    <!-- @Johnson2021 6.12 -->

1.  **Modelo Beta-Binomial con RStan (I)**

    Considere el modelo Beta-Binomial para $\pi$ con $Y | \pi \sim \text{Binomial}(\pi, n)$
    y $\pi \sim \text{Beta}(3, 8)$. Suponga que en $n = 10$ ensayos independientes
    observa $y = 2$ éxitos.

    i. Obtenga muestras del _posterior_ de $\pi$ con `{RStan}` utilizando 3 cadenas y 12000
    iteraciones por cadena.
    i. Grafique la traza de cada una de las tres cadenas.
    i. ¿Cuál es el rango de valores en el eje x del _traceplot_? 
    ¿Por qué el valor máximo de este rango no es 12000?
    i. Cree un gráfico que permita visualizar la función de densidad de los valores obtenidos
    con cada una de las tres cadenas.
    i. Utilizando lo estudiado en la Unidad 2, especifique el _posterior_ de $\pi$. 
    ¿Cómo se compara con la aproximación mediante MCMC?

1.  **Modelo Beta-Binomial con RStan (II)**

    Repita el ejercicio anterior utilizando $\pi \sim \text{Beta}(4, 3)$, donde observa
    $y = 4$ éxitos en $n = 12$ ensayos independientes.

1.  **Modelo Gamma-Poisson con RStan (I)**

    Considere el modelo Gamma-Poisson para $\lambda$ con 
    $Y_i | \lambda \sim \text{Poisson}(\lambda)$ y $\lambda \sim \text{Gamma}(20, 5)$.
    Suponga que cuenta con $n = 3$ observaciones independientes $(y_1, y_2, y_3) = (0, 1, 0)$

    i. Obtenga muestras del _posterior_ de $\lambda$ con `{RStan}` utilizando 4 cadenas y 
    10000 iteraciones por cadena.
    i. Grafique la traza y la función de densidad de cada una de las tres cadenas.
    i. A partir del gráfico de la función de densidad, ¿cuáles suelen ser, _a posteriori_,
    los valores más probables de $\lambda$?
    i. Utilizando lo estudiado en la Unidad 2, especifique el _posterior_ de $\lambda$. 
    ¿Cómo se compara con la aproximación mediante MCMC?

1.  **Modelo Gamma-Poisson con RStan (II)**

    Repita el ejercicio anterior utilizando el _prior_ $\lambda \sim \text{Gamma}(5, 5)$.

1.  **Modelo Normal-Normal con RStan (I)**

    Repita los mismos pasos del ejercicio **Modelo Gamma-Poisson con Rstan (I)** pero
    considere el modelo Normal-Normal para $\mu$ con 
    $Y_i | \mu \sim \text{Normal}(\mu, 1.3^2)$ y $\mu \sim \text{Normal}(10, 1.2^2)$.
    Suponga que cuenta con $n = 4$ observaciones independientes 
    $(y_1, y_2, y_3, y_4) = (7.1, 8.9, 8.4, 8.6)$

1.  **Modelo Normal-Normal con RStan (II)**

    Repita el ejercicio anterior con el modelo Normal-Normal pero ahora considere 
    $Y_i | \mu \sim \text{Normal}(\mu, 8^2)$ y $\mu \sim \text{Normal}(-15, 2^2)$.
    Suponga que en $n = 5$ observaciones independientes observa 
    $(y_1, y_2, y_3, y_4, y_5) = (−10.1, 5.5, 0.1,−1.4, 11.5)$


1.  **Un modelo que es un poco ¿complicado?**

    Considere el siguiente modelo

    $$
    \begin{aligned}
    \text{mass}_i &\sim \text{Normal}(\mu_i, \sigma^2) \\
    \mu_i         &= \theta_1 + \theta_2 + \text{age}_i^{\theta_3} \\
    \theta_1      &\sim \text{Normal}(0, 100^2) \\
    \theta_2      &\sim \text{Uniforme}(0, 20000) \\
    \theta_3      &\sim \text{Normal}(0, 1) \\
    \sigma^2      &\sim \text{InvGamma}(0.01, 0.01)
    \end{aligned}
    $$

    y los siguientes datos

    ```{R}
    #| eval: false
    edad <- c(2, 15, 14, 16, 18, 22, 28)
    peso <- c(29.9, 1761, 1807, 2984, 3230, 5040, 5654)
    n <- length(edad)
    data_list <- data.frame(peso = peso, edad = edad, n = n)
    ```

    i. Ajuste el modelo utilizando `{RStan}`.
    i. Obtenga una visualización de la edad versus el peso junto con una curva que indique
    la media _a posteriori_ de $\mu_i$ para evaluar si el modelo ajusta bien.
    i. Estudie la convergencia de las cadenas de Markov.
    i. Mencione tres medidas que podría tomar para mejorar la convergencia.
    <!-- @Reich2020 3.15 -->

## **Otros**

1.  Una compañía pesquera de Comodoro Rivadavia se encuentra probando un nuevo método para
    estimar el peso de los peces que extrae del Mar Argentino. El objetivo de este método
    es obtener una estimación lo suficientemente buena del peso de cada pescado sin tener
    que pesarlos uno por uno, ya que es un proceso costoso en tiempo y labor. 
    Para eso, seleccionaron una muestra de pescados, los pesaron
    y les midieron ciertos aspectos morfológicos (ancho, alto y largo). En el futuro,
    esperan recolectar estas mismas medidas morfológicas mediante una cámara especializada
    y utilizar un modelo para estimar el peso.
    
    El modelo propuesto por el equipo de investigación es el siguiente:

    $$
    \begin{aligned}
    \log(\text{Peso}_i) &\sim \text{Normal}(\mu, \sigma) \\
    \mu_i               &= \beta_0 + \beta_1 \log(\text{Largo}_i) \\
    \sigma              &\sim \text{Gamma}(k, \theta)
    \end{aligned}
    $$

    El peso se encuentra medido en gramos y la longitud en centímetros. El equipo provee 
    las muestras que obtuvieron del _posterior_. Las mismas se pueden leer en `R` 
    utilizando el siguiente bloque de código. 

    ```{r}
    #| eval: false
    url <- paste0(
        "https://raw.githubusercontent.com/estadisticaunr/",
        "estadistica-bayesiana/main/datos/fish-market-posterior.csv"
    )
    df_posterior <- readr::read_csv(url)
    head(df_posterior)
    ```
    ```
    # A tibble: 6 × 3
      intercepto pendiente sigma
           <dbl>     <dbl> <dbl>
    1      -4.44      3.08 0.408
    2      -4.30      3.05 0.431
    3      -4.49      3.12 0.433
    4      -4.04      2.96 0.341
    5      -4.76      3.18 0.413
    6      -4.65      3.15 0.350
    ```

    i.  Analice de manera gráfica y analítica los _posteriors_ marginales de los 
    parámetros del modelo. Realice las transformaciones de parámetros que crea
    conveniente para facilitar la comprensión del análisis.
    i.  Considere un pescado cuya longitud es de 30 centímetros.
        a. Obtenga y grafique la distribución _a posteriori_ del peso medio.
        a. Obtenga y grafique la distribución predictiva _a posteriori_ del peso.
        a. Interprete los resultados. 
    i.  Grafique la curva de regresión junto a una banda de credibilidad del 95% 
    en el plano de las variables originales y en el plano de las variables transformadas.
    i.  Agregue a los gráficos anteriores una banda de credibilidad del 95% para la 
    distribución predictiva _a posteriori_. Interprete los resultados.


<!--
TO DO: Mover a otro lado?

1.  Considere la siguiente familia de distribuciones normales en 2D

    $$
    f(\mathbf{x} | \pmb{\Sigma}, \pmb{\mu} = \mathbf{0}) 
    = \frac{1}{\det(2\pi\pmb{\Sigma})^{-\frac{1}{2}}}
    \exp[{-\frac{1}{2} \mathbf{x}^T \pmb{\Sigma}^{-1} \mathbf{x}}]
    $$

    y las siguientes matrices de covarianza

    $$
    \begin{array}{cc}
        \pmb{\Sigma}_1 = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} & 
        \pmb{\Sigma}_2 = \begin{bmatrix} 1 & 0.2 \\ 0.2 & 1 \end{bmatrix}
        \\ \\ 
        \pmb{\Sigma}_1 = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix} & 
        \pmb{\Sigma}_2 = \begin{bmatrix} 0.1 & 0 \\ 0 & 1 \end{bmatrix}
        \\ \\
        \pmb{\Sigma}_1 = \begin{bmatrix} 1 & 0.9 \\ 0.9 & 1 \end{bmatrix} & 
        \pmb{\Sigma}_2 = \begin{bmatrix} 0.01 & 0 \\ 0 & 1 \end{bmatrix}
    \end{array}
    $$

    Que dan lugar a las siguientes funciones de densidad:

    ```{r plot-matrix-of-gaussians}
    #| warning: false
    #| cache: true
    #| echo: false
    #| fig.width: 8
    #| fig.height: 12
    #| fig.align: center
    data <- tidyr::crossing(x1 = seq(-3, 3, 0.1), x2 = seq(-3, 3, 0.1))
    Mu <- replicate(6, c(0, 0), simplify = FALSE)
    Sigma <- list(
        matrix(c(1, 0, 0, 1), nrow = 2),
        matrix(c(1, 0.2, 0.2, 1), nrow = 2),
        matrix(c(1, 0.5, 0.5, 1), nrow = 2),
        matrix(c(0.1, 0, 0, 1), nrow = 2),
        matrix(c(1, 0.9, 0.9, 1), nrow = 2),
        matrix(c(0.01, 0, 0, 1), nrow = 2)
    )

    index <- 1
    plot_list <- purrr::map2(Mu, Sigma, function(x, y) {
        title_str <- paste0("$\\Sigma_", index, "$")
        plt <- data |>
            mutate(f = mvtnorm::dmvnorm(data, x, y)) |>
            ggplot() +
            geom_raster(aes(x = x1, y = x2, fill = f)) +
            stat_contour(aes(x = x1, y = x2, z = f), col = "white", bins = 5) +
            viridis::scale_fill_viridis() +
            labs(title = latex2exp::TeX(title_str)) + 
            theme(
                legend.position = "none", 
                plot.title = element_text(hjust = 0.5, size = 18)
            )
        index <<- index + 1
        return(plt)
    })

    plt <- Reduce(`+`, plot_list) + 
    plot_layout(ncol = 2)
    plt
    ```

    **Parte 1:** Metropolis-Hastings

    i. Utilice el algoritmo Metropolis-Hastings para obtener $n=10000$ muestras de
    cada una de las distribuciones.
    i. Calcule la probabilidad de aceptación.
    i. Grafique la función de autocorrelación y calcule la cantidad de muestras efectivas.
    i. Analice como varía la probabilidad de aceptación y la cantidad de muestras 
    efectivas según las diferentes características de la distribución objetivo.
    i. ¿Cuáles son las ventajas y desventajas del algoritmo de Metropolis-Hastings según
    lo que puede concluir a partir de esta aplicación? Comente dificultades con las que
    se haya encontrado. 

    **Parte 2:** Hamiltonian Monte Carlo

    i. Utilice el algoritmo HMC para obtener $n=10000$ muestras de
    cada una de las distribuciones.
    i. Calcule la probabilidad de aceptación.
    i. Grafique la función de autocorrelación y calcule la cantidad de muestras efectivas.
    i. Analice como varía la probabilidad de aceptación y la cantidad de muestras 
    efectivas según las diferentes características de la distribución objetivo.
    i. ¿Cuáles son las ventajas y desventajas del algoritmo de Metropolis-Hastings según
    lo que puede concluir a partir de esta aplicación? Comente dificultades con las que
    se haya encontrado. 

    **To Do** Proveer valores para los parámetros 'mu' y 'sigma'

-->


<!--
TO DO

### Ejercicios que faltan

* Utilizar HMC para la normal multivariada con correlación moderada y alta correlación
* Utilizar HMC para los modelos donde se usó MH
* Algun caso donde los diagnosticos no den bien...
    * Puede ser cuando el HMC no esta bien tuneado
    * Pensar algunos otros (deberia buscar en cosas que he hecho)
* Algo con brms?

**Nota:** Para los que dicen "utilizar HMC" estaria bueno que proveamos una funcion
que use HMC, sin que tengan que usar Stan.
-->

<!-- 
1. **La maldición de la dimensionalidad**

    **Nota:** Creo que esto puede ir para el TP 2 de este año, o ser parte del TP 2
    del año que viene. Esto todo en el contexto de grid approximation.

    * Mostrar que casi todo el volumen de un hipercubo está en las esquinas.
    * Hablar de la distnacia a la moda en una normal multivariada conforme d -> inftys 

1.  **Tomar el Torus por las astas**

    Ver el script "torus.R"
-->