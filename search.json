[
  {
    "objectID": "trabajos_practicos/02_tp2.html",
    "href": "trabajos_practicos/02_tp2.html",
    "title": "TP2: Implementación del algoritmo de Metropolis-Hastings",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "href": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "title": "TP2: Implementación del algoritmo de Metropolis-Hastings",
    "section": "Metropolis-Hastings en 2D",
    "text": "Metropolis-Hastings en 2D\nSe desean tomar muestras de una normal bivariada asimétrica cuya función de densidad viene dada por\n\\[\nf(\\mathbf{x}) = 2\\ \\phi_2(\\mathbf{x}\\mid\\mathbf{0},\\mathbf{\\Omega})\\ \\Phi(\\mathbf{\\alpha}^T\\mathbf{x}) \\qquad \\mathbf{x} \\in \\mathbb{R}^2\n\\]siendo \\(\\phi_2(\\mathbf{x}\\mid\\mathbf{0},\\mathbf{\\Omega})\\) la función de densidad de la normal bivariada de media \\(\\mathbf{0}\\) y matriz de covarianza \\(\\mathbf{\\Omega}\\), \\(\\Phi(\\mathbf{\\alpha}^T\\mathbf{x})\\) es la función de probabilidad acumulada de la normal estándar \\(\\mathcal{N}(0,1)\\) y \\(\\alpha\\in\\mathbb{R}^2\\) es un vector de parámetros.\n\nEn este caso, se tiene:\n\\[\n\\mathbf{\\Omega} = \\begin{bmatrix}1.5 & 0.6 \\\\ 0.6 & 1.5 \\end{bmatrix}\n\\] y\n\\[\n\\mathbf{\\alpha} = [2\\quad 0]\n\\]\n\n\n\n\n\nFunción de densidad de la que se desean obtener muestras\n\n\n\n\n\nEscriba una función que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una función de probabilidad bivariada dada. Separe en funciones cada una de los pasos del algoritmo. La probabilidad de salto será normal bivariada de matriz de covarianza variable. Otorgue flexibilidad al algoritmo haciendo que reciba como argumento la matriz de covarianza de la probabilidad de transición.\n\nSe utilizará una normal bivariada para proponer un salto en el algoritmo de Metropolis-Hastings. Se explorará el efecto de diferentes distribuciones de probabilidad de salto, en función de diferentes matrices de covarianza \\(\\mathbf{\\Sigma}\\). Si pensamos en escribir\n\\[\n\\mathbf{\\Sigma} = \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix} \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1\\end{bmatrix}  \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n\\]\ncon \\(\\sigma_i\\), la varianza de la componente \\(i\\) y \\(\\rho\\) la correlación entre las variables \\(X_1\\) y \\(X_2\\), entonces se deberán ensayar diferentes casos: \\(\\sigma_1=\\sigma_2\\) y \\(\\rho = 0\\), \\(\\sigma_1 > \\sigma_2\\) y \\(\\rho=0\\), \\(\\sigma_1<\\sigma_2\\) y \\(\\rho =0\\), \\(\\sigma_1=\\sigma_2\\) y \\(\\rho > 0\\), \\(\\sigma_1=\\sigma_2\\) y \\(\\rho < 0\\). TO DO Hacer gráficos:\n\nPara al menos dos variantes de cada uno de los cinco casos anteriores, comparar las trayectorias seguidas por las cadenas al obtener muestras de \\(f(x)\\)."
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#aplicación-tiempo-de-reacción-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "href": "trabajos_practicos/02_tp2.html#aplicación-tiempo-de-reacción-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "title": "TP2: Implementación del algoritmo de Metropolis-Hastings",
    "section": "Aplicación: ¿tiempo de reacción humano? ¿proponer un prior para sigma y uno para mu?",
    "text": "Aplicación: ¿tiempo de reacción humano? ¿proponer un prior para sigma y uno para mu?"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html",
    "href": "trabajos_practicos/03_tp3.html",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#simulaciones-y-validación-cruzada",
    "href": "trabajos_practicos/03_tp3.html#simulaciones-y-validación-cruzada",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Simulaciones y validación cruzada",
    "text": "Simulaciones y validación cruzada\n\nAlgo de calibración de probabilidades\nCalcular lppd “a mano”"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "href": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Enfriamiento de agua en un termo",
    "text": "Enfriamiento de agua en un termo\n\nEcuación diferencial (verificar)\nTransformación de variables\nAjustar el modelo lineal\nEncontrar el posterior del parámetro transformado\nPredecir la temperatura a la que estará después de un tiempo…"
  },
  {
    "objectID": "trabajos_practicos/descripcion.html",
    "href": "trabajos_practicos/descripcion.html",
    "title": "Generalidades",
    "section": "",
    "text": "Para aprobar la materia es necesario completar tres trabajos prácticos cortos. La denominación cortos hace referencia a que los trabajos son guiados y las tareas a realizar están delimitadas.\nLos trabajos prácticos tienen como objetivo repasar y afianzar los conocimientos adquiridos durante las clases, adquirir práctica en la aplicación de conceptos trabajados, mejorar las habilidades de programación y el uso de R, e incorporar algunos conceptos complementarios.\nCada trabajo práctico será presentado y discutido en clase. Se destinará una fracción de la clase a comenzar a pensar algunas de las actividades.\nLa fecha de entrega de cada trabajo práctico será de dos semanas luego de la fecha de presentación. Se podrá entregar el trabajo práctico una semana después de la fecha de entrega con una penalización del 25% de la nota final.\nPara cada trabajo práctico, cada grupo deberá entregar un informe en formato pdf donde se resuelvan las actividades propuestas. El informe debe estar obligatoriamente elaborado utilizando \\(\\mathrm{\\LaTeX{}}\\) (a través de Quarto, RMarkdown o alguna otra variante). Tener en cuenta que los apartados presentados en el enunciado del trabajo práctico constituyen una guía de actividades a resolver y no deben responderse uno a uno como si se tratara de un cuestionario. El informe deberá permitir una lectura fluida de los resultados y análisis presentados. Cuando la resolución de una problemática consista en una función o porción de código en R, el código deberá mostrarse en el informe.\nSe evaluarán los siguientes aspectos del informe: presentación, redacción (claridad, coherencia y cohesión), estética, resultados obtenidos, profundidad del análisis."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html",
    "href": "trabajos_practicos/01_tp1.html",
    "title": "TP1: Aplicación de modelos conjugados a reviews de Google Maps",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#descubriendo-la-distribución-de-dirichlet",
    "href": "trabajos_practicos/01_tp1.html#descubriendo-la-distribución-de-dirichlet",
    "title": "TP1: Aplicación de modelos conjugados a reviews de Google Maps",
    "section": "Descubriendo la distribución de Dirichlet",
    "text": "Descubriendo la distribución de Dirichlet\nLa distribución Dirichlet es en realidad una familia de distribuciones. Se trata de una familia de distribuciones de probabilidad continuas y multivariadas. La distribución de Dirichlet en \\(K \\geq 2\\) es la distribución de probabilidad del vector aleatorio \\(X=[X_1, X_2 \\dots, X_K]\\) dimensiones tiene como parámetro al vector \\(\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\dots,\\alpha_K]\\).\n\\[\nf(x_1,x_2,\\dots,x_k\\mid \\alpha_1, \\alpha_2,\\dots,\\alpha_K) = \\frac{1}{B(\\mathbf{\\alpha})} \\prod_{i=1}^K x_i^{\\alpha_i-1}\n\\]\ndonde los \\(\\alpha_i \\in \\mathbb{R}^+\\) y \\(B(\\mathbf{\\alpha})\\) es la constante que hace que la integral sea unitaria.\nEl soporte de la distribución Dirichlet es tal que \\(\\sum_{i=1}^{K} x_i = 1\\) y \\(x_i \\in [0,1]\\). Es decir, los \\(x_i\\) suman 1. Si consideramos, por ejemplo, \\(K=3\\), el vector \\([x_1, x_2, x_3]\\) pertenece al triángulo en \\(\\mathbb{R}^3\\) que tiene por vértices a los puntos \\((1,0,0)\\), \\((0,1,0)\\) y \\((0,0,1)\\). Así, si \\(x_1=1\\) entonces \\(x_2=x_3=0\\).\nMás simple aún, cuando \\(K=2\\), el vector \\([x_1,x_2]\\) pertenece al segmento en \\(\\mathbb{R}^2\\) que tiene por extremos a los puntos \\((1,0)\\) y \\((0,1)\\).\nNotar que esta característica hace que los \\(x_1,x_2,\\dots,x_K\\) puedan representar las probabilidades de un experimento con \\(K\\) resultados posibles.\nA título informativo, el soporte de la distribución Dirichlet en \\(K\\) dimensiones es lo que se conoce como simplex (estándar) de \\(K-1\\) dimensiones. El \\(3\\)-simplex es un triángulo y el \\(2\\)-simplex es un segmento. En general, un \\(K-1\\)-simplex es la envolvente convexa de \\(K\\) vértices y, a su vez, es la colección de todas las combinaciones convexas de puntos en el conjunto (Teorema de Carathéodory).\nLos párrafos anteriores, delirantemente matemáticos, muestran una virtud particular de la distribución Dirichlet de \\(K=3\\) dimensiones. Esta distribución, a pesar de ser de una variable aleatoria en \\(\\mathbb{R}^3\\), puede representarse perfectamente de manera gráfica en dos dimensiones (aunque utilizando un sistema de coordenadas peculiar: las coordenadas baricéntricas), como si se tratara de una distribución bivariada.\n\n\n\n\n\nComo los valores posibles del vector aleatorio tridimensional yacen en un plano, la distribución de probabilidad puede representarse gráficamente con facilidad\n\n\n\n\n\n\nMostrar que, cuando \\(K=2\\), la distribución de Dirichlet es la distribución beta de parámetros \\(a=\\alpha_1\\) y \\(b=\\alpha_2\\)"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#relación-entre-la-distribución-dirichlet-y-la-multinomial",
    "href": "trabajos_practicos/01_tp1.html#relación-entre-la-distribución-dirichlet-y-la-multinomial",
    "title": "TP1: Aplicación de modelos conjugados a reviews de Google Maps",
    "section": "Relación entre la distribución Dirichlet y la multinomial",
    "text": "Relación entre la distribución Dirichlet y la multinomial\nCuando un experimento puede tener dos resultados posibles, uno de ellos tiene probabilidad \\(p\\) y el otro probabilidad \\(1-p\\). Si coleccionamos \\(N\\) realizaciones del experimento, el número de éxitos es una variable aleatoria con distribución binomial. Estudiamos que era natural utilizar la distribución beta como distribución a priori para \\(p\\), dado que la distribución a posteriori también era beta.\nAnálogamente, cuando un experimento puede tener tres resultados posibles, el primero tiene probabilidad \\(p_1\\), el segundo tiene probabilidad \\(p_2\\) y el tercero, probabilidad \\(p_3 = p_1 - p_2\\). Necesariamente debe ser \\(p_1+p_2+p_3=1\\). Si coleccionamos \\(N\\) realizaciones del experimento, el número de ocurrencias de cada resultado posible es un vector aleatorio con distribución multinomial. Por lo visto hasta aquí, todo parece indicar que, si queremos realizar inferencias sobre \\(p_1\\), \\(p_2\\) y \\(p_3\\), sería natural utilizar la distribución Dirichlet de tres dimensiones como distribución a priori para las probabilidades…\nEn efecto, cuando la distribución a priori es Dirichlet y la verosimilitud es multinomial, la distribución a posteriori también es Dirichlet.\n\nSabemos que para una verosimilitud binomial, si la distribución a priori de la probabilidad de éxito \\(p\\) es beta de parámetros \\(a\\) y \\(b\\) y se observan \\(s\\) éxitos en \\(N\\) intentos, la distribución a posteriori es beta de parámetros \\(a' = a+s\\) y \\(b'=b+(N-s)\\).\nHallar, por analogía con el caso anterior, los parámetros de la distribución a posteriori que se obtiene si la verosimilitud es multinomial con tres resultados posibles, la distribución a priori es Dirichlet de parámetros \\([\\alpha_1,\\alpha_2,\\alpha_3]\\) y se obtuvieron \\(s_1\\) veces el primer resultado y \\(s_2\\) veces el segundo resultado, sobre un total de \\(N\\) intentos."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#aplicación",
    "href": "trabajos_practicos/01_tp1.html#aplicación",
    "title": "TP1: Aplicación de modelos conjugados a reviews de Google Maps",
    "section": "Aplicación",
    "text": "Aplicación\nAsumiremos ahora que las reviews de un local tienen distribución multinomial de parámetros \\([p_1,p_2,\\dots,p_5]\\). Es decir, la probabilidad de que un usuario asigne 1⭐ es \\(p_1\\), de que asigne 2⭐ es \\(p_2\\), y así sucesivamente. Llamaremos \\(n_1\\) al número de calificaciones de 1⭐, \\(n_2\\) al número de calificaciones de 2⭐, y así sucesivamente. \\(n_1+n_2+n_3+n_4+n_5 = N\\) será el número total de reviews.\nSe puede verificar que el número esperado de reviews de \\(i\\)⭐ será \\(N p_i\\). Por lo tanto, la puntuación esperada será:\n\\[\n\\frac{1}{N} (1\\cdot N p_1 + 2\\cdot N p_2 + 3\\cdot N p_3 + 4\\cdot N p_4 +5\\cdot N p_5) = \\sum_{i=1}^5 i\\cdot p_i\n\\]\n\nElija dos combinaciones de posibles valores de \\(p_i\\) que den un valor esperado de 4.1⭐. Piense en una combinación que represente acuerdo entre los clientes y otra que indique la presencia de opiniones dispares.\nEscriba una función que, dada una combinación de valores de \\(p_i\\), simule el proceso de calificación de un cliente\nConstruya una función que simule la calificación de \\(U\\) clientes\nSimule 1000 veces el proceso de 15 clientes que evalúan una cafetería de 4.1⭐ y el proceso de 100 clientes que evalúan la misma cafetería. ¿Qué se observa?\n\nUtilizaremos este nuevo modelo para realizar inferencias sobre las puntuaciones de Arto y Orlan.\n\nLos datos se generan siguiendo una distribución multinomial. ¿Cuáles son los parámetros de esa distribución multinomial? ¿Qué distribución a priori sería conveniente utilizar? ¿Cómo está parametrizada esa distribución a priori?\nElija los parámetros de la distribución a priori de modo tal que la creencia inicial sea uniforme sobre los posibles valores de los \\(p_i\\). ¿Qué implicancias tiene para la puntuación en ⭐ la distribución a priori elegida?\nCon los datos de la introducción, obtenga la distribución a posteriori de los \\(p_i\\) para cada cafetería.\n¿Cuál es la probabilidad de que Orlan sea mejor que Arto?"
  },
  {
    "objectID": "trabajos_practicos/00_tp0.html",
    "href": "trabajos_practicos/00_tp0.html",
    "title": "TP0: Distribución de Rocklets azules",
    "section": "",
    "text": "Descargar PDF\n\n\nDistribución de Rocklets azules"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística Bayesiana",
    "section": "",
    "text": "Este es el subtitulo…\n\n\n\n   Licenciatura en Estadística\n   Facultad de Ciencias Económicas y Estadística (UNR)\n   1° Cuatrimestre 2023"
  },
  {
    "objectID": "index.html#profesores",
    "href": "index.html#profesores",
    "title": "Estadística Bayesiana",
    "section": "Profesores",
    "text": "Profesores\n\n\nNacho Evangelista\n\n   email_de_nacho@mail.com\n   Miércoles (7:00-9:00) y Viernes (7:00-9:00)\n\n\n\nTomás Capretto\n\n   email_de_tomi@mail.com\n   Lunes (11-13hs) y Miércoles (7-9hs)"
  },
  {
    "objectID": "practica/practica_01.html",
    "href": "practica/practica_01.html",
    "title": "Práctica - Unidad 1",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_01.html#regla-de-bayes",
    "href": "practica/practica_01.html#regla-de-bayes",
    "title": "Práctica - Unidad 1",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\n\nEscribir la expresión matemática para cada una de las siguientes descripciones verbales:\n\nProbabilidad de un parametro dados los datos observados\nLa distribucion de probabilidad de los parametros antes de ver los datos\nLa verosimilitud de los datos para un valor dado de los parámetros\nLa probabilidad de una observación nueva dados los datos observados\nLa probabilidad de una observación antes de ver los datos\nTo Do Revisar texto. No se si es mejor usar “dado/dada” o “condicional a”, u otra expresión.\nTo Do Algunas descripciones no estan cubiertas en la Unidad 1. \n\nEl test infalible\nEn una población dada, una de cada mil personas tiene una enfermedad. Se toma una persona al azar de la población, se le aplica un test para detectar dicha enfermedad, y el resultado es positivo. El test se caracteriza por dar positivo el 99% de las veces que una persona tiene la enfermedad. Además, dicho test tiene una tasa de falsos positivos del 5%.\n\n¿Cuál es la probabilidad de que la persona tenga efectivamente la enfermedad?\nSi realizamos el mismo análisis una segunda vez sobre el mismo paciente y obtenemos nuevamente positivo\n\n¿Cuál seria la probabilidad que el paciente esté enfermo?\n¿Y si diera negativo?\n¿Es el a priori el mismo para el segundo análisis que para el primero? \n\n\n¿Es verdad que existen los vampiros? Versión Crepúsculo\nEdward quiere probarle a Bella que los vampiros existen. Según Bella, hay una probabilidad del 5% de que los vampiros existan. También cree que la probabilidad de que exista alguien con la piel brillante dado que los vampiros existen es del 70%, y que la probabilidad de que alguien tenga la piel brillante si los vampiros no existen es del 3%. Edward lleva a Bella al bosque y le muestra que de hecho su piel brilla como un 💎 ¿Cuál es la probabilidad que existan los vampiros? \n\n\n\n\n\nRobert Pattinson como Edward en Crepúsculo\n\n\n\n\nLos M&Ms azul fueron introducidos en el año 1995 (antes había dos tipos de marrón)\n\nAntes de 1995, la mezcla de colores en una bolsa de M&Ms era: 30% marron, 20% amarillo, 20% rojo, 10% verde, 10% naranja y 10% marrón bronceado.\nLuego de 1995, la mezcla pasó a ser: 24% azul, 20% verde, 16% naranja, 14% amarillo, 13% rojo y 13% marrón.\n\nUn amigo tiene dos bolsas de M&M y nos dice que una bolsa es de 1994 y la otra es de 1996, pero no nos dice cuál es cuál. Nos da un M&M de cada bolsa: uno es amarillo y el otro es verde (ambos posiblemente estén vencidos). ¿Cuál es la probabilidad de que el amarillo venga de la bolsa de 1994?\nÁrboles enfermos\nUn vivero de la ciudad se destaca por vender una variedad de árboles nativos, incluyendo al jacarandá, ceibo, ombú, entre otros. Lamentablemente, el 18% de los árboles del vivero estan infectados con moho. Los árboles enfremos se componen en un 15% por jacarandás, 80% de ceibos, y 5% de otras especies 1. Los árboles sanos se componen por un 20% de jacarandás, 10% de ceibos, y 70% de otras especies. Con el objetivo de monitorear cuanto se propagó la enfermedad, una de las personas que trabaja en el vivero selecciona al azar uno de los árboles para testear.\n\n¿Cuál es la probabilidad a priori de que el árbolo tenga moho?\nResulta que el árbol seleccionado es un ceibo. ¿Cuál es la probabilidad de haber seleccionado un ceibo?\n¿Cuál es la probabilidad a posteriori de que el ceibo seleccionado tenga moho?\nCompare las probabilidades a priori y a posteriori de que el árbol tenga moho. ¿Cómo afecta el análisis el saber que el árbol es un ceibo? \n\n\n\n\n\n\nFlor del Ceibo, la flor nacional\n\n\n\n\nTransporte El Impuntual\nUna cierta empresa de transporte regional, que decidimos llamar “El Impuntual”, tiene servicios que van desde Rosario hasta Wheelwright varias veces al día, todos los días de la semana. Un 30% de los viajes salen a la mañana, otro 30% salen a la tarde, y el restante 40% salen a la noche. Los pasajeros suelen estar muy frustrados ya que un 25% de los viajes salen tarde. De estos viajes demorados, el 40% corresponden a la mañana, un 50% suceden a la tarde, y el 10% restante ocurre a la noche.\nLucio y Franco son dos amigos del pueblo, y se volvieron a sus casas en colectivos diferentes.\n\nLucio se fue en uno de los colectivos de la mañana. ¿Cuál es la probabilidad que su viaje esté demorado?\nEl colectivo de Franco no está demorado. ¿Cuál es la probabilidad de que esté viajando en uno de los colectivos de la mañana? \n\n\n\n\n\n\nFoto de Markus Winkler en Unsplash\n\n\n\n\nBebé panda\nSupongamos que hay dos especies de osos panda. Ambas especies son igual de frecuentes y viven en la misma región. Es más, lucen de la misma forma y comen la misma comida. Aún no existe una prueba genética que pueda diferenciarlos. Lo único que los diferencia es la cantidad de crías que suelen tener. Las madres de la especie A dan luz a mellizos el 10% del tiempo. Y las madres de la especie B dan a luz mellizos el 20% del tiempo. En todos los otros casos, estas madres dan a luz un solo bebé panda.\nUsando un poco la imaginación, supongamos que somos la persona encargada de un programa de reproducción de pandas. Tenemos una panda femenina que acaba de dar a luz a un par de mellizos, pero no sabemos a que especie pertenece.\n\n¿Cuál es la probabilidad que la mamá panda sea de la especie A?\n¿Cuál es la probabilidad que vuelva a tener mellizos en la próxima parición?\nUn tiempo después sos encontramos con que en la segunda parición da a luz a un único bebé panda. ¿Cuál es la probabilidad de que este panda sea de la especie A? \n\n\n\n\n\n\nFoto de Stone Wang en Unsplash\n\n\n\n\nDemuestra la validez de la siguiente expresión de la regla de Bayes\n\\[\nP(B_j | A) = \\frac{P(A | B_j) P(B_j)}{\\sum_{k=1}^{K}P(A | B_k) P(B_k)}\n\\]\ndonde \\(A\\) es un evento cualquiera y \\(\\{B_1, \\cdots, B_K\\}\\) forman una partición. Para ello siga los siguientes pasos\n\nDemuestre que \\(P(B_j | A) P(A) = P(A | B_j) P(B_j)\\).\nDemuestre que \\(P(A) = P(A \\cap B_1) + P(A \\cap \\{\\cup_{k=2}^{K}B_j\\})\\).\nDemuestre que \\(P(A) = \\sum_{k=1}^{K} P(A \\cap B_j)\\).\nJunte las partes para formar la regla de Bayes.  \n\nHouse of Cards\nHay 538 miembros en el Congreso de Estados Unidos. Supongamos que se auditan sus inversiones y se encuentra que 312 de ellos obtuvieron rendimientos por encima del mercado. Asumamos que un miembro honesto del Congreso tiene solo una probabilidad del 50% de tener rendimientos por encima del mercado, pero uno deshonesto que opera con información confidencial tiene una chance del 90% de hacerlo. ¿Cuántos miembros del Congreso son honestos? \nEstás a punto de subir a un avión rumbo a Seattle. Querés saber si tenés que llevar un paraguas. Llamás a tres amigos que viven en Seattle y les preguntás si está lloviendo. Cada uno de ellos tiene una probabilidad de 2/3 de decirte la verdad y 1/3 de mentirte para hacerte una broma. Los tres responden que sí está lloviendo. Cuál es la probbailidad de que realmente esté lloviendo en Seattle? Se puede asumir que llueve el 10% del tiempo. \nDos personas dejaron rastros de sangre en la escena del crimen. La sangre de Oliver, un sospechoso, es analizada y resulta ser de tipo ‘0’. Los rastros de sangre de la escena son de tipo ‘0’ (un tipo común en la población, presente en el 60% de las personas) y de tipo ‘AB’ (un tipo raro, con una frecuencia del 1% en la población). ¿Estos datos representan evidencia de que Oliver estaba presente en la escena del crimen? \nNos encontramos con alguien en la calle y nos dice que tiene dos hijxs. Le preguntamos si algunx de ellxs es mujer y nos responde que sí. ¿Cuál es la probabilidad de que ambxs sean niñas? \nElvis Presley tenía un hermano varón que nació en el mismo parto pero que murió al poco tiempo. ¿Cuál es la probabilidad de que Elvis tuviera un gemelo? Alguna información adicional: en 1935, cuando Elvis nació, 1/3 de los hermanxs del mismo parto eran gemelxs y 2/3 mellizxs; además, la probabilidad de que dos mellizxs sean del mismo sexo biológico puede estimarse en 50%, mientras que dos gemelxs son siempre del mismo sexo biológico. \nDos cajones contienen medias. Uno de ellos tiene igual cantidad de medias blancas y negras. El otro contiene un número igual de medias rojas, verdes y azules. Se elige un cajón al azar, se sacan dos medias sin mirar y resultan ser las dos iguales. ¿Cuál es la probabilidad de que las medias sean blancas? Supóngase que sacar la primera media no altera las proporciones. \nProsecutor’s Fallacy\nSally Clark era una abogada británica que fue erróneamente sentenciada a prisión perpetua en 1999 por la muerte de sus dos hijos bebés. Su hijo mayor, Christopher, murió con 11 semanas en diciembre de 1996 y su hijo más joven, Harry, con 8 semanas en enero de 1998. Durante el juicio, la defensa argumentó que las muertes se debieron al síndrome de muerte súbita del lactante (SIDS). Clark fue condenada a partir del testimonio del pediatra Sir Roy Meadow, quien argumentó en la corte lo siguiente:\n\nEn familias sanas, la chance de muerte por SIDS es de \\(\\frac{1}{8500}\\)\nLa probabilidad de dos muertes por SIDS en la misma familia es aproximadamente \\(\\frac{1}{8500^2} \\approx \\frac{1}{73000000}\\)\nEs, por ende, muy poco probable que Clark sea inocente\n\nLuego de pasar 3 años en priosión, Clark fue liberada en 2003 luego de que se determinara que el testimonio experto de Meadows era equivocado. Dos mujeres, a las cuales el testimonio de Meadows había enviado a prisión, también fueron liberadas.\n\nIdentifica una falla en la probabilidad de \\(\\frac{1}{73000000}\\) dada por Meadows\nIncluso aceptando el número anterior como correcto, ¿cuál es el problema de interpretar esa probabilidad como la probabilidad de inocencia de Clark?"
  },
  {
    "objectID": "practica/practica_01.html#popurrí",
    "href": "practica/practica_01.html#popurrí",
    "title": "Práctica - Unidad 1",
    "section": "Popurrí?",
    "text": "Popurrí?\nTodos como que caen dentro de “regla de bayes”. Tenemos que ver como los dividimos\n\nSea \\(X_1 \\sim \\text{Bernoulli}(\\theta)\\) una variable que indica si una especie de árboles se halla en un determinado bosque y \\(\\theta \\in [0, 1]\\) representa la probabilidad a priori de que la especie se encuentre en el bosque. Una investigadora selecciona una muestra de \\(n\\) árboles del bosque y encuentra que \\(X_2\\) de ellas pertenecen a la especie de interés.\nEl modelo luego es \\[\n\\begin{array}{lc}\nX_2|X_1 \\sim \\text{Binomial}(n, \\lambda X_1) & \\text{con } \\lambda \\in [0, 1]\n\\end{array}\n\\]\n\\(\\lambda\\) representa la probabilidad de detectar la especie, dado que la especie se encuentra en el bosque.\nEncuntre expresiones matemáticas en término de \\(n\\), \\(\\theta\\) y \\(\\lambda\\) para las siguientes probabilidades:\n\n\\(P(X_1 = 0, X_2 = 0)\\)\n\\(P(X_1 = 0)\\)\n\\(P(X_2 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 0)\\)\n\\(P(X_2 = 0 | X_1 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 1)\\)\n\\(P(X_2 = 0 | X_1 = 1)\\)\nExplique de manera intuitiva cómo es que las probabilidades calculadas en (iv)-(vii) cambian según \\(n\\), \\(\\theta\\) y \\(\\lambda\\).\nAsuma \\(\\theta=0.5\\), \\(\\lambda=0.1\\) y \\(X_2 = 0\\) ¿Cuán grande debe ser \\(n\\) para que se puede concluir con 95% de confianza que la especie no se encuentra en el bosque? \n\nEn un estudio que utiliza métodos de la Estadística Bayesiana para predecir el número de especies que serán descubiertas en el futuro se reporta que la cantidad de especies marinas bivalvas2 descubiertas cada año entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSi se representa con \\(Y_t\\) a la cantidad de especies descubierta en el año \\(t\\), y asumiendo:\n\\[\n\\begin{aligned}\nY_t | \\lambda &\\underset{iid}{\\sim} \\text{Poisson}(\\lambda) \\\\\n\\lambda       &\\sim \\text{Uniforme}(0, 100)\n\\end{aligned}\n\\]\nGraficar la distribución a posteriori de \\(\\lambda\\). \nSea \\(n\\) la cantidad desconocida de clientes que visitan una tienda en un dia cualquiera. El número de clientes que realizan una compra es \\(Y\\) y se cumple que\n\\[\nY | n \\sim \\text{Binomial}(n, \\theta)\n\\]\ndonde \\(\\theta\\) es la probabilidad de compra, dado que se produce la visita a la tienda. La distribución a priori de \\(n\\) es \\(n \\sim \\text{Poisson}(5)\\). Bajo el supuesto que \\(\\theta\\) es conocido y que \\(n\\) es desconocido, graficar la distribución a posteriori de \\(n\\) para todas las combinaciones de \\(Y \\in \\{0, 5, 10 \\}\\) y \\(\\theta \\in \\{0.2, 0.5\\}\\). Explique cual es del efecto de cambiar \\(Y\\) y \\(\\theta\\) sobre la distribución a posteriori.  \nUn amigo arroja un dado y anota en secreto el número que sale (llamémoslo \\(T\\)). A continuación, nosotros, con los ojos vendados, arrojamos el dado varias veces. No podemos ver el número que sale pero nuestro amigo nos dice si el número que sacamos es mayor, menor o igual a \\(T\\).\nSupongamos que nos da la secuencia: \\(G,\\ G,\\ C,\\ I,\\ C,\\ C,\\ C, I,\\ G,\\ C\\) (siendo \\(G\\) más grande, \\(C\\) más chico e \\(I\\) igual). ¿Cuál es la distribución a posteriori de los valores de \\(T\\)? \nHay dos monedas en una caja. Una de ellas es una moneda común y la otra es una moneda que tiene dos caras.\n\nSe elige una moneda al azar, se arroja, y se obtiene cara. ¿Cuál es la probabilidad de que la moneda elegida sea la falsa?\nSe elige una moneda al azar y se arroja al aire tres veces, obteniéndose tres caras. ¿Cuál es la probabilidad de que la moneda elegida sea la falsa?\n\nCansada de los experimentos de arrojar una moneda cientos de veces al aire, una estudiante diseña un sistema de reconocimiento de imágenes que determina si salió cara o ceca y registra el resultado.\nLógicamente, el sistema diseñado no es perfecto sino que presenta una tasa de error. En particular, la probabilidad de que clasificar mal es de 0.2 (20% de las veces que sale cara, el sistema dice ceca, y viceversa).\nSe arroja la moneda 250 veces y el sistema detecta 140 caras,\n\n¿Cuál es la distribución a posteriori de \\(\\theta\\), la probabilidad de obtener cara?\n¿Qué ocurre a medida que la probabilidad de clasificar mal varía? \n\nEn las Jornadas Rosarinas de Ciencia de Datos, una expositora está dando una charla en un salón cuando el personal de seguridad la interrumpe porque cree que puede haber más de 1000 personas en la sala, superando el máximo permitido.\nLa expositora piensa que hay menos de 1000 personas y se ofrece a demostrarlo, aunque piensa que contarlas podría llevar mucho tiempo.\nDecide hacer un experimento:\n\nPregunta cuántas personas nacieron el 11 de mayo. Dos personas levantan la mano.\nPregunta cuántas personas nacieron el 23 de mayo. Una persona levanta la mano.\nPregunta cuántas personas nacieron el 1 de agosto. Nadie levanta la mano.\n\n¿Cuántas personas hay en la sala? O, mejor dicho, ¿cuál es la probabilidad de que haya más de 1000 personas en la sala? \nSupongamos que existe un idioma con seis palabras:\n\\[\n\\text{\\{perro, parra, farra, carro, corro, tarro\\}}\n\\]\nUn análisis lingüístico exhaustivo de esta lengua ha descubierto que todas las palabras son igualmente probables, excepto por ‘perro’, que es \\(\\alpha\\) veces más probable que las otras. Además:\n\nCuando se tipean, un caracter se introduce erróneamente con probabilidad \\(\\theta\\);\nTodas las letras tienen la misma probabilidad de producir un error de tipeo;\nSi una letra se tipeó mal, la probabilidad de cometer un error en otro caracter no cambia;\nLos errores son independientes a lo largo de una palabras.\n\n\n¿Cuál es la probabilidad de escribir correctamente ‘tarro’?\n¿Cuál es la probabilidad de tipear ‘cerro’ o ‘curro’ al querer escribir ‘carro’?\nUtilizando la Regla de Bayes, desarrollar un corrector gramatical para esta lengua. Para las palabras tipeadas ‘farra’, ‘birra’ y ‘locos’, hallar la probabilidad de que cada palabra del diccionario sea la palabra que se había querido escribir. Utilizar las siguientes combinaciones de parámetros:\n\n\\(\\alpha=2\\) y \\(\\theta = 0.1\\)\n\\(\\alpha=50\\) y \\(\\theta = 0.1\\)\n\\(\\alpha=2\\) y \\(\\theta = 0.9\\)"
  },
  {
    "objectID": "practica/practica_01.html#conceptuales",
    "href": "practica/practica_01.html#conceptuales",
    "title": "Práctica - Unidad 1",
    "section": "Conceptuales",
    "text": "Conceptuales\n\nVoy a conseguir esa pasantía\nLa empresa de tecnología en la que todo el mundo quiere trabajar tiene varias vacantes para pasantes en ciencia de datos. Luego de leer la descripción de la búsqueda, te das cuenta que sos una persona calificada para el puesto: estos son tus datos. Tu objetivo es averiguar si te van a ofrecer el puesto: esta es tu hipótesis.\n\nDesde la perspectiva de una persona con un razonamiento frecuentista, ¿Qué es lo que se responde al evaluar la hipótesis de que te ofrecen el puesto?\nRepita el punto anterior considerando la perspectiva de una persona con un razonamiento Bayesiano.\n¿Qué pregunta tiene más sentido responder: la frecuentista o la Bayesiana? Justifica tu respuesta. \n\nBeneficios de la Estadística Bayesiana\nUna amiga te cuenta que está interesada en aprender más sobre Estadística Bayesiana. Explícale lo siguiente:\n\n¿Por qué es útil el enfoque Bayesiano?\n¿Cuáles son las similitudes entre el enfoque frecuentista y el Bayesiano?"
  },
  {
    "objectID": "practica/practica_03.html",
    "href": "practica/practica_03.html",
    "title": "Práctica - Unidad 3",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_03.html#métodos-computacionales",
    "href": "practica/practica_03.html#métodos-computacionales",
    "title": "Práctica - Unidad 3",
    "section": "Métodos Computacionales",
    "text": "Métodos Computacionales\n\nEn la Copa del Mundo de la FIFA 2014, Alemania jugó contra Brasil en la semifinal. Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23. En ese momento del partido,\n\n¿Cuántos goles cabría esperar que Alemania hiciera al finalizar los 90 minutos?\n¿Cuál era la probabilidad de que Alemania hiciera más de 5 goles (cosa que ocurrió)? \n\nGrid approximation para un modelo de tres parámetros? Una regresión lineal? No la dimos pero la conocen…"
  },
  {
    "objectID": "practica/practica_00.html",
    "href": "practica/practica_00.html",
    "title": "Práctica - Unidad 0",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_00.html#probabilidad",
    "href": "practica/practica_00.html#probabilidad",
    "title": "Práctica - Unidad 0",
    "section": "Probabilidad",
    "text": "Probabilidad\n\nDe las siguientes expresiones cual(es) se corresponde(n) con el enunciado “la probabilidad de que Argentina gane la copa del mundo el 18 de Diciembre de 2022”?\n\n\\(P(\\text{18 de Diciembre de 2022} | \\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon}, \\text{18 de Diciembre de 2022}) / P(\\text{18 de Diciembre de 2022})\\)\n\\(P(\\text{Argentina campeon} | \\text{Diciembre})\\)\n\\(P(\\text{Argentina campeon} | \\text{18 de Diciembre de 2022})\\) \n\nEnuncie con palabras cada una de las expresiones del punto anterior. \nSegún la definición de probabilidad condicional\n\n¿Cuál es el valor de \\(P(A | A)\\)?\n¿Cuál es la probabilidad de \\(P(A, B)\\)?\n¿Cuál es la probabilidad de \\(P(A, B)\\) en el caso que \\(A\\) y \\(B\\) sean independientes?\nCuando se cumple que \\(P(A | B) = P(A)\\)?\nEs posible que \\(P(A | B) > P(A)\\)? Cuando?\nEs posible que \\(P(A | B) < P(A)\\)? Cuando?"
  },
  {
    "objectID": "practica/practica_00.html#distribuciones",
    "href": "practica/practica_00.html#distribuciones",
    "title": "Práctica - Unidad 0",
    "section": "Distribuciones",
    "text": "Distribuciones\n\nSea \\(X\\) una variable aleatoria con soporte \\(X \\in \\mathcal{S} = [1, \\infty)\\). Encuentre la constante \\(c\\), en función de \\(\\theta\\), que haga que \\(f(x) = c \\exp(-x / \\theta)\\) sea una función de densidad de probabilidad (pdf) válida. \nSuponga \\(X \\sim \\text{Uniforme}(a, b)\\), por lo que su soporte es \\(\\mathcal{S} = [a, b]\\) y su función de densidad de probabilidad es \\(f(x) = 1 / (b - a)\\) para todo \\(x \\in \\mathcal{S}\\).\n\nPruebe que \\(f(x)\\) es una función de densidad de probabilidad válida.\nEncuentre la media y la varianza de \\(X\\). \n\nSegún los expertos de un problema determinado, se indica que el valor de un parámetro debe ser positivo y su distribución a priori debe tener media igual a 5 y varianza igual a 3. Encuentre una distribución que satisfaga estas condiciones. \nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias con función de probabilidad conjunta dada por la siguiente tabla.\n\n\n\n\n\n\\(X_1\\) / \\(X_2\\)\n\\(X_2=0\\)\n\\(X_2=1\\)\n\n\n\n\n\\(X_1=0\\)\n\\(0.15\\)\n\\(0.15\\)\n\n\n\\(X_1=1\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\\(X_2=2\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\n\n\nDonde la celda de la primer fila y primer columna se lee \\(P(X_1=0, X_2=0)=0.15\\)\n\nObtenga la distribución marginal de \\(X_1\\).\nObtenga la distribución marginal de \\(X_2\\).\nObtenga la distribución condicional de \\(X_1\\) dado \\(X_2\\).\nObtenga la distribución condicional de \\(X_2\\) dado \\(X_1\\). \n\nSean \\(X_1\\) y \\(X_2\\) tales que \\((X_1, X_2)\\) siguen una distribución normal bivariada con \\(\\mathbb{E}(X_1) = \\mathbb{E}(X_1)\\) = 0, \\(\\text{Var}(X_1) = \\text{Var}(X_2 = 1)\\) y \\(\\text{cor}(X_1, X_2) = \\rho\\)\n\nEncuentre la distribución marginal de \\(X_1\\).\nEncuentre la distribución condicional de \\(X_1\\) dado \\(X_2\\)."
  },
  {
    "objectID": "practica/practica_00.html#esperanza-y-varianza",
    "href": "practica/practica_00.html#esperanza-y-varianza",
    "title": "Práctica - Unidad 0",
    "section": "Esperanza y Varianza",
    "text": "Esperanza y Varianza\n\nSuponga una urna \\(S\\) contiene un 40% de bolas verdes y un 60% de bolas rojas, y otra urna \\(E\\) contiene un 60% de bolas verdes y un 40% de bolas rojas. Una persona arroja una moneda de un peso argentino y selecciona una bola de una de las dos urnas dependiendo de si la moneda en sol o escudo. Si la moneda cae en sol, saca una bola de la urna \\(S\\) y si la moneda cae en escudo, saca una bola de la urna \\(E\\).\nConsidere las siguientes variables aleatorias:\n\\[\n\\begin{aligned}\nX &=\n    \\begin{cases}\n    1 & \\text{Si la moneda cae en sol} \\\\\n    0 & \\text{Si la moneda cae en escudo}\n    \\end{cases}\n\\\\\n\\\\\nY &=\n    \\begin{cases}\n    1 & \\text{Si la bola es verde} \\\\\n    0 & \\text{Si la bola es roja}\n    \\end{cases}\n\\end{aligned}\n\\]\n\nEncuentre la distribución conjunta de \\(X\\) e \\(Y\\) en una tabla.\nEncuentre \\(\\mathbb{E}(Y)\\). ¿Cuál es la probabilidad de que la bola sea verde?\nEncuentre \\(\\text{Var}(Y | X = 0)\\), \\(\\text{Var}(Y | X = 1)\\) Y \\(\\text{Var}(Y)\\). Considerando a la varianza como una medida de incertidumbre, explique de manera intuitiva por que algunas variancias son mas grandes que otras.\nSuponga que observa que la bola es verde. ¿Cuál es la probabilidad de que la moneda haya caido en escudo? \n\n\n\n\n\n\nMoneda de un peso argentino acuñada en 1995"
  },
  {
    "objectID": "practica/practica_02.html",
    "href": "practica/practica_02.html",
    "title": "Práctica - Unidad 2",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "href": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "title": "Práctica - Unidad 2",
    "section": "Modelos de Distribuciones Conjugadas",
    "text": "Modelos de Distribuciones Conjugadas\n\nEn un campamento de verano para infantes se realizaron actividades que promueven el contacto con la naturaleza. Una de las tareas consistió en germinar semillas de tomate. Josefina plantó 18 semillas en su almaciguera. Al cabo de 5 días, germinaron 8 de ellas. Llamaremos con \\(\\theta\\) a la probabilidad de que una semilla de tomate germine y asumimos una distribución \\(\\text{Beta}(1, 1)\\).\n\nCalcular la media y el desvío estándar a posteriori de \\(\\theta\\) a mano.\nVerifique el cálculo utilizando R.\nCalcule un intervalo de credibilidad del 95% para \\(\\theta\\).\n\nA mano\nUsando R\n\n\n\n\n\n\n\nFoto de Markus Spiske en Unsplash\n\n\n\n\nEn la final del 2018 de la Copa del Mundo de la FIFA, Francia le ganó a Croacia por 4 a 2. En función de este resultado,\n\n¿Qué probabilidad hay de que Francia fuera un mejor equipo que Croacia?\nSi el mismo partido se jugara de nuevo (cosa que los franceses en aquella oportunidad no pidieron), ¿cuál es la probabilidad de que Francia ganara de nuevo? \n\nDurante el desarrollo de las vacunas contra el COVID-19, un medio anunció para una determinada vacuna una eficacia del 100%.\n\nEn la fase 3 de un ensayo en adolescentes de entre 12 y 15 años, la vacuna BNT162b2 de Pfizer-BioNTech para el COVID-19 demostró una eficacia del 100% y una respuesta robusta de anticuerpos. El ensayo clínico involucró 2260 jóvenes estadounidenses. En el ensayo, 18 casos de COVID-19 fueron observados en el grupo placebo (\\(n=1129\\)) y ninguno en el grupo vacunado (\\(n=1131\\))\n\nEs de esperar que, en un ensayo más grande, aparezca algún caso de COVID-19 en el grupo que recibió el tratamiento. ¿Cómo se estima la probabilidad de algo que aún no ocurrió? \nLa regla del tres\nUna estudiante de Licenciatura en Estadística está releyendo su tesina antes de entregarla. Si en 20 páginas encontrara 5 typos, sería razonable estimar \\(\\frac{5}{20} = \\frac{1}{4}\\) typos/página. ¿Pero qué ocurre si en 20 páginas no encuentra ningún error?\nVerifcar que, partiendo de un prior uniforme, \\(\\frac{3}{N}\\) es una estimación razonable para \\(\\tau\\) (la tasa de typos por página), siendo \\(N\\) el número de páginas. Para ello, hallar la probabilidad de que $> \\(\\frac{3}{N}\\) para diferentes valores de \\(N\\).  4\nUna colega quiere comprar un producto por Internet. Tres vendedores ofrecen el mismo producto al mismo precio. Un vendedor tiene 100% evaluaciones positivas, con 10 reviews. Otro tiene 96% de evaluaciones positivas, con 50 reviews. El último tiene 90% de comentarios positivos, con 200 evaluaciones. ¿Cuál de los tres vendedores le recomendarías? \nInferencia sobre una distribución de Poisson\nLa distribución de masa de probabilidad Poisson se define como \\[\n\\begin{array}{lcr}\n\\displaystyle p(x | \\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!} &\n\\text{con} &\nx \\in \\{0, 1, 2, \\cdots \\}\n\\end{array}\n\\]\ndonde \\(\\lambda > 0\\) es la cantidad promedio de veces que ocurre el evento de interés en un periodo o espacio determinado.\n\nDerive el estimador de máxima verosimilitud del parámetro \\(\\lambda\\).\nDerive el posterior \\(p(\\lambda|D)\\) suponiendo que el prior sobre \\(\\lambda\\) es \\(p(\\lambda) = \\text{Ga}(\\lambda | a, b) \\propto \\lambda^{\\alpha-1}e^{-\\lambda b}\\). Ayuda: El posterior también es una distribución Gamma.\n¿A qué valor tiende la media a posteriori cuando \\(a \\to 0\\) y \\(b \\to 0\\)? Recuerde que la media de una distribución \\(\\text{Ga}(a, b)\\) es \\(a/b\\). \n\nInferencia sobre una distribución Uniforme\nConsidere una distribución uniforme crentrada en \\(0\\) y rango \\(2a\\). La función de densidad de probabilidad es\n\\[\np(x) = \\frac{1}{2a}I(x \\in [-a, a])\n\\]\nSea \\(\\mathbf{X} = (X_1,..., X_n)\\) un vector de \\(n\\) variables aleatorias independientes e idénticamente distribuidas según \\(p(x)\\)\nInferencia máximo-verosímil\n\n¿Cuál es el estimador máximo verosímil de \\(a\\) (llámelo \\(\\hat{a}\\))?\n¿Qué probabilidad le asigna el modelo a una nueva observación \\(x_{n + 1}\\) usando \\(\\hat{a}\\)?\n¿Observa algún problema con el resultado anterior? Si es así, sugiera una alternativa mejor.\n\nInferencia Bayesiana\nEl prior conjugado de la distribución uniforme es la distribución de Pareto.\nSi \\(x \\sim \\text{Pareto}(x | \\alpha, m)\\), luego\n\\[\np(x| \\alpha, m) = \\frac{\\alpha m^\\alpha}{x^{\\alpha+1}} \\mathbb{I}(x \\ge m)\n\\]\nSi el prior es una distribución de Pareto, la distribución conjunta de \\(\\theta\\) y \\(\\mathbf{X} = (X_1,..., X_n)\\) es\n\\[\np(\\theta, \\mathbf{X})\n    = \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n    \\mathbb{I}(\\theta \\ge \\text{max}(\\mathbf{X}))\n\\]\nLlamando \\(M_x = \\text{max}(\\mathbf{X})\\). La evidencia (la probabilidad que las \\(n\\) muestras provengan de la misma distribución uniforme) es\n\\[\n\\begin{aligned}\np(\\mathbf{X}) &= \\int_{M_x}^\\infty\n                 \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n                 d\\theta \\\\\n&=  \\begin{cases}\n    \\frac{\\alpha}{(n+\\alpha)m^n} & \\text{Si } M_x \\le m \\\\\n    \\frac{\\alpha m^\\alpha}{(n+\\alpha)m^{n+\\alpha}} & \\text{Si } M_x > m \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDerive el posterior y muestre que puede ser expresado como una distribución de Pareto.  \nInferencia sobre una distribución Exponencial\nEl tiempo de vida de una máquina en años \\(X\\) es modelado con una distribución exponencial con parámetro \\(\\theta\\) desconocido. La función de densidad es\n\\[\n\\begin{array}{lcrr}\np(x | \\theta) = \\theta e^{-\\theta x} & \\text{con} & x \\ge 0, & \\theta \\ge 0\n\\end{array}\n\\]\n\nMuestre que el estimador máximo verosímil es \\(\\hat{\\theta} = 1/\\bar{x}\\)\n\nSuponga que se observan los siguientes tiempos de vida de tres máquinas independientes \\(x_1 = 5\\), \\(x_2 = 6\\), \\(x_3 = 4\\). ¿Cuál es el valor del estimador MV?\nUna experta del área sugiere que \\(\\theta\\) debe tener una distribución a priori que también sea exponencial. \\[\n\\begin{aligned}\n\\theta &\\sim \\text{Exp}(\\lambda) \\\\\np(\\theta | \\lambda) &= \\lambda e^{-\\lambda \\theta}\n\\end{aligned}\n\\] Elija un valor para la distribución a priori, llámelo \\(\\hat{\\lambda}\\), tal que \\(\\mathbb{E}(\\theta) = 1/3\\).\n¿Cuál es el posterior \\(p(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)?\n¿Es la distribución exponencial conjugada con un likelihood exponencial?\nEncuentre la media del posterior, \\(\\mathbb{E}(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)\nExplique por que difieren el estimador MV de la media a posteriori.\n¿Cuál es más razonable en este ejemplo? \n\nCalculo de conjugada no tradicional\n\nBinomial negativa - Beta\nExponencial - Gamma. Modificar el ejercicio sobre Exponencial-Exponencial?\n\n7.4.5 de Reich"
  },
  {
    "objectID": "practica/practica_02.html#simulaciones",
    "href": "practica/practica_02.html#simulaciones",
    "title": "Práctica - Unidad 2",
    "section": "Simulaciones",
    "text": "Simulaciones\n\nEl tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene distribución exponencial con media 30 minutos. Los tiempos de duración de cada entrevista se pueden considerar independientes entre sí. Las entrevistas a postulantes para un trabajo están programadas cada 15 minutos, comenzando desde las 8. Es válido considerar que todos los postulantes llegan puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina\n\n¿Cuál es la probabilidad de que tenga que esperar antes de ser entrevistada?\n¿Cuál es el horario esperado al que terminará su entrevista? \n\nDos personas se conocen en la fila de embarque para un vuelo en un avión Airbus A330-300\n\n¿Cuál es la probabilidad de que tengan asientos en la misma fila?\n¿Cuál es la probabilidad de que estén sentados en asientos adyacentes?\n\nEl Problema de Monty Hall es trabajado con frecuencia en cursos de Probabilidad. Mediante simulación, determine cuál es la probabilidad de ganar el juego si se cambia de puerta. To Do Explicar el juego. \n\n\n\n\n\nLas 3 puertas del problema de Monty Hall\n\n\n\n\nBasándose en el siguiente tuit y conociendo el problema del cumpleaños (¿cuántas personas debe haber en una habitación para que la probabilidad de que dos de ellas cumplan años el mismo día sea mayor a X%?) construir un gráfico similar al del tuit donde se grafique la probabilidad de que haya \\(n\\) personas que cumplan años el mismo día para \\(K\\) personas presentes en la habitación.\nEl álbum oficial del Mundial de Fútbol de Qatar 2022 consta de 638 figuritas. Cada paquete trae cinco figuritas.\n\nComprando cinco paquetes, ¿cuál es la probabilidad de tener a Messi?\nComprando cinco paquetes, ¿cuál es la probabilidad de sacar a Messi repetido?\n¿Cuántos paquetes se necesitan, en promedio, para completar el álbum?\nSi a una persona le faltan diez figuritas para completar el álbum, ¿cuántos paquetes tiene que comprar para asegurarse de lograrlo?\n\nSi se arroja una moneda \\(n\\) veces, ¿cuál es la probabilidad de que no haya secuencias de \\(k\\) caras?\n¿Cuál es la probabilidad de que tres personas en un ascensor con doce pisos presionen para ir a tres pisos consecutivos?\nPrevio a la final de la Copa América 2021, los jugadores de la Selección Argentina se reúnen en la habitación del hotel como se describe en este tuit.\n\n¿Cuál es la probabilidad de que un jugador adivine una de diez cartas?\n¿Cuál es la probabilidad de que tres de ellos adivinen una de diez cartas?\n\n7.4.2 de Reich\nQuizás algo con tasa de falsos descubrimientos, p-values y su distribución…"
  },
  {
    "objectID": "practica/practica_02.html#elección-de-distribuciones-a-priori",
    "href": "practica/practica_02.html#elección-de-distribuciones-a-priori",
    "title": "Práctica - Unidad 2",
    "section": "Elección de distribuciones a priori?",
    "text": "Elección de distribuciones a priori?\n\nEsbozar la distribución de las siguientes variables\n\nEl número de personas que compran café en el bar de la facultad asumiendo distribución de Poisson.\nEl peso de perros adultos en kilogramos asumiendo una distribución Uniforme.\nEl peso de elefantes adultos en kilogramos asumiendo una distribución Normal.\nEl peso de humanos adultos en libras asumiendo una distribución asimétrica hacia la derecha.\n\nPara cada uno cada uno de los ejemplos del ejercicio anterior, graficar la distribución usando R. Seleccionar los parámetros que creas razonable, tomar una muestra aleatoria de tamaño 1000 y graficar la distribución en base a las muestras. ¿Se refleja tu conocimiento del problema en la distribución graficada? Si no, ajustar los parámetros y repetir el proceso hasta que el resultado tenga concuerde con el conocimiento del problema.\nComparar las siguientes distribuciones a priori.\n\n\\(\\text{Beta}(0.5, 0.5)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 4)\\)\n\\(\\text{Beta}(5, 1.5)\\)\n\n\n¿En qué se diferencian?\n¿Cuál de ellas es más informativa?\n¿Cómo lo determinaste?\n\nEn cada una de la situaciones que se describen debajo, ajustar manualmente los parámetros de una distribución \\(\\text{Beta}\\) para que reflejen la información brindada. En algunos casos puede haber varias respuestas aceptables en vez de existir “la respuesta correcta”.\n\nUn amigo se postuló para un empleo en LinkedIn y te dijo: “Diría que tengo una chance del 40% de que me den el trabajo, pero no estoy seguro”. Cuando le preguntamos un poco mas, dijo que estima sus chances entre un 20% y un 60%.\nUn grupo de investigación del CONICET desarrolló una nueva prueba para una enfermedad bastante rara. El grupo espera que esta prueba arroje resultados correctos el 80% de las veces, con una varianza de 0.05.\nEl primo de un amigo disfruta de salir a pescar, y lo hace muy seguido. En el asado de los Jueves dice que “El 90% de las veces que salgo a pescar, vuelvo con algo. Si te tuviera que dar un rango, te diría entre el 85% y el 100% de las veces”.\n\nEfecto de la parametrización\nSea \\(\\theta\\) la probabilidad de éxito en un experimento binomial y sea \\(\\gamma = \\frac{\\theta}{1-\\theta}\\) la chance de éxito. Utilizar simulaciones para explorar los efectos de las siguientes elecciones de distribuciones a priori\n\nSi \\(\\theta \\sim \\text{Uniforme}(0,1)\\), ¿cuál es el prior inducido para \\(\\gamma\\)?\nSi \\(\\theta \\sim \\text{Beta}(0,1)\\), ¿cuál es el prior inducido para \\(\\gamma\\)?\nSi \\(\\gamma \\sim \\text{Uniforme}(0,100)\\), ¿cuál es el prior inducido para \\(\\theta\\)?\nSi \\(\\gamma \\sim \\text{Gamma}(1,1)\\), ¿cuál es el prior inducido para \\(\\theta\\)?"
  },
  {
    "objectID": "practica/practica_02.html#notas",
    "href": "practica/practica_02.html#notas",
    "title": "Práctica - Unidad 2",
    "section": "Notas",
    "text": "Notas\nEn algún lado podríamos tener un glosario, o algo del estilo. El objetivo es despejar dudas, por ejemplo, sobre las parametrizaciones de las distribuciones que utilizamos por defecto. Acá podriamos mostrar que usamos \\(\\text{Beta}(a, b)\\) con \\(\\text{pdf}(x) = \\frac{\\Gamma(a + b)}{\\Gamma(a) + \\Gamma(b)} x^{a-1}(1-x)^{b-1}\\)"
  },
  {
    "objectID": "practica/practica_05.html",
    "href": "practica/practica_05.html",
    "title": "Práctica - Unidad 5",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_05.html#section",
    "href": "practica/practica_05.html#section",
    "title": "Práctica - Unidad 5",
    "section": "",
    "text": "1. 4.6.3 de Reich\n2. 4.6.4 de Reich\n3. 4.6.9 de Reich\n4. 6.3 de Reich\n5. 5.7.1 de Reich"
  },
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "Bibliografía",
    "section": "",
    "text": "Bibliografía principal\n\nJohnson, Ott, y Dogucu (2022) McElreath (2020) Gelman y Hill (2006) Kruschke (2014) Reich y Ghosh (2019)\n\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC.\n\n\n\n\nBibliografía complementaria\n\nGelman et al. (2013), Gelman, Hill, y Vehtari (2021), Downey (2021), Lee y Wagenmakers (2014), Davidson-Pilon (2015), Nicenboim, Schad, y Vasishth (2022), Barr (2021), Carlin y Louis (2008), Hoff (2009), MacKay (2003), Lambert (2018), Murphy (2022), Murphy (2023), Bishop (2006), Martin, Kumar, y Lao (2021), Theoridis (2020), Clyde et al. (2022), Ma, Kording, y Goldreich (2022)\n\n\n\n\n\nBarr, Dale J. 2021. Learning statistical models through simulation in R: An interactive textbook. 1st edition. https://psyteachr.github.io/stat-models-v1/.\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. 1st edition. Springer.\n\n\nCarlin, Bradley P., y Thomas A. Louis. 2008. Bayesian Methods for Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nClyde, Merlise, Mine Çetinkaya-Rundel, Colin Rundel, David Banks, Christine Chai, y Lizzy Huang. 2022. An Introduction to Bayesian Thinking. 1st edition. https://statswithr.github.io/book/.\n\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nDowney, Allen B. 2021. Think Bayes: Bayesian Statistics in Python. 2nd edition. O’Reilly Media. http://allendowney.github.io/ThinkBayes2/.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nLambert, Ben. 2018. A Student’s Guide to Bayesian Statistics. 1st edition. SAGE Publications Ltd.\n\n\nLee, Michael D., y Eric-Jan Wagenmakers. 2014. Bayesian Cognitive Modeling: A Practical Course. 1st edition. Cambridge University Press.\n\n\nMa, Wei Ji, Konrad P. Kording, y Daniel Goldreich. 2022. Bayesian Models of Perception and Action: An Introduction. 3rd edition. http://www.cns.nyu.edu/malab/bayesianbook.html.\n\n\nMacKay, David J. C. 2003. Information Theory, Inference and Learning Algorithms. 1st edition. Cambridge University Press.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/.\n\n\nMurphy, Kevin P. 2023. Probabilistic Machine Learning: Advanced Topics. 1st edition. The MIT Press. https://probml.ai/.\n\n\nNicenboim, Bruno, Daniel Schad, y Shravan Vasishth. 2022. An Introduction to Bayesian Data Analysis for Cognitive Science. https://vasishth.github.io/bayescogsci/book/.\n\n\nTheoridis, Sergios. 2020. Machine Learning: A Bayesian and Optimization Perspective. 2nd edition. Academic Press."
  },
  {
    "objectID": "info/enlaces_utiles.html",
    "href": "info/enlaces_utiles.html",
    "title": "Enlaces útiles",
    "section": "",
    "text": "Awesome Bayesian Statistics. Es un listado de recursos en línea (y gratuitos!) relacionados al mundo de la Estadística Bayesiana."
  },
  {
    "objectID": "info/aprobacion.html",
    "href": "info/aprobacion.html",
    "title": "Condiciones de aprobación",
    "section": "",
    "text": "Instancias de evaluación\n\n📝 Parcial – escrito e individual, se aprueba con 6, hay una instancia de recuperación;\n💻💻💻 Trabajos prácticos cortos – grupales (hasta tres personas), se hacen por fuera del horario de clase, se entrega informe;\n📈 Trabajo práctico final – realización grupal, defensa individual.\n\n\n\nCondiciones de aprobación\n\nPromoción\n\nLas y los estudiantes que hayan aprobado el parcial o su recuperatorio (con nota \\(P\\)), los tres trabajos prácticos cortos (con promedio simple \\(T\\)) y hayan entregado el trabajo práctico final, accederán a una instancia de evaluación oral donde se discutirá el trabajo práctico final y se evaluarán de manera general todos los contenidos conceptuales de la asignatura; esta instancia puede incluir la realización de algunas actividades en computadora (el trabajo práctico final y la instancia oral tendrán nota \\(O\\)).\nLa nota final se obtendrá según \\(0.3\\ T + 0.4\\ P + 0.3\\ O\\)\n\nRegularidad\n\nQuienes no alcancen la condición de promoción podrán quedar en condición de estudiante regular si aprueban el parcial o su recuperatorio y aprueban al menos dos de los trabajos prácticos cortos. Para alcanzar la aprobación de la asignatura, los y las estudiantes en condición de regulares deberán presentar el trabajo final en una mesa de examen y aprobar una instancia oral de defensa del trabajo y de evaluación integral de los contenidos de la materia. Esta instancia puede incluir la realización de algunas actividades en computadora.\n\nLibres\n\nAquellas personas que no alcancen la promoción de la asignatura ni la condición de estudiante regular quedarán en condición de estudiante libre. Los y las estudiantes en condición de libre deberán presentar un trabajo práctico y rendir un examen teórico-práctico sobre la totalidad de los temas de la asignatura."
  },
  {
    "objectID": "info/faq.html",
    "href": "info/faq.html",
    "title": "Estadística Bayesiana",
    "section": "",
    "text": "Preguntas frecuentes"
  },
  {
    "objectID": "info/docentes.html",
    "href": "info/docentes.html",
    "title": "Estadística Bayesiana",
    "section": "",
    "text": "Docentes"
  },
  {
    "objectID": "info/programa.html",
    "href": "info/programa.html",
    "title": "Programa",
    "section": "",
    "text": "Fundamentación\nLa Estadística Bayesiana es un enfoque de la inferencia estadística que se basa en utilizar probabilidades para representar el conocimiento disponible sobre el conjunto de parámetros de un modelo y actualizar esa información utilizando la Regla de Bayes a partir de la observación de un conjunto de datos. El conocimiento inicial se representa con una distribución de probabilidad a priori, la información contenida en los datos observados se modeliza con una función de verosimilitud y ambas fuentes de información se combinan para obtener una distribución de probabilidad a posteriori. La información a posteriori puede ser utilizada para extraer conclusiones sobre el fenómeno en estudio y realizar predicciones sobre datos no observados o eventos futuros.\nLos métodos bayesianos requieren, salvo en casos muy simples, una complejidad computacional que resultaba inalcanzable hace algunos años. Gracias a desarrollos revolucionarios en el ámbito de la computación, la principal barrera para la implementación de los modelos bayesianos desapareció y la utilización de estos se ha incrementado masivamente en múltiples campos científicos. Esta creciente popularidad se debe a que la inferencia bayesiana brinda un marco teórico consistente que permite la incorporación de información a priori, el desarrollo de un aprendizaje secuencial, la obtención de inferencias y predicciones en forma de distribuciones de probabilidad, el tratamiento de datos faltantes, los análisis con pocos datos, entre otras ventajas.\n\n\nObjetivos\nQue quienes cursen la materia logren:\n\nentender las características y los conceptos fundamentales de la Estadística Bayesiana;\ndescribir las características principales de la Estadística Bayesiana;\ncomprender la complejidad analítica de la inferencia bayesiana y la necesidad de la utilización de un enfoque computacional para superar estas dificultades;\nser capaces de aplicar métodos bayesianos a problemas reales utilizando software específico; e\ninterpretar los resultados del proceso de análisis bayesiano de datos.\n\n\n\nContenidos\n\nUnidad 1: Introducción y Fundamentos de la Estadística Bayesiana\n\nProbabilidad para cuantificar la incertidumbre. Modelos de probabilidad. Regla de Bayes. Inferencia bayesiana. Distribución a priori, función de verosimilitud, distribución a posteriori.\n\nUnidad 2: Inferencia Bayesiana\n\nModelos de distribuciones conjugadas. Modelos de un parámetro. Modelo beta-binomial. Enfoque intuitivo. Distribución a posteriori como compromiso entre la verosimilitud y la distribución a priori. Razonamiento secuencial. Modelo normal-normal. Modelo gamma–Poisson. Modelos de varios parámetros. Modelo normal – normal-gamma-inversa. Modelo Dirichlet–multinomial.\nElección de distribuciones a priori: no informativas (impropias, de Jeffrey) y débilmente informativas. Medidas de resumen de la distribución a posteriori. Intervalos de credibilidad. Distribución predictiva a posteriori. Nociones de teoría de la decisión bayesiana. Riesgo bayesiano. Estimador de Bayes.\n\nUnidad 3: Métodos Computacionales\n\nLimitaciones del enfoque analítico: cálculo de probabilidades y determinación de la distribución a posteriori. Soluciones: análisis de datos simulados y aproximación de grilla. Introducción al cómputo bayesiano. Nociones básicas de métodos de cadenas de Markov – Montecarlo (MCMC). Algoritmo de Metropolis–Hastings. Montecarlo Hamiltoniano. Diagnóstico de métodos MCMC.\nProgramación probabilística. Alternativas. Sintaxis de modelos. Ejemplos. Diagnóstico. Medidas de resumen a partir de las cadenas obtenidas. Visualizaciones.\n\nUnidad 4: Modelos Lineales\n\nModelos lineales. Elección de distribuciones a priori. Regularización. Diagnóstico de modelos. Predicciones basadas en distribuciones de probabilidad. Pruebas predictivas a priori y a posteriori. Densidad predictiva a posteriori logarítmica evaluada punto a punto (lppd). Deviance. Criterios de información: AIC, BIC, WAIC. Validacion cruzada. Sobreajuste y subajuste. Validación cruzada utilizando muestreo por importancia mediante suavizado Pareto (PSIS-CV).\n\nUnidad 5: Modelos Avanzados\n\nRegresión logística. Regresión Poisson. Comparación de grupos. Modelos de variable latente. Formulación gráfica. Análisis de sensibilidad.\nEl enfoque multinivel: modelos jerárquicos. Modelo beta-binomial jerárquico. Shrinkage de parámetros. Variación en el intercepto. Variación en la pendiente. Pooling de estimaciones. Problemas de estimación."
  },
  {
    "objectID": "info/calendario.html",
    "href": "info/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nUnidad\nTemas\nApunte\nLectura sugerida\nOtras actividades\n\n\n\n\n1\n2023-03-20\n1\nProbabilidad para cuantificar la incertidumbre. Repaso de probabilidad. Modelos de probabilidad. Regla de Bayes.\n\n\n\n\n\n2\n2023-03-27\n1\nInferencia bayesiana. Distribucion a priori, funcion de verosimilitud y distribucion a posteriori.\n\n\n\n\n\n\n\n2\nConjugación. Modelos conjugados a un parámetro. Modelo beta-binomial. Posterior como compromismo entre verosimilitud y prior. Razonamiento secuencial.\n\n\n\n\n\n3\n2023-04-03\n2\nModelos conjugados a un parámetro. Modelo normal-normal. Modelo gamma-poisson. Modelos de varios parametros. Normal-normal-gamma-inversa. Modelo Dirichlet-multinomial.\n\n\nPresentación TP 1\n\n\n4\n2023-04-10\n2\nMedidas de resumen de la distribucion a posteriori. Distribucion predictiva a posteriori. Teoria de decision bayesiana. Estimador de Bayes.\n\n\n\n\n\n5\n2023-04-17\n3\nLimitaciones en el enfoque analítico. Aproximación mediante grilla de puntos. Limitaciones en la aproximación mediante grilla de puntos. Necesidad de contar con otro tipo de técnicas. Solución de problemas mediante técnicas de simulación. Obtención de muestras de distribuciones de probabilidad.\n\n\nEntrega TP 1\n\n\n6\n2023-04-24\n3\nIntroducción al cómputo bayesiano. Nociones básicas de cadenas de Markov y de muestreo mediante el método de Algoritmo de Metrópolis-Hastings. Monte Carlo Hamiltoniano. Diagnóstico de métodos de MCMC. Monte Carlo basado en cadenas de Markov.\n\n\n\n\n\n7\n2023-05-01\n3\nProgramación probabilística. Introducción a Stan. Sintáxis básica de modelos en Stan. Especificación de modelos en Stan. Obtención del posterior. Diagnósticos. Análisis del posterior. Responder preguntas usando las muestras del posterior.\n\n\nParcialPresentación TP 2\n\n\n8\n2023-05-08\n4\nRepaso de modelos lineales. Estimación clásica (MCO y MV). Limitaciones. Interpretación frecuentista de los Intervalos de Confianza. Modelos lineales bajo el enfoque bayesiano. Uso de distribuciones a priori. Estimación. Intervalos de Credibilidad y su interpretación. Elección de distribuciones a priori. Predicciones basadas en distribuciones de probabilidad. Distribución predictiva a posteriori.\n\n\n\n\n\n9\n2023-05-15\n4\nModelos lineales. Introducción a brms. Reemplazo de Stan por brms. Diagnósticos y selección de modelos. lppd. Deviance. AIC, BIC, WAIC. Validación cruzada. Sobreajuste y subajuste. PSIS-CV.\n\n\nEntrega TP 2Presentación TP 3\n\n\n10\n2023-05-22\n4\nEjercitación integradora de modelos lineales bayesianos usando R y brms.\n\n\n\n\n\n11\n2023-05-29\n5\nExtensión de los modelos lineales considerando funciones de verosimilitud no-normales. Introducción a MLG. Predictor lineal. Función de enlace. Función de verosimilitud. Mención a modelos para datos de conteo y para probabilidades. Modelos para datos de conteo. Verosimilitud Poisson. Función de enlace logarítmica, y otras funciones.\n\n\nEntrega TP 3\n\n\n12\n2023-06-05\n5\nEjercitación con modelos para datos de conteo. Modelos para probabilidades. Verosimilitud Bernoulli. Función de enlace logit. Interpretación de coeficientes.\n\n\nPresentación TP Final\n\n\n13\n2023-06-12\n5\n…\n\n\n\n\n\n14\n2023-06-19\n5\n…\n\n\n\n\n\n15\n2023-06-26\n5\n…\n\n\nDefensa oral del TP Final\n\n\n16\n2023-07-03\n5\n…"
  },
  {
    "objectID": "computo/instalacion.html#rstan",
    "href": "computo/instalacion.html#rstan",
    "title": "Instalación de herramientas comutacionales",
    "section": "RStan",
    "text": "RStan\n\nWindows\n\n\nUbuntu\n\n\nMac OS\n\n\nVerificación"
  },
  {
    "objectID": "computo/instalacion.html#librerias-adicionales",
    "href": "computo/instalacion.html#librerias-adicionales",
    "title": "Instalación de herramientas comutacionales",
    "section": "Librerias adicionales",
    "text": "Librerias adicionales\n\n{brms}\n{ggplot2}\n{dplyr}\n**Estaria bueno pinear las dependencias usando {here} o algo similar\n\n\nVerificación"
  },
  {
    "objectID": "computo/instalacion.html#dependencias-optativas",
    "href": "computo/instalacion.html#dependencias-optativas",
    "title": "Instalación de herramientas comutacionales",
    "section": "Dependencias optativas",
    "text": "Dependencias optativas\n\nQuarto\n… ?"
  },
  {
    "objectID": "complementario/variables.html",
    "href": "complementario/variables.html",
    "title": "Repaso de Variables Aleatorias",
    "section": "",
    "text": "Variables aleatorias\n\nDiscretas\nContinuas\n\nCDF\nPDF\nDistribucion conjunta\nDistribucion marginal\nDistribucion condicional\nIndependencia e independencia condicional\nMomentos de una distribucion\nRegla de Bayes\nDistribuciones de probabilidad frecuentemente utilizadas\nTransformacion de variables aleatorias\n\nPropiedades de transformaciones lineales\n\n\nEste listado esta sacado del capitulo 2 de Murphy (2022)\nTambien hay cosas interesantes en capitulo 3 de Murphy (2022)\n\nUncorrelated does not imply independent\nCorrelation does not imply causation\n\n\nPairwise independence does not imply mutual independence\nWe say that two random variables are pairwise independent if \\(p(X_2|X_1) = p(X_2)\\) and hence \\(p(X_2, X_1) = p(X_1)p(X_2|X_1) = p(X_1)p(X_2)\\)\nWe say that \\(n\\) random variables are mutually independent if \\(p(Xi|XS) = p(Xi)\\) \\(\\forall S \\subseteq \\{1, \\cdots , n\\}\\) and hence \\(\\displaystyle p(X_{1:n}) = \\prod_{i=1}^{n} p(X_i)\\)\nShow that pairwise independence between all pairs of variables does not necessarily imply mutual independence. It suffices to give a counter example.\nExercise 2.5 Murphy (2022)\nExercise 2.6 Murphy (2022)\nExercise 3.5 [Gaussian vs jointly Gaussian ]\n\n\n\n\n\nReferencias\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/."
  }
]