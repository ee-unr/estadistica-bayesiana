[
  {
    "objectID": "notas/planificacion.html",
    "href": "notas/planificacion.html",
    "title": "Contenidos detallados",
    "section": "",
    "text": "Actividad Rocklets\n\n\nRepaso\n\nRepaso de probabilidad, distribuciones conjuntas, distribuciones marginales\nPr√°ctica 0 (ver qu√© ejercicios)\n\n\n\nIntroducci√≥n\n\nProbabilidad para cuantificar la incertidumbre\n\nDefiniciones de probabilidad\n\nClasica\nFrecuentista\nBayesiana (subjetiva)\n\nProbabilidades subjetivas\nL√≥gica y razonamiento plausible (ver Jaynes)\nDutch book\n\nRegla de Bayes\n\nHistoria: Bayes, Price, Laplace\nPresentaci√≥n tradicional de la Regla de Bayes\n\nLey de la probabilidad total\n\nPr√°ctica 1 (ver qu√© ejercicios)\n\nInferencia bayesiana: problema original de Bayes, problema de la percepci√≥n del suelo mojado, problema de las bolas (¬øhecho en vivo con Sugus?), problema del globo terr√°queo (¬øhecho en vivo?), problema de detecci√≥n de gluten (ver Downey), problema de detecci√≥n de una explosi√≥n (ver Barber).\n\nDiscutir modelos generativos (probabilidad hacia adelante e inversa).\nPr√°ctica 1 (ver qu√© ejercicios)\nIdea intuitiva: ¬øqu√© es el prior? ¬øqu√© es la funci√≥n de verosimilitud? ¬øqu√© es el posterior?\n\n\n\n\nModelos de distribuciones conjugadas\n\nModelo beta-binomial\n\nDemostraci√≥n\n\nBeta(a,b) siendo a y b ‚Äúpseudocuentas‚Äù\n\nDefinici√≥n de ‚Äúdistribuciones conjugadas‚Äù (ver BDA 2.4)\nEnfoque intuitivo\nDistribuci√≥n a posteriori como compromiso entre likelihood y prior\n\nver caso particular y luego generalidad 2.2 de BDA\n\nRazonamiento secuencial\nResumen de la distribuci√≥n a posteriori: media, moda, intervalos de credibilidad. C√°lculos a mano, c√°lculos exacto con funciones de R. Simulaciones (vamos a introducir la idea de utilizar simulaciones para resolver problemas)\n\nPodemos resolver algunos ejercicios de Simulaci√≥n de la Pr√°ctica 2\n\nPredicciones: simulaciones. Problema del amanecer.\nEstimaci√≥n por m√°xima verosimilitud\nPr√°ctica 2\n\nElecci√≥n de la distribuci√≥n a priori\n\nPr√°ctica 2\n\nModelo normal-normal\n\nDemostraci√≥n\nEnfoque intuitivo\nDistribuci√≥n a posteriori como compromiso entre likelihood y prior\nRazonamiento secuencial\nPredicciones: distribuci√≥n predictiva. Incertidumbre propia del sampleo + incertidumbre (ver BDA 2.5 y posterior predictive distribution). Plugin approximation vs posterior predictive distribution (3.1.5.2 de Murphy)\nModelo normal con prior uniforme (ver Devinderjit y Skilling, Secci√≥n 2.3 ‚Äì Example 2)\n(¬ø) Modelo normal con media conocida y varianza desconocida (?) (ver BDA 2.6)\n\nModelo Gamma-Poisson\nOtros modelos de distribuciones conjugadas para una variable (ver Pr√°ctica 2)\nPresentaci√≥n TP1 ‚Äì Conjugaci√≥n Dirichlet-Multinomial\nModelos de varias variables\n\nNormal con media y desv√≠o desconocido: modelo normal ‚Äì normal-gamma-inversa (ver Ejemplo 2.8 de Carlin y Louis, BDA Secci√≥n 3.3 y 3.2.3.3 de Murphy)\nNormal con con media y desv√≠o desconocido: prior uniforme (ver Devinderjit y Skilling, Secci√≥n 3.3 ‚Äì Example 5 y ver BDA Secci√≥n 3.2). Relaci√≥n con m√°xima verosimilitud (ver Devinderjit y Skilling, Secci√≥n 3.5 ‚Äì Approximations)\n(¬ø) Distribuciones marginales de los par√°metros (?)\n\n\n\n\nNociones de Teor√≠a de la Decisi√≥n\n\nEl resultado de la inferencia bayesiana es la distribuci√≥n a posteriori‚Ä¶ a√∫n as√≠, a veces podemos querer resumirla\n¬øPor qu√© tiene sentido resumir la distribuci√≥n a posteriori usando la media?\nFunciones de p√©rdida (ver Davidson-Pilon, Cap√≠tulo 5)\nPosterior expected loss (ver Robert, Secci√≥n 2.3: Utility and loss)\n\nEjemplo de COVID-19 de Murphy (3.8.2)\n\nDemostraci√≥n de que la media minimiza la p√©rdida cuadr√°tica (ver Robert, Proposici√≥n 2.5.1)\nEjercicios (Pr√°ctica 2)\n\n\n\nM√©todos Computacionales\n\nProblemas: determinaci√≥n de probabilidades, c√°lculo de integrales, determinaci√≥n de la distribuci√≥n a posteriori (dos problemas: integrales anal√≠ticas y dimensiones de esa integral)\nDeterminaci√≥n de probabilidades (ya lo hemos trabajado en la Pr√°ctica 2)\nEjercicios Simulaci√≥n (Pr√°ctica 3)\nIntegraci√≥n por Montecarlo\nGrid approximation\n\nUn par√°metro\nDos par√°metros\nCaso discreto ((¬ø)grid approximation de un problema para estimar N y theta(?)) y caso continuo\n\nEjercitaci√≥n grid approximation (Pr√°ctica 3)\nDeterminaci√≥n de la distribuci√≥n a posteriori (aka sampling) por m√©todos de MCMC\n\nPresentar rejection sampling\n(¬ø) Importance sampling (?)\nMetropolis-Hastings\n\nPresentaci√≥n TP2 ‚Äì Metropolis-Hastings (trabajo en clase)\nDiagn√≥stico de m√©todos de MCMC\nHamiltonian Montecarlo\nPr√°ctica HMC\nProgramaci√≥n probabil√≠stica: Stan\nComponentes de un modelo en Stan\nImplementaci√≥n de un modelo ya trabajado.\n\nDiagn√≥sticos\nManipulaci√≥n de muestras de MCMC.\nVisualizaciones de resultados (estimaciones de par√°metros y predicciones). Uso del paquete ggdist.\n\n\n\n\nModelos lineales\n\nEstimaci√≥n por m√≠nimos cuadrados. Estimaci√≥n por m√°xima verosimilitud.\n\nVer ROS 8.1\n\nEstimaci√≥n bayesiana. Priors conjugados para varianza conocida y varianza desconocida.\n\nCentrado de variables (ver Murphy y 12.3 de ROS)\n\nDistribuci√≥n predictiva.\nImplementaci√≥n en Stan y brms (comparaci√≥n de brms con lm en R, ¬øc√≥mo obtenemos los mismos resultados? ver ROS 8.4).\nManipulaci√≥n de resultados.\nPredicciones probabil√≠sitas (predicciones basadas en distribuciones de probabilidad). Propagaci√≥n de incertidumbre. Interpretaci√≥n.\n\nPredicci√≥n puntual vs predicci√≥n de la media (predictor lineal) vs distribuci√≥n predictiva\nWe have a set of posterior simulations rather than a single point estimate because we have uncertainty about these parameters. (ROS 9.1)\nAs sample size approaches infinity, the coefficients a and b are estimated more and more precisely, and the uncertainty in the linear predictor approaches zero, but the uncertainty in the predictive distribution for a new observation does not approach zero; it approaches the residual standard deviation œÉ. (ROS 9.2)\n\nParameter recovery\n\n(ver ROS 7.2 Checking the model-fitting procedure using fake-data simulation)\n\nPruebas predictivas a posteriori. Comparaci√≥n de los datos disponibles con r√©plicas generadas por el modelo ajustado (lo que en ROS llaman validaci√≥n interna)\n\nVer ROS 11.4\n\nElecci√≥n de una distribuci√≥n a priori. Pruebas predictivas a priori.\nProblemas con la estimaci√≥n de m√≠nimos cuadrados. Regularizaci√≥n ridge (\\(L_2\\)) y lasso (\\(L_1\\)). Distribuciones a priori para regularizar.\n\nSelecci√≥n de variables con horseshoe prior (ver ROS 12.7)\nValidaci√≥n externa y criterios de informaci√≥n (ver 3.7.4 de Murphy Advanced, McElreath y BDA aunque est√° medio confuso)\n\nlppd (log pointwise predictive density): promedio del score¬†predictivo a trav√©s de los posibles valores de \\(\\theta\\)\n\\[\nlppd = \\sum_{i=1}^{N} \\log \\left( \\int p\\left(y_i\\mid\\theta\\right) p_{post}(\\theta) d\\theta \\right)\n\\]\n\\[\nlppd = \\sum_{i=1}^{N} \\log \\left( \\frac{1}{S} \\sum_{i=1}^{S} p\\left(y_i\\mid\\theta^{(s)}\\right) \\right)\n\\]\nPSIS\n\n\n\n\nRegresi√≥n Log√≠stica\n\nModelo para clasificaci√≥n (creo que podemos trabajarlo bien siguiendo Bayes Rules!)\nSimulaci√≥n\nInterpretaci√≥n de coeficientes\nExceso de ceros (ver ejemplo de Bayes Rules! y Negative Binomial)\n\n\n\nRegresi√≥n Poisson\n\nModelo para datos de conteo (creo que podemos trabajarlo bien siguiendo Bayes Rules!)\nSimulaci√≥n\n\n\n\nEnfoque multinivel\n\nModelo beta-binomial jer√°rquico (ver Kruschke)\nShrinkage de par√°metros\nEjemplo de uranio de Gelman: no pooling vs complete pooling vs partial pooling\nEjemplo de las ranas de McElreath:\nEjemplo de las canciones (Bayes Rules!)\nEjemplo de la carrera de Washington (Bayes Rules!)\nModelos jer√°rquicos con predictores (Cap√≠tulo 17 de Bayes Rules)\n\nVariaci√≥n en el intercepto\nVariaci√≥n en la pendiente\n\nProblemas de estimaci√≥n\nOpcional: regresi√≥n log√≠stica jer√°rquica y regresi√≥n Poisson jer√°rquica (ver ejemplo de Bayes Rules! y de un paper de Paul Burkner sobre pesca (?))"
  },
  {
    "objectID": "info/aprobacion.html",
    "href": "info/aprobacion.html",
    "title": "Condiciones de aprobaci√≥n",
    "section": "",
    "text": "Instancias de evaluaci√≥n\n\nüìù Parcial ‚Äì escrito e individual, se aprueba con 6, hay una instancia de recuperaci√≥n;\nüíªüíªüíª Trabajos pr√°cticos cortos ‚Äì grupales (hasta tres personas), se hacen por fuera del horario de clase, se entrega informe;\nüìà Trabajo pr√°ctico final ‚Äì realizaci√≥n grupal, defensa individual.\n\n\n\nCondiciones de aprobaci√≥n\n\nPromoci√≥n\n\nLas y los estudiantes que hayan aprobado el parcial o su recuperatorio (con nota \\(P\\)), los tres trabajos pr√°cticos cortos (con promedio simple \\(T\\)) y hayan entregado el trabajo pr√°ctico final, acceder√°n a una instancia de evaluaci√≥n oral donde se discutir√° el trabajo pr√°ctico final y se evaluar√°n de manera general todos los contenidos conceptuales de la asignatura; esta instancia puede incluir la realizaci√≥n de algunas actividades en computadora (el trabajo pr√°ctico final y la instancia oral tendr√°n nota \\(O\\)).\nLa nota final se obtendr√° seg√∫n \\(0.3\\ T + 0.4\\ P + 0.3\\ O\\)\n\nRegularidad\n\nQuienes no alcancen la condici√≥n de promoci√≥n podr√°n quedar en condici√≥n de estudiante regular si aprueban el parcial o su recuperatorio y aprueban al menos dos de los trabajos pr√°cticos cortos. Para alcanzar la aprobaci√≥n de la asignatura, los y las estudiantes en condici√≥n de regulares deber√°n presentar el trabajo final en una mesa de examen y aprobar una instancia oral de defensa del trabajo y de evaluaci√≥n integral de los contenidos de la materia. Esta instancia puede incluir la realizaci√≥n de algunas actividades en computadora.\n\nLibres\n\nAquellas personas que no alcancen la promoci√≥n de la asignatura ni la condici√≥n de estudiante regular quedar√°n en condici√≥n de estudiante libre. Los y las estudiantes en condici√≥n de libre deber√°n presentar un trabajo pr√°ctico y rendir un examen te√≥rico-pr√°ctico sobre la totalidad de los temas de la asignatura."
  },
  {
    "objectID": "info/docentes.html",
    "href": "info/docentes.html",
    "title": "Estad√≠stica Bayesiana",
    "section": "",
    "text": "Docentes"
  },
  {
    "objectID": "info/faq.html",
    "href": "info/faq.html",
    "title": "Estad√≠stica Bayesiana",
    "section": "",
    "text": "Preguntas frecuentes\n\nPertenezo al plan 2003 de la carrera, ¬øpuedo participar de las clases?\nSi, pod√©s asistir a las clases como oyente y tambi√©n realizar los trabajos pr√°cticos. Sin embargo, los profesores no se comprometen a realizar devoluciones o correcciones sobre los trabajos de estudiantes que asistan en calidad de oyente."
  },
  {
    "objectID": "info/calendario.html",
    "href": "info/calendario.html",
    "title": "Calendario",
    "section": "",
    "text": "Semana\nFecha\nUnidad\nTemas\nApunte\nLectura sugerida\nOtras actividades\n\n\n\n\n1\n20 de marzo\n1\n‚Ä¢ Presentaci√≥n de la materia‚Ä¢ Probabilidad‚Ä¢ Regla de Bayes\n\n‚Ä¢ McElreath (2020): Cap√≠tulo 1‚Ä¢ Kruschke (2014): Cap√≠tulo 4\n\n\n\n2\n27 de marzo\n1, 2\n‚Ä¢ Inferencia bayesiana‚Ä¢ Distribuci√≥n a priori, funci√≥n de verosimilitud y distribuci√≥n a posteriori‚Ä¢ Modelos conjugados\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulos 1, 3, 4, 5 y 8‚Ä¢ Kruschke (2014): Cap√≠tulos 1, 5 y 6‚Ä¢ McElreath (2020): Cap√≠tulo 2\n\n\n\n3\n3 de abril\n2\n‚Ä¢ Modelos de varios par√°metros\n\n‚Ä¢ Gelman et¬†al. (2013): Cap√≠tulo 3\nPresentaci√≥n TP1 (5-abr)\n\n\n4\n10 de abril\n2, 3\n‚Ä¢ Nociones de Teoria de Decisi√≥n Bayesiana‚Ä¢ Limitaciones del enfoque anal√≠tico‚Ä¢ Simulaciones‚Ä¢ Aproximaci√≥n grilla\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 6‚Ä¢ McElreath (2020): Cap√≠tulo 3\n\n\n\n5\n17 de abril\n3\n‚Ä¢ Introducci√≥n al c√≥mputo bayesiano‚Ä¢ Markov-chain Montecarlo‚Ä¢ Metropolis-Hastings\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 7‚Ä¢ Kruschke (2014): Cap√≠tulo 7\nEntrega TP1 (19-abr)  Presentaci√≥n TP2 (19-abr)\n\n\n6\n24 de abril\n3\n‚Ä¢ Programaci√≥n probabil√≠stica‚Ä¢ Stan‚Ä¢ Diagn√≥sticos‚Ä¢ Visualizaciones‚Ä¢ Hamiltonian Montecarlo\n\n‚Ä¢ Kruschke (2014): Cap√≠tulo 14\n\n\n\n7\n1 de mayo\n4\n‚Ä¢ Modelos lineales‚Ä¢ Paquete brms\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 9‚Ä¢ McElreath (2020): Cap√≠tulo 4‚Ä¢ Gelman y Hill (2006): Cap√≠tulos 3 y 4‚Ä¢ Gelman, Hill, y Vehtari (2021): Cap√≠tulos 6, 7 y 8\nEntrega TP2 (3-may)\n\n\n8\n8 de mayo\n4\n‚Ä¢ Regularizaci√≥n\n\n\n\n\n\n9\n15 de mayo\n4\n‚Ä¢ Selecci√≥n de modelos‚Ä¢ Criterios de informaci√≥n‚Ä¢ Validaci√≥n cruzada‚Ä¢ Sobreajuste y subajuste\n\n‚Ä¢ Gelman, Hill, y Vehtari (2021): Cap√≠tulo 11‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 10‚Ä¢ McElreath (2020): Cap√≠tulo 7\nParcial (15-may)  Presentaci√≥n TP3 (17-may)\n\n\n10\n22 de mayo\n5\n‚Ä¢ Regresi√≥n log√≠stica\n\n‚Ä¢ Gelman, Hill, y Vehtari (2021): Cap√≠tulo 13‚Ä¢ Gelman y Hill (2006): Cap√≠tulo 5‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 13\n\n\n\n11\n29 de mayo\n5\n‚Ä¢ Regresi√≥n Poisson\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 12‚Ä¢ Gelman y Hill (2006): Cap√≠tulo 6‚Ä¢ Gelman, Hill, y Vehtari (2021): Cap√≠tulo 15\nEntrega TP3 (31-may)  Recuperatorio (2-jun)\n\n\n12\n5 de junio\n5\n‚Ä¢ Enfoque multinivel‚Ä¢ Modelos jer√°rquicos‚Ä¢ Shrinkage de par√°metros\n\n‚Ä¢ Kruschke (2014): Cap√≠tulo 9‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulos 15 y 16‚Ä¢ McElreath (2020): Cap√≠tulo 13‚Ä¢ Gelman y Hill (2006): Cap√≠tulo 11\nPresentaci√≥n TP Final\n\n\n13\n12 de junio\n5\n‚Ä¢ Modelos lineales jer√°rquicos‚Ä¢ Variaci√≥n en el intercepto‚Ä¢ Variaci√≥n en la pendiente‚Ä¢ Problemas de estimaci√≥n\n\n‚Ä¢ Johnson, Ott, y Dogucu (2022): Cap√≠tulo 17‚Ä¢ Gelman y Hill (2006): Cap√≠tulos 12 y 13\n\n\n\n14\n19 de junio\n\n\n\n\n\n\n\n15\n26 de junio\n\n\n\n\nEntrega TP Final + Defensa oral\n\n\n\n\n\n\n\n\n\n\nReferencias\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "info/programa.html",
    "href": "info/programa.html",
    "title": "Programa",
    "section": "",
    "text": "Fundamentaci√≥n\nLa Estad√≠stica Bayesiana es un enfoque de la inferencia estad√≠stica que se basa en utilizar probabilidades para representar el conocimiento disponible sobre el conjunto de par√°metros de un modelo y actualizar esa informaci√≥n utilizando la Regla de Bayes a partir de la observaci√≥n de un conjunto de datos. El conocimiento inicial se representa con una distribuci√≥n de probabilidad a priori, la informaci√≥n contenida en los datos observados se modeliza con una funci√≥n de verosimilitud y ambas fuentes de informaci√≥n se combinan para obtener una distribuci√≥n de probabilidad a posteriori. La informaci√≥n a posteriori puede ser utilizada para extraer conclusiones sobre el fen√≥meno en estudio y realizar predicciones sobre datos no observados o eventos futuros.\nLos m√©todos bayesianos requieren, salvo en casos muy simples, una complejidad computacional que resultaba inalcanzable hace algunos a√±os. Gracias a desarrollos revolucionarios en el √°mbito de la computaci√≥n, la principal barrera para la implementaci√≥n de los modelos bayesianos desapareci√≥ y la utilizaci√≥n de estos se ha incrementado masivamente en m√∫ltiples campos cient√≠ficos. Esta creciente popularidad se debe a que la inferencia bayesiana brinda un marco te√≥rico consistente que permite la incorporaci√≥n de informaci√≥n a priori, el desarrollo de un aprendizaje secuencial, la obtenci√≥n de inferencias y predicciones en forma de distribuciones de probabilidad, el tratamiento de datos faltantes, los an√°lisis con pocos datos, entre otras ventajas.\n\n\nObjetivos\nQue quienes cursen la materia logren:\n\nentender las caracter√≠sticas y los conceptos fundamentales de la Estad√≠stica Bayesiana;\ndescribir las caracter√≠sticas principales de la Estad√≠stica Bayesiana;\ncomprender la complejidad anal√≠tica de la inferencia bayesiana y la necesidad de la utilizaci√≥n de un enfoque computacional para superar estas dificultades;\nser capaces de aplicar m√©todos bayesianos a problemas reales utilizando software espec√≠fico; e\ninterpretar los resultados del proceso de an√°lisis bayesiano de datos.\n\n\n\nContenidos\n\nUnidad 1: Introducci√≥n y Fundamentos de la Estad√≠stica Bayesiana\n\nProbabilidad para cuantificar la incertidumbre. Modelos de probabilidad. Regla de Bayes. Inferencia bayesiana. Distribuci√≥n a priori, funci√≥n de verosimilitud, distribuci√≥n a posteriori.\n\nUnidad 2: Inferencia Bayesiana\n\nModelos de distribuciones conjugadas. Modelos de un par√°metro. Modelo beta-binomial. Enfoque intuitivo. Distribuci√≥n a posteriori como compromiso entre la verosimilitud y la distribuci√≥n a priori. Razonamiento secuencial. Modelo normal-normal. Modelo gamma‚ÄìPoisson. Modelos de varios par√°metros. Modelo normal ‚Äì normal-gamma-inversa. Modelo Dirichlet‚Äìmultinomial.\nElecci√≥n de distribuciones a priori: no informativas (impropias, de Jeffrey) y d√©bilmente informativas. Medidas de resumen de la distribuci√≥n a posteriori. Intervalos de credibilidad. Distribuci√≥n predictiva a posteriori. Nociones de teor√≠a de la decisi√≥n bayesiana. Riesgo bayesiano. Estimador de Bayes.\n\nUnidad 3: M√©todos Computacionales\n\nLimitaciones del enfoque anal√≠tico: c√°lculo de probabilidades y determinaci√≥n de la distribuci√≥n a posteriori. Soluciones: an√°lisis de datos simulados y aproximaci√≥n de grilla. Introducci√≥n al c√≥mputo bayesiano. Nociones b√°sicas de m√©todos de cadenas de Markov ‚Äì Montecarlo (MCMC). Algoritmo de Metropolis‚ÄìHastings. Montecarlo Hamiltoniano. Diagn√≥stico de m√©todos MCMC.\nProgramaci√≥n probabil√≠stica. Alternativas. Sintaxis de modelos. Ejemplos. Diagn√≥stico. Medidas de resumen a partir de las cadenas obtenidas. Visualizaciones.\n\nUnidad 4: Modelos Lineales\n\nModelos lineales. Elecci√≥n de distribuciones a priori. Regularizaci√≥n. Diagn√≥stico de modelos. Predicciones basadas en distribuciones de probabilidad. Pruebas predictivas a priori y a posteriori. Densidad predictiva a posteriori logar√≠tmica evaluada punto a punto (lppd). Deviance. Criterios de informaci√≥n: AIC, BIC, WAIC. Validacion cruzada. Sobreajuste y subajuste. Validaci√≥n cruzada utilizando muestreo por importancia mediante suavizado Pareto (PSIS-CV).\n\nUnidad 5: Modelos Avanzados\n\nRegresi√≥n log√≠stica. Regresi√≥n Poisson. Comparaci√≥n de grupos. Modelos de variable latente. Formulaci√≥n gr√°fica. An√°lisis de sensibilidad.\nEl enfoque multinivel: modelos jer√°rquicos. Modelo beta-binomial jer√°rquico. Shrinkage de par√°metros. Variaci√≥n en el intercepto. Variaci√≥n en la pendiente. Pooling de estimaciones. Problemas de estimaci√≥n."
  },
  {
    "objectID": "info/bibliografia.html",
    "href": "info/bibliografia.html",
    "title": "Bibliograf√≠a",
    "section": "",
    "text": "Bibliograf√≠a principal\n\nJohnson, Ott, y Dogucu (2022) McElreath (2020) Gelman y Hill (2006) Kruschke (2014) Reich y Ghosh (2019)\n\n\n\nGelman, Andrew, y Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel-Hierarchical Models. 1st edition. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Q. Ott, y Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling. 1st edition. Chapman; Hall/CRC. https://www.bayesrulesbook.com/.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. 2nd edition. Academic Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC.\n\n\n\n\nBibliograf√≠a complementaria\n\nGelman et¬†al. (2013), Gelman, Hill, y Vehtari (2021), Downey (2021), Lee y Wagenmakers (2014), Davidson-Pilon (2015), Nicenboim, Schad, y Vasishth (2022), Barr (2021), Carlin y Louis (2008), Hoff (2009), MacKay (2003), Lambert (2018), Murphy (2022), Murphy (2023), Bishop (2006), Martin, Kumar, y Lao (2021), Theoridis (2020), Clyde et¬†al. (2022), Ma, Kording, y Goldreich (2022)\n\n\n\n\n\nBarr, Dale J. 2021. Learning statistical models through simulation in R: An interactive textbook. 1st edition. https://psyteachr.github.io/stat-models-v1/.\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. 1st edition. Springer.\n\n\nCarlin, Bradley P., y Thomas A. Louis. 2008. Bayesian Methods for Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nClyde, Merlise, Mine √áetinkaya-Rundel, Colin Rundel, David Banks, Christine Chai, y Lizzy Huang. 2022. An Introduction to Bayesian Thinking. 1st edition. https://statswithr.github.io/book/.\n\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nDowney, Allen B. 2021. Think Bayes: Bayesian Statistics in Python. 2nd edition. O‚ÄôReilly Media. http://allendowney.github.io/ThinkBayes2/.\n\n\nGelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, y Donald B. Rubin. 2013. Bayesian Data Analysis. 3rd edition. Chapman; Hall/CRC.\n\n\nGelman, Andrew, Jennifer Hill, y Aki Vehtari. 2021. Regression and Other Stories. 1st edition. Cambridge University Press. https://users.aalto.fi/~ave/ROS.pdf.\n\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nLambert, Ben. 2018. A Student‚Äôs Guide to Bayesian Statistics. 1st edition. SAGE Publications Ltd.\n\n\nLee, Michael D., y Eric-Jan Wagenmakers. 2014. Bayesian Cognitive Modeling: A Practical Course. 1st edition. Cambridge University Press.\n\n\nMa, Wei Ji, Konrad P. Kording, y Daniel Goldreich. 2022. Bayesian Models of Perception and Action: An Introduction. 3rd edition. http://www.cns.nyu.edu/malab/bayesianbook.html.\n\n\nMacKay, David J. C. 2003. Information Theory, Inference and Learning Algorithms. 1st edition. Cambridge University Press.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/.\n\n\nMurphy, Kevin P. 2023. Probabilistic Machine Learning: Advanced Topics. 1st edition. The MIT Press. https://probml.ai/.\n\n\nNicenboim, Bruno, Daniel Schad, y Shravan Vasishth. 2022. An Introduction to Bayesian Data Analysis for Cognitive Science. https://vasishth.github.io/bayescogsci/book/.\n\n\nTheoridis, Sergios. 2020. Machine Learning: A Bayesian and Optimization Perspective. 2nd edition. Academic Press."
  },
  {
    "objectID": "info/enlaces_utiles.html",
    "href": "info/enlaces_utiles.html",
    "title": "Enlaces √∫tiles",
    "section": "",
    "text": "Awesome Bayesian Statistics. Es un listado de recursos en l√≠nea (y gratuitos!) relacionados al mundo de la Estad√≠stica Bayesiana."
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html",
    "href": "trabajos_practicos/02_tp2.html",
    "title": "TP2: Implementaci√≥n del algoritmo de Metropolis-Hastings",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "href": "trabajos_practicos/02_tp2.html#metropolis-hastings-en-2d",
    "title": "TP2: Implementaci√≥n del algoritmo de Metropolis-Hastings",
    "section": "Metropolis-Hastings en 2D",
    "text": "Metropolis-Hastings en 2D\nSe desean tomar muestras de una normal bivariada asim√©trica cuya funci√≥n de densidad viene dada por\n\\[\nf(\\mathbf{x}) =\n    2\\ \\phi_2(\\mathbf{x} \\mid \\mathbf{0}, \\pmb{\\Omega})\n    \\ \\Phi(\\pmb{\\alpha}^T\\mathbf{x})\n    \\qquad \\mathbf{x} \\in \\mathbb{R}^2\n\\]\nsiendo \\(\\phi_2(\\mathbf{x}\\mid\\mathbf{0},\\mathbf{\\Omega})\\) la funci√≥n de densidad de la normal bivariada de media \\(\\mathbf{0}\\) y matriz de covarianza \\(\\mathbf{\\Omega}\\), \\(\\Phi(\\pmb{\\alpha}^T\\mathbf{x})\\) es la funci√≥n de probabilidad acumulada de la normal est√°ndar \\(\\mathcal{N}(0,1)\\) y \\(\\pmb{\\alpha} \\in \\mathbb{R}^2\\) es un vector de par√°metros.\n\nEn este caso, se tiene:\n\\[\n\\mathbf{\\Omega} = \\begin{bmatrix}1.5 & 0.6 \\\\ 0.6 & 1.5 \\end{bmatrix}\n\\]\ny\n\\[\n\\pmb{\\alpha} = [2 \\quad 0]\n\\]\n\n\n\n\n\nFunci√≥n de densidad de la que se desean obtener muestras\n\n\n\n\n\nEscriba una funci√≥n que implemente el algoritmo de Metropolis-Hastings para tomar muestras de una funci√≥n de probabilidad bivariada dada. Separe en funciones cada una de los pasos del algoritmo. La probabilidad de salto ser√° normal bivariada de matriz de covarianza variable. Otorgue flexibilidad al algoritmo haciendo que reciba como argumento la matriz de covarianza de la probabilidad de transici√≥n.\n\nSe utilizar√° una normal bivariada para proponer un salto en el algoritmo de Metropolis-Hastings. Se explorar√° el efecto de diferentes distribuciones de probabilidad para el salto, en funci√≥n de diferentes matrices de covarianza \\(\\mathbf{\\Sigma}\\). Si se representa a \\(\\mathbf{\\Sigma}\\) de la siguiente manera\n\\[\n\\mathbf{\\Sigma} =\n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n    \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1\\end{bmatrix}  \n    \\begin{bmatrix} \\sigma_1 & 0 \\\\ 0 & \\sigma_2 \\end{bmatrix}\n\\]\ndonde \\(\\sigma_i\\) representa el desv√≠o est√°ndar de la componente \\(i\\) y \\(\\rho\\) la correlaci√≥n entre las variables \\(X_1\\) y \\(X_2\\), entonces se deber√°n ensayar los siguientes casos:\n\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 > \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 < \\sigma_2\\) y \\(\\rho = 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho > 0\\)\n\\(\\sigma_1 = \\sigma_2\\) y \\(\\rho < 0\\)\n\nTO DO: Hacer gr√°ficos\n\nPara al menos dos de los cinco casos anteriores, comparar las trayectorias seguidas por las cadenas al obtener muestras de \\(f(x)\\)."
  },
  {
    "objectID": "trabajos_practicos/02_tp2.html#aplicaci√≥n-tiempo-de-reacci√≥n-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "href": "trabajos_practicos/02_tp2.html#aplicaci√≥n-tiempo-de-reacci√≥n-humano-proponer-un-prior-para-sigma-y-uno-para-mu",
    "title": "TP2: Implementaci√≥n del algoritmo de Metropolis-Hastings",
    "section": "Aplicaci√≥n: ¬øtiempo de reacci√≥n humano? ¬øproponer un prior para sigma y uno para mu?",
    "text": "Aplicaci√≥n: ¬øtiempo de reacci√≥n humano? ¬øproponer un prior para sigma y uno para mu?"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html",
    "href": "trabajos_practicos/01_tp1.html",
    "title": "TP1: Aplicaci√≥n de modelos conjugados a reviews de Google Maps",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuci√≥n-de-dirichlet",
    "href": "trabajos_practicos/01_tp1.html#descubriendo-la-distribuci√≥n-de-dirichlet",
    "title": "TP1: Aplicaci√≥n de modelos conjugados a reviews de Google Maps",
    "section": "Descubriendo la distribuci√≥n de Dirichlet",
    "text": "Descubriendo la distribuci√≥n de Dirichlet\nLa distribuci√≥n Dirichlet es en realidad una familia de distribuciones. Se trata de una familia de distribuciones de probabilidad continuas y multivariadas. La distribuci√≥n de Dirichlet en \\(K \\geq 2\\) es la distribuci√≥n de probabilidad del vector aleatorio \\(X=[X_1, X_2 \\dots, X_K]\\) dimensiones tiene como par√°metro al vector \\(\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\dots,\\alpha_K]\\).\n\\[\nf(x_1,x_2,\\dots,x_k \\mid \\alpha_1, \\alpha_2,\\dots,\\alpha_K) =\n    \\frac{1}{B(\\pmb{\\alpha})} \\prod_{i=1}^K x_i^{\\alpha_i-1}\n\\]\ndonde los \\(\\alpha_i \\in \\mathbb{R}^+\\) y \\(B(\\pmb{\\alpha})\\) es la constante que hace que la integral sea unitaria.\nEl soporte de la distribuci√≥n Dirichlet es tal que \\(\\sum_{i=1}^{K} x_i = 1\\) y \\(x_i \\in [0,1]\\). Es decir, los \\(x_i\\) suman 1. Si consideramos, por ejemplo, \\(K=3\\), el vector \\([x_1, x_2, x_3]\\) pertenece al tri√°ngulo en \\(\\mathbb{R}^3\\) que tiene por v√©rtices a los puntos \\((1,0,0)\\), \\((0,1,0)\\) y \\((0,0,1)\\). As√≠, si \\(x_1=1\\) entonces \\(x_2=x_3=0\\).\nM√°s simple a√∫n, cuando \\(K=2\\), el vector \\([x_1,x_2]\\) pertenece al segmento en \\(\\mathbb{R}^2\\) que tiene por extremos a los puntos \\((1,0)\\) y \\((0,1)\\).\nNotar que esta caracter√≠stica hace que los \\(x_1, x_2, \\dots, x_K\\) puedan representar las probabilidades de un experimento con \\(K\\) resultados posibles.\nA t√≠tulo informativo, el soporte de la distribuci√≥n Dirichlet en \\(K\\) dimensiones es lo que se conoce como simplex (est√°ndar) de \\(K-1\\) dimensiones. El \\(3\\)-simplex es un tri√°ngulo y el \\(2\\)-simplex es un segmento. En general, un \\(K-1\\)-simplex es la envolvente convexa de \\(K\\) v√©rtices y, a su vez, es la colecci√≥n de todas las combinaciones convexas de puntos en el conjunto (Teorema de Carath√©odory).\nLos p√°rrafos anteriores, delirantemente matem√°ticos, muestran una virtud particular de la distribuci√≥n Dirichlet de \\(K=3\\) dimensiones. Esta distribuci√≥n, a pesar de ser de una variable aleatoria en \\(\\mathbb{R}^3\\), puede representarse perfectamente de manera gr√°fica en dos dimensiones (aunque utilizando un sistema de coordenadas peculiar: las coordenadas baric√©ntricas), como si se tratara de una distribuci√≥n bivariada.\n\n\n\n\n\nComo los valores posibles del vector aleatorio tridimensional yacen en un plano, la distribuci√≥n de probabilidad puede representarse gr√°ficamente con facilidad\n\n\n\n\n\n\nMostrar que, cuando \\(K=2\\), la distribuci√≥n de Dirichlet es la distribuci√≥n beta de par√°metros \\(a=\\alpha_1\\) y \\(b=\\alpha_2\\)"
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#relaci√≥n-entre-la-distribuci√≥n-dirichlet-y-la-multinomial",
    "href": "trabajos_practicos/01_tp1.html#relaci√≥n-entre-la-distribuci√≥n-dirichlet-y-la-multinomial",
    "title": "TP1: Aplicaci√≥n de modelos conjugados a reviews de Google Maps",
    "section": "Relaci√≥n entre la distribuci√≥n Dirichlet y la multinomial",
    "text": "Relaci√≥n entre la distribuci√≥n Dirichlet y la multinomial\nCuando un experimento puede tener dos resultados posibles, uno de ellos tiene probabilidad \\(p\\) y el otro probabilidad \\(1-p\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el n√∫mero de √©xitos es una variable aleatoria con distribuci√≥n binomial. Estudiamos que era natural utilizar la distribuci√≥n beta como distribuci√≥n a priori para \\(p\\), dado que la distribuci√≥n a posteriori¬†tambi√©n era beta.\nAn√°logamente, cuando un experimento puede tener tres resultados posibles, el primero tiene probabilidad \\(p_1\\), el segundo tiene probabilidad \\(p_2\\) y el tercero, probabilidad \\(p_3 = p_1 - p_2\\). Necesariamente debe ser \\(p_1 + p_2 + p_3 = 1\\). Si coleccionamos \\(N\\) realizaciones independientes del experimento, el n√∫mero de ocurrencias de cada resultado posible es un vector aleatorio con distribuci√≥n multinomial. Por lo visto hasta aqu√≠, todo parece indicar que, si queremos realizar inferencias sobre \\(p_1\\), \\(p_2\\) y \\(p_3\\), ser√≠a natural utilizar la distribuci√≥n Dirichlet de tres dimensiones como distribuci√≥n a priori para las probabilidades‚Ä¶\nEn efecto, cuando la distribuci√≥n a priori es Dirichlet y la verosimilitud es multinomial, la distribuci√≥n a posteriori tambi√©n es Dirichlet.\n\nSabemos que para una verosimilitud binomial, si la distribuci√≥n a priori de la probabilidad de √©xito \\(p\\) es beta de par√°metros \\(a\\) y \\(b\\) y se observan \\(s\\) √©xitos en \\(N\\) intentos independientes, la distribuci√≥n a posteriori es beta de par√°metros \\(a' = a + s\\) y \\(b' = b + (N - s)\\).\nHallar, por analog√≠a con el caso anterior, los par√°metros de la distribuci√≥n a posteriori que se obtiene si la verosimilitud es multinomial con tres resultados posibles, la distribuci√≥n a priori¬†es Dirichlet de par√°metros \\([\\alpha_1, \\alpha_2, \\alpha_3]\\) y se obtuvieron \\(s_1\\) veces el primer resultado y \\(s_2\\) veces el segundo resultado, sobre un total de \\(N\\) intentos."
  },
  {
    "objectID": "trabajos_practicos/01_tp1.html#aplicaci√≥n",
    "href": "trabajos_practicos/01_tp1.html#aplicaci√≥n",
    "title": "TP1: Aplicaci√≥n de modelos conjugados a reviews de Google Maps",
    "section": "Aplicaci√≥n",
    "text": "Aplicaci√≥n\nAsumiremos ahora que las reviews de un local tienen distribuci√≥n multinomial de par√°metros \\([p_1, p_2, \\dots, p_5]\\). Es decir, la probabilidad de que un usuario asigne 1‚≠ê es \\(p_1\\), de que asigne 2‚≠ê es \\(p_2\\), y as√≠ sucesivamente. Llamaremos \\(n_1\\) al n√∫mero de calificaciones de 1‚≠ê, \\(n_2\\) al n√∫mero de calificaciones de 2‚≠ê, y as√≠ sucesivamente. \\(n_1 + n_2 + n_3 + n_4 + n_5 = N\\) ser√° el n√∫mero total de reviews.\nSe puede verificar que el n√∫mero esperado de reviews de \\(i\\)‚≠ê ser√° \\(N p_i\\). Por lo tanto, la puntuaci√≥n esperada ser√°:\n\\[\n\\frac{1}{N} (1\\cdot N p_1 + 2\\cdot N p_2 + 3\\cdot N p_3 + 4\\cdot N p_4 +5\\cdot N p_5) =\n    \\sum_{i=1}^5 i \\cdot p_i\n\\]\n\nElija dos combinaciones de posibles valores de \\(p_i\\) que den un valor esperado de 4.1‚≠ê. Piense en una combinaci√≥n que represente acuerdo entre los clientes y otra que indique la presencia de opiniones dispares.\nEscriba una funci√≥n que, dada una combinaci√≥n de valores de \\(p_i\\), simule el proceso de calificaci√≥n de un cliente.\nConstruya una funci√≥n que simule la calificaci√≥n de \\(U\\) clientes.\nSimule 1000 veces el proceso de 15 clientes que eval√∫an una cafeter√≠a de 4.1‚≠ê y el proceso de 100 clientes que eval√∫an la misma cafeter√≠a. ¬øQu√© se observa?\n\nUtilizaremos este nuevo modelo para realizar inferencias sobre las puntuaciones de Arto y Orlan.\n\nLos datos se generan siguiendo una distribuci√≥n multinomial. ¬øCu√°les son los par√°metros de esa distribuci√≥n multinomial? ¬øQu√© distribuci√≥n a priori ser√≠a conveniente utilizar? ¬øC√≥mo est√° parametrizada esa distribuci√≥n a priori?\nElija los par√°metros de la distribuci√≥n a priori de modo tal que la creencia inicial sea uniforme sobre los posibles valores de los \\(p_i\\). ¬øQu√© implicancias tiene para la puntuaci√≥n en ‚≠ê la distribuci√≥n a priori elegida?\nCon los datos de la introducci√≥n, obtenga la distribuci√≥n a posteriori de los \\(p_i\\) para cada cafeter√≠a.\n¬øCu√°l es la probabilidad de que Orlan sea mejor que Arto?"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html",
    "href": "trabajos_practicos/03_tp3.html",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#simulaciones",
    "href": "trabajos_practicos/03_tp3.html#simulaciones",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Simulaciones",
    "text": "Simulaciones\nEl archivo ‚Ä¶ contiene 100 observaciones que se usar√°n para identificar los par√°metros de un modelo, mientras que el archivo ‚Ä¶ tiene 20 observaciones que se usar√°n para evaluar los resultados del proceso de inferencia.\nSe sabe que los datos fueron generados utilizando un modelo de la forma:\n\\[\ny_i \\sim \\mathcal{N}(\\theta_3 x_i^3 + \\theta_2 x_i^2 + \\theta_1 x_i + \\theta_0, \\sigma^2)\n\\]\naunque no se conocen los valores de los \\(\\theta_i\\) ni de \\(\\sigma\\)\nEn primer lugar, se estudiar√° el efecto de la cantidad de datos utilizados para el ajuste del modelo.\n\nUtilizando priors vagos para los par√°metros del modelo, analice los resultados obtenidos al utilizar 10, 20, 50 o 100 observaciones de los datos de entrenamiento. Compare las distribuciones a posteriori de los par√°metros y las predicciones sobre los datos de test.\n\nEn segundo lugar, se investigar√° qu√© efecto tiene la elecci√≥n de distribuciones a priori centradas en valores err√≥neos de los par√°metros de la regresi√≥n.\n\nConsidere las siguientes distribuciones a priori [‚Ä¶]. Compare, como hizo en el caso anterior, los resultados en las estimaciones utilizando 10, 20, 50 y 100 observaciones.\n\nFinalmente, se considera el caso donde se propone un modelo err√≥neo.\n\nUtilizando priors vagos, ajuste polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Compare gr√°ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaci√≥n. ¬øQu√© ocurre si se utilizan todos los datos?\nUtilice ahora priors de regularizaci√≥n (centrados en 0) para polinomios de grado 3, 4, 5 y 6 utilizando 20 observaciones. Pruebe diferentes grados de regularizaci√≥n. Compare gr√°ficamente el ajuste en los datos de entrenamiento con el ajuste en los datos de evaluaci√≥n.\nEscriba una funci√≥n que calcule el lppd para un conjunto de observaciones. Compare lppd para los polinomios de grados 3, 4, 5 y 6 ajustados con 20 observaciones. Compare la m√©trica utilizando los datos de entrenamiento y de evaluaci√≥n."
  },
  {
    "objectID": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "href": "trabajos_practicos/03_tp3.html#enfriamiento-de-agua-en-un-termo",
    "title": "TP3: Estudio de modelos lineales mediante simulaciones",
    "section": "Enfriamiento de agua en un termo",
    "text": "Enfriamiento de agua en un termo\nEn un pa√≠s matero como Argentina, era de esperarse que aparecieran casi tantos termos como personas. Es dif√≠cil decir si la cantidad de variantes de termos en el mercado nacional cambi√≥, pero es indudable que, tras el furor del termo color verde militar, la elecci√≥n de un termo adquiri√≥ un papel relevante en el ritual del mate.\nDe acero, de vidrio, con capa aisladora. Diferentes configuraciones dan lugar a distintas capacidades de mantener la temperatura y, obviamente, a distintos rangos de precios. Dejando de lado la cuesti√≥n monetaria, centr√©monos en estudiar c√≥mo var√≠a la temperatura de un l√≠quido en el interior de un termo en funci√≥n del tiempo transcurrido.\nLa temperatura es una medida del grado de agitaci√≥n de las part√≠culas de una sustancia. Un l√≠quido (o s√≥lido, o gas) est√° m√°s caliente que otro si sus part√≠culas tienen (en promedio) mayor grado de agitaci√≥n. Sabemos por evidencia emp√≠rica que si un cuerpo se pone en contacto con otro que tiene una temperatura menor, hay una transferencia de energ√≠a que hace que el primero se enfr√≠e y el segundo se caliente, hasta que alcanzan el denominado equilibrio t√©rmico.\nDe manera similar, esto es lo que ocurre con el agua que dejamos dentro del termo: en alg√∫n momento, llega al equilibrio t√©rmico con el ambiente. La salvedad necesaria ac√° es que, como el ambiente es grande, no aumenta su temperatura con la energ√≠a que pierde el agua del recipiente.\nAhora bien, el ritmo con el cual el agua caliente pierde energ√≠a no es constante. F√≠sicamente, mientras mayor sea la diferencia de temperatura entre dos cuerpos, m√°s r√°pido fluir√° la energ√≠a (y m√°s r√°pido cambiar√° la temperatura). Si estudiamos la temperatura del agua en el termo en funci√≥n del tiempo, notaremos que el ritmo con el que cambia decrece a medida con el que transcurre el tiempo.\nLa lectura del p√°rrafo anterior deber√≠a permitir asociar el concepto de ritmo de cambio con la noci√≥n matem√°tica de derivada. En efecto, la derivada de la temperatura respecto al tiempo var√≠a con el tiempo. En otras palabras, la pendiente no es constante.\nLas leyes que rigen el universo pueden muchas veces formularse en t√©rminos de lo que en matem√°tica se conoce como ecuaci√≥n diferencial. En este caso, la temperatura del agua en el termo satisface la siguiente ley:\n\\[\n\\frac{\\mathrm{d}T(t)}{\\mathrm{d}t} = r [T_{\\text{amb}}-T(t)]\n\\]\ndonde \\(T_{\\text{amb}}\\) es la temperatura ambiente (un valor fijo y conocido), \\(r\\) es una constante y \\(T(t)\\) es la funci√≥n (en principio desconocida) que describe la temperatura del agua del termo en funci√≥n del tiempo.\nNo se trata de una ecuaci√≥n algebraica donde la soluci√≥n es un valor num√©rico sino de una ecuaci√≥n donde la soluci√≥n es una funci√≥n. Buscamos una funci√≥n \\(T(t)\\) que satisfaga la ecuaci√≥n: su derivada debe cambiar con el valor que toma la funci√≥n.\nUna funci√≥n que satisface esa ecuaci√≥n es:\n\\[\nT(t) = T_{\\text{amb}} + (T_i - T_{\\text{amb}})e^{-rt}\n\\]\nsiendo \\(T_i\\) la temperatura a la que est√° inicialmente el agua en el termo (un valor fijo y conocido).\n\nVerificar que la funci√≥n anterior satisface la ecuaci√≥n diferencial\nGrafique \\(T(t)\\) para \\(T_{\\text{amb}} = 20 \\text{ C¬∞}\\) y \\(T_i = 90 \\text{ C¬∞}\\), para dos valores de \\(r\\), \\(r_1=0.1\\) y \\(r_2 = 0.3\\). ¬øQu√© representa \\(r\\)?\nSeg√∫n su experiencia con termos, ¬øcu√°l es un valor realista de \\(r\\)?\n\nEstudiaremos a continuaci√≥n un conjunto de mediciones de temperatura de agua en un termo en funci√≥n del tiempo transcurrido.\nLeonel tiene un termo Estanli‚Ñ¢ que compr√≥ por Amason y se dispone a despejar la duda de cualquier usuario de termos Estanli‚Ñ¢: ¬øcu√°nto dura el agua caliente? Pone agua en la pava el√©ctrica, la vierte en el termo y registra la temperatura en algunos momentos posteriores. Ese d√≠a, el reporte meteorol√≥gico indica una temperatura de \\(T_{\\text{amb}} = 23\\text{ C¬∞}\\). Las temperaturas que registr√≥ Leonel son las siguientes:\n\n\n\n\n \n  \n    t (h:mm) \n    T (¬∞C) \n  \n \n\n  \n    1:20 \n    92.0 \n  \n  \n    2:30 \n    90.5 \n  \n  \n    4:00 \n    81.4 \n  \n  \n    5:15 \n    80.8 \n  \n  \n    8:30 \n    74.2 \n  \n\n\n\n\n\nPara simplificar la construcci√≥n de un modelo, en lugar de considerar la temperatura del agua en el termo, se considerar√° la diferencia entre la temperatura del agua y la temperatura ambiente \\(T-T_{\\text{amb}}\\). Adem√°s, se llamar√° \\(T_{\\text{diff}}\\) a la diferencia de temperatura entre la temperatura inicial del agua y la temperatura ambiente \\(T_i - T_{\\text{amb}}\\).\n\\[\nT(t) - T_{\\text{amb}} = T_{\\text{diff}} e^{-rt}\n\\]\n\nVerifique que el logaritmo natural de la nueva variable (\\(T(t) - T_{\\text{amb}}\\)) es una funci√≥n lineal de \\(t\\).\n¬øQu√© representan \\(\\beta_0\\) y \\(\\beta_1\\)?\n\nAjustaremos un modelo lineal a los datos transformados.\n\nEn funci√≥n del enunciado del problema y de su conocimiento de termos, elija una distribuci√≥n a priori para \\(\\beta_0\\), \\(\\beta_1\\) y \\(\\sigma\\). ¬øCu√°les son las implicancias de sus distribuciones a priori? Realice pruebas predictivas a priori.\nAjuste el modelo lineal utilizando R\nEncontrar el posterior de \\(r\\), de \\(T_{\\text{diff}}\\) y de la temperatura inicial del agua \\(T_i\\)\nPredecir la temperatura a la que estar√° el agua transcurridas 12:00 h del inicio de la experiencia.\nHalle la distribuci√≥n a posteriori del tiempo que le toma al agua llegar a \\(30 \\text{ C¬∞}\\)"
  },
  {
    "objectID": "trabajos_practicos/00_tp0.html",
    "href": "trabajos_practicos/00_tp0.html",
    "title": "TP0: Distribuci√≥n de Rocklets azules",
    "section": "",
    "text": "Descargar PDF\n\n\nDistribuci√≥n de Rocklets azules"
  },
  {
    "objectID": "trabajos_practicos/descripcion.html",
    "href": "trabajos_practicos/descripcion.html",
    "title": "Generalidades",
    "section": "",
    "text": "Para aprobar la materia es necesario completar tres trabajos pr√°cticos cortos. La denominaci√≥n cortos hace referencia a que los trabajos son guiados y las tareas a realizar est√°n delimitadas.\nLos trabajos pr√°cticos tienen como objetivo repasar y afianzar los conocimientos adquiridos durante las clases, adquirir pr√°ctica en la aplicaci√≥n de conceptos trabajados, mejorar las habilidades de programaci√≥n y el uso de R, e incorporar algunos conceptos complementarios.\nCada trabajo pr√°ctico ser√° presentado y discutido en clase. Se destinar√° una fracci√≥n de la clase a comenzar a pensar algunas de las actividades.\nLa fecha de entrega de cada trabajo pr√°ctico ser√° de dos semanas luego de la fecha de presentaci√≥n. Se podr√° entregar el trabajo pr√°ctico una semana despu√©s de la fecha de entrega con una penalizaci√≥n del 25% de la nota final.\nPara cada trabajo pr√°ctico, cada grupo deber√° entregar un informe en formato pdf donde se resuelvan las actividades propuestas. El informe debe estar obligatoriamente elaborado utilizando \\(\\mathrm{\\LaTeX{}}\\) (a trav√©s de Quarto, RMarkdown o alguna otra variante). Tener en cuenta que los apartados presentados en el enunciado del trabajo pr√°ctico constituyen una gu√≠a de actividades a resolver y no deben responderse uno a uno como si se tratara de un cuestionario. El informe deber√° permitir una lectura fluida de los resultados y an√°lisis presentados. Cuando la resoluci√≥n de una problem√°tica consista en una funci√≥n o porci√≥n de c√≥digo en R, el c√≥digo deber√° mostrarse en el informe.\nSe evaluar√°n los siguientes aspectos del informe: presentaci√≥n, redacci√≥n (claridad, coherencia y cohesi√≥n), est√©tica, resultados obtenidos, profundidad del an√°lisis."
  },
  {
    "objectID": "complementario/variables.html",
    "href": "complementario/variables.html",
    "title": "Repaso de Variables Aleatorias",
    "section": "",
    "text": "Variables aleatorias\n\nDiscretas\nContinuas\n\nCDF\nPDF\nDistribucion conjunta\nDistribucion marginal\nDistribucion condicional\nIndependencia e independencia condicional\nMomentos de una distribucion\nRegla de Bayes\nDistribuciones de probabilidad frecuentemente utilizadas\nTransformacion de variables aleatorias\n\nPropiedades de transformaciones lineales\n\n\nEste listado esta sacado del capitulo 2 de Murphy (2022)\nTambien hay cosas interesantes en capitulo 3 de Murphy (2022)\n\nUncorrelated does not imply independent\nCorrelation does not imply causation\n\n\nPairwise independence does not imply mutual independence\nWe say that two random variables are pairwise independent if \\(p(X_2|X_1) = p(X_2)\\) and hence \\(p(X_2, X_1) = p(X_1)p(X_2|X_1) = p(X_1)p(X_2)\\)\nWe say that \\(n\\) random variables are mutually independent if \\(p(Xi|XS) = p(Xi)\\) \\(\\forall S \\subseteq \\{1, \\cdots , n\\}\\) and hence \\(\\displaystyle p(X_{1:n}) = \\prod_{i=1}^{n} p(X_i)\\)\nShow that pairwise independence between all pairs of variables does not necessarily imply mutual independence. It suffices to give a counter example.\nExercise 2.5 Murphy (2022)\nExercise 2.6 Murphy (2022)\nExercise 3.5 [Gaussian vs jointly Gaussian ]\n\n\n\n\n\nReferencias\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. 1st edition. The MIT Press. https://probml.ai/."
  },
  {
    "objectID": "computo/instalacion.html#rstan",
    "href": "computo/instalacion.html#rstan",
    "title": "Instalaci√≥n de herramientas computacionales",
    "section": "RStan",
    "text": "RStan\n\nWindows\n\n\nUbuntu\n\n\nMac OS\n\n\nVerificaci√≥n"
  },
  {
    "objectID": "computo/instalacion.html#librerias-adicionales",
    "href": "computo/instalacion.html#librerias-adicionales",
    "title": "Instalaci√≥n de herramientas computacionales",
    "section": "Librerias adicionales",
    "text": "Librerias adicionales\n\n{brms}\n{ggplot2}\n{dplyr}\n**Estaria bueno pinear las dependencias usando {here} o algo similar\n\n\nVerificaci√≥n"
  },
  {
    "objectID": "computo/instalacion.html#dependencias-optativas",
    "href": "computo/instalacion.html#dependencias-optativas",
    "title": "Instalaci√≥n de herramientas computacionales",
    "section": "Dependencias optativas",
    "text": "Dependencias optativas\n\nQuarto\n‚Ä¶ ?"
  },
  {
    "objectID": "presentaciones/01_clase1.html",
    "href": "presentaciones/01_clase1.html",
    "title": "Estad√≠stica Bayesiana",
    "section": "",
    "text": "Turn off alarm\nGet out of bed\n\n\n\n\n\n\n\n\nPay Attention\n\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\n\n\n\n\n\nPay Attention\n\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "presentaciones/01_clase1.html#slide-title",
    "href": "presentaciones/01_clase1.html#slide-title",
    "title": "Estad√≠stica Bayesiana",
    "section": "Slide Title",
    "text": "Slide Title\n\n\nLeft column\n\nRight column"
  },
  {
    "objectID": "presentaciones/01_clase1.html#slide-3",
    "href": "presentaciones/01_clase1.html#slide-3",
    "title": "Estad√≠stica Bayesiana",
    "section": "Slide 3",
    "text": "Slide 3\n\n\n\n\n\nProbando\n\n\n\n\nEstad√≠stica Bayesiana ‚Äì 2023\n\n\nSome additional commentary of more peripheral interest."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estad√≠stica Bayesiana",
    "section": "",
    "text": "Licenciatura en Estad√≠stica\n ¬† Facultad de Ciencias Econ√≥micas y Estad√≠stica (UNR)\n ¬† 1¬∞ Cuatrimestre 2023\n ¬† Lun ‚Äì 11:00 a 13:00 ¬† | ¬† Mi√© ‚Äì 7:00 a 9:00 ¬† | ¬† Vie ‚Äì 7:00 a 9:00"
  },
  {
    "objectID": "index.html#profesores",
    "href": "index.html#profesores",
    "title": "Estad√≠stica Bayesiana",
    "section": "Profesores",
    "text": "Profesores\n\n\nNacho Evangelista\n\n ¬† evangelistaignacio@gmail.com\n ¬† Consultas\n\n\n\nTom√°s Capretto\n\n ¬† tomicapretto@gmail.com\n ¬† Consultas"
  },
  {
    "objectID": "practica/practica_03.html",
    "href": "practica/practica_03.html",
    "title": "Pr√°ctica - Unidad 3",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_03.html#m√©todos-computacionales",
    "href": "practica/practica_03.html#m√©todos-computacionales",
    "title": "Pr√°ctica - Unidad 3",
    "section": "M√©todos Computacionales",
    "text": "M√©todos Computacionales\n\nSea \\(X \\sim \\text{Normal}(\\mu=3, \\sigma=1.2)\\).\n\nElabore un gr√°fico que permita visualizar la funci√≥n de densidad de probabilidad de \\(X\\).\n¬øCu√°l es la probabilidad de que \\(X\\) sea menor a 2.5?\n¬øCu√°l es la probabilidad de que \\(X\\) sea mayor a 4?\n¬øCu√°l es la probabilidad de que \\(X\\) sea mayor 2 y menor 3?\n\nSea \\(X \\sim \\text{Beta}(\\alpha=10, \\beta=2)\\)\n\nElabore un gr√°fico que permita visualizar la funci√≥n de densidad de probabilidad de \\(X\\).\n¬øCu√°l es la probabilidad de que \\(X\\) sea menor a 0.5?\n¬øCu√°l es la probabilidad de que \\(X\\) sea mayor a 0.8?\n¬øCu√°l es la probabilidad de que \\(X\\) sea mayor 0.25 y menor 0.75?\n\nResponda los dos puntos anteriores sin evaluar la funci√≥n de densidad ni la funci√≥n de distribuci√≥n de las variables aleatorias mencionadas. Para eso genere muestras que provengan de las correspondientes distribuciones y util√≠celas para responder las preguntas mencionadas. Reflexione sobre las ventajas y desventajas de utilizar un enfoque basado en la simulaci√≥n para resolver problemas.\nUna variable aleatoria \\(X\\) toma valores en el conjunto \\(\\{2, 4, 6, 8, 10\\}\\) con igual probabilidad. Encuentre la media y el desv√≠o est√°ndar de las variables \\(X\\) e \\(Y = 2X + 1\\). \nEn un problema determinado la distribuci√≥n a posteriori de la par√°metro de inte≈ïes \\(\\alpha\\) es \\(\\Gamma(k=3, \\theta=1.5)\\), donde \\(k\\) es el par√°metro de forma y \\(\\theta\\) es el par√°metro de escala. Calcule la probabilidad de que \\(\\alpha^2\\) sea mayor a 10. \nSean \\(X\\) e \\(Y\\) dos variables aleatorias independientes con distribuci√≥n uniforme en el intervalo \\([0, 1]\\).\n\n¬øCu√°l es la probabilidad de que \\(X \\le Y\\)?\nGrafique los puntos muestreados coloreando de acuerdo a si la muestra satisface el evento antes mencionado o no.\n\nDos estudiantes de estad√≠stica deciden encontrarse en la fotocopiadora de la Facultad entre las 10 y las 11 de la ma√±ana, eligiendo el tiempo de llegada al azar. La estudiante A esperar√° 10 minutos luego de llegar. Si el estudiante B no llega en ese intervalo, se ir√°. Lo mismo hace el estudiante B, pero este decide esperar 14 minutos. ¬øCu√°l es la probabilidad de que se produzca el encuentro en la fotocopiadora entre la estudiante A y el estudiante B?\nUna m√°quina que se utiliza para ensamblar tel√©fonos celulares en una f√°brica en Tierra del Fuego cuenta con tres componentes cr√≠ticos para su funcionamiento. Ante una falla en cualquiera de estos componentes, la m√°quina se detiene. Las probabilidades de que estos elementos operen correctamente durante un d√≠a cualquiera son \\(p_1 = 0.8\\), \\(p_2 = 0.9\\) y \\(p_3 = 0.7\\). Responda las siguientes preguntas utilizando t√©cnicas de simulaci√≥n:\n\n¬øCu√°l es la probabilidad de que la m√°quina falle en el primer d√≠a de uso?\n¬øCu√°l es la probabilidad de que la m√°quina siga funcionando luego de 10 d√≠as?\n¬øCu√°l es la probabilidad de que la m√°quina falle en el d√≠a 7 de uso?\nSea \\(T=\\) Cantidad de d√≠as que la m√°quina funciona ininterrumpidamente. Grafique la funci√≥n de densidad de probabilidad de \\(T\\).\n\nEste tuit propone un problema muy interesante. Una urna contiene una bola azul y una amarilla. Se elije una bola al azar y se la vuelve a colocar junto con otra bola adicional del mismo color. Se repite este proceso indefinidamente. ¬øQu√© ocurre con la proporci√≥n de bolas azules en la urna a medida que repetimos m√°s y m√°s veces?\n\nTiende a 1/2\nTiende a 0 √≥ a 1\nNo se estabiliza\nNinguna de las anteriores\n\nEscriba un programa en R para responder esta pregunta utilizando simulaciones. Genere gr√°ficos que faciliten la comprensi√≥n del resultado.\n¬øCu√°nto vale \\(\\pi\\)?\nImagine un c√≠rculo de radio \\(r\\) y un cuadrado de lado \\(2r\\), ambos centrados en el mismo punto, que de manera arbitraria puede ser el punto \\((0, 0)\\). Obtenga muestras de una distribuci√≥n uniforme en el plano \\((x, y)\\), cuyo dominio est√° acotado por el cuadrado antes mencionado. Para cada muestra extraida, determine si se encuentra dentro del c√≠rculo o no ‚Äì todos las muestras se encontrar√°n dentro del cuadrado. Utilice esta informaci√≥n para estimar el valor de \\(\\pi\\).\n\n\n\n\n\n\n\n\n\nDatos √∫tiles\n\nArea de un c√≠rculo: \\(\\pi \\cdot r^2\\).\nArea de un cuadrado: \\(a^2\\), donde \\(a\\) es la longitud del lado.\n\nSe seleccionan dos puntos de manera uniforme e independiente dentro de un c√≠rculo. ¬øCu√°l es la probabilidad de que la distancia entre dos puntos sea menor al radio?\n\nIntentar hacer a mano?\nResuelva el problema utilizando R\nElabore una visualizaci√≥n que facilite la comunicaci√≥n de los resultados\n\nEn la Copa del Mundo de la FIFA 2014, Alemania jug√≥ contra Brasil en la semifinal. Los alemanes hicieron el primer gol a los 11 minutos y el segundo a los 23. Asuma que el tiempo entre goles sigue una distribuci√≥n exponencial. Elija una distribuci√≥n a priori para el tiempo entre goles (puede ser conjugada o no). En ese momento del partido,\n\n¬øCu√°l es la distribuci√≥n a posteriori del tiempo entre goles de Alemania?\n¬øCu√°ntos goles cabr√≠a esperar que Alemania hiciera al finalizar los 90 minutos?\n¬øCu√°l era la probabilidad de que Alemania hiciera m√°s de 5 goles (cosa que ocurri√≥)? \n\n¬øTendr√© que esperar mucho?\nEl tiempo que un empleado de recursos humanos demora en hacer una entrevista tiene distribuci√≥n exponencial con media 30 minutos. Los tiempos de duraci√≥n de cada entrevista se pueden considerar independientes entre s√≠. Las entrevistas a postulantes para un trabajo est√°n programadas cada 15 minutos, comenzando desde las 8. Es v√°lido considerar que todos los postulantes llegan puntuales a su entrevista. Cuando la persona del turno de las 8:15 llega a la oficina\n\n¬øCu√°l es la probabilidad de que tenga que esperar antes de ser entrevistada?\n¬øCu√°l es el horario esperado al que terminar√° su entrevista? \n\n¬°Qu√© casualidad!\nDos personas se conocen en la fila de embarque para un vuelo en un avi√≥n Airbus A330-300\n\n¬øCu√°l es la probabilidad de que tengan asientos en la misma fila?\n¬øCu√°l es la probabilidad de que est√©n sentados en asientos adyacentes?\n\nEl Problema de Monty Hall\nEl Problema de Monty Hall es un problema de probabilidad basado en un juego del concurso televisivo estadounidense ‚ÄúTrato hecho‚Äù. En este problema, el concursante debe elegir una puerta entre tres, todas cerradas. El premio consiste en llevarse lo que se encuentra detr√°s de la elegida. Se sabe con certeza que tras una de ellas se oculta un autom√≥vil, y tras las otras dos hay cabras. Una vez que el concursante haya elegido una puerta y comunicado su elecci√≥n a los presentes, el presentador, que sabe lo que hay detr√°s de cada puerta, abrir√° una de las otras dos en la que haya una cabra. A continuaci√≥n, le da la opci√≥n al concursante de cambiar, si lo desea, de puerta (tiene dos opciones). ¬øDebe el concursante mantener su elecci√≥n original o escoger la otra puerta? ¬øHay alguna diferencia? Resuelva este ejercicio utilizando simulaciones. \n\n\n\n\n\nLas 3 puertas del problema de Monty Hall\n\n\n\n\nQue los cumplan feliz\nBas√°ndose en el siguiente tuit y conociendo el problema del cumplea√±os (¬øcu√°ntas personas debe haber en una habitaci√≥n para que la probabilidad de que dos de ellas cumplan a√±os el mismo d√≠a sea mayor a X%?) construir un gr√°fico similar al del tuit donde se grafique la probabilidad de que haya \\(n\\) personas que cumplan a√±os el mismo d√≠a para \\(K\\) personas presentes en la habitaci√≥n.\nQu√© suerte, ¬øno?\nPrevio a la final de la Copa Am√©rica 2021, los jugadores de la Selecci√≥n Argentina se re√∫nen en la habitaci√≥n del hotel como se describe en este tuit.\n\n¬øCu√°l es la probabilidad de que un jugador adivine una de diez cartas?\n¬øCu√°l es la probabilidad de que tres de ellos adivinen una de diez cartas?\n\nEl √°lbum del Campe√≥n\nEl √°lbum oficial del Mundial de F√∫tbol de Qatar 2022 consta de 638 figuritas. Cada paquete trae cinco figuritas.\n\nComprando cinco paquetes, ¬øcu√°l es la probabilidad de tener a Messi?\nComprando cinco paquetes, ¬øcu√°l es la probabilidad de sacar a Messi repetido?\n¬øCu√°ntos paquetes se necesitan, en promedio, para completar el √°lbum?\nSi a una persona le faltan diez figuritas para completar el √°lbum, ¬øcu√°ntos paquetes tiene que comprar para asegurarse de lograrlo?\n\n¬øQue t√°n raras son estas secuencias raras?\nSi se arroja una moneda \\(n\\) veces, ¬øcu√°l es la probabilidad de que no haya secuencias de \\(k\\) caras?\nUn viaje por el elevador\n¬øCu√°l es la probabilidad de que tres personas en un ascensor con doce pisos presionen para ir a tres pisos consecutivos? ¬øQu√© supuestos realiza para resolver el problema? Escr√≠balos en una lista de manera expl√≠cita.\nLa vida es muy corta como para perderla ordenando medias\nUn caj√≥n contiene 10 pares de medias. No hay dos pares iguales. Por fiaca, el due√±o de las medias no las agrupa despu√©s de lavarlas y simplemente las pone en el caj√≥n. Al momento de necesitar un par de medias, saca una tras una hasta que se forma un par. En promedio, ¬øcu√°ntas medias sacar√° hasta encontrar un par? \n¬øVale la pena hacer un ensayo cl√≠nico a gran escala?\nDados los resultados de un estudio piloto, la probabilidad a posteriori de que la droga desarrollada por tu compa√±√≠a sea mas efectiva que el tratamiento actual es \\(\\theta \\in [0, 1]\\). Tu compa√±√≠a est√° considerando realizar un ensayo cl√≠nico a gran escala para confirmar que la droga que desarrollan es de hecho mejor. El costo del estudio es $X. Si la droga es mejor, la probabilidad de que esto se confirme en el ensayo es del 80%. Si la droga no es mejor, hay una probabilidad del 5% de que el estudio confirme que es mejor. Si el ensayo sugiere que tu droga es mejor, ganar√°s $cX. ¬øPara qu√© valores de \\(\\theta\\) y \\(c\\) tiene sentido realizar el estudio? \nEl problema de concordancia\nResuelva el problema de concordancia de de Montmort presentado en la Pr√°ctica 0 utilizando simulaciones. \nEl problema de los sobres\nResuelva el problema de los dos sobres presentado en la Pr√°ctica 0 utilizando simulaciones.\nIntegraci√≥n por muestreo\nCalcule las siguientes integrales utilizando muestras.\n\n\\(\\displaystyle \\int_{-\\infty}^{\\infty}{\\frac{x^2}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{\\infty}{\\frac{x^3}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{\\infty}{\\frac{x^6}{\\sqrt{2\\pi}}\\exp \\left(-\\frac{x^2 - 4x}{2} \\right)dx}\\)\n\\(\\displaystyle \\int_{1}^{10}{x^6\\frac{e^{-x^4/2}}{\\sqrt{2\\pi}}dx}\\) \n\n¬øCu√°l es la distribuci√≥n de muestreo aproximada al usar muestreo independiente para evaluar integrales?"
  },
  {
    "objectID": "practica/practica_03.html#m√©todo-de-la-grilla",
    "href": "practica/practica_03.html#m√©todo-de-la-grilla",
    "title": "Pr√°ctica - Unidad 3",
    "section": "M√©todo de la grilla",
    "text": "M√©todo de la grilla\nPodriamos encontrar un mejor nombre‚Ä¶\n\nAproximaci√≥n de grilla\nSe tiene un experimento binomial donde \\(n=80\\) y se observan \\(y=7\\) √©xitos. Considere que el prior de la probabilidad de √©xito \\(\\theta\\) es \\(\\text{Beta}(2, 10)\\).\n\nObtenga la distribuci√≥n a posteriori de \\(\\theta\\) de manera anal√≠tica y graf√≠quela.\nObtenga la distribuci√≥n a posteriori de \\(\\theta\\) utilizando el m√©todo de la grilla en base a una grilla de 10 puntos y dibuje la curva obtenida en el gr√°fico creado anteriormente.\nRepita el proceso del punto anterior utilizando una grilla de 100 puntos.\nConcluya sobre la fidelidad de las aproximaciones. ¬øConsidera que es necesario utilizar una grilla m√°s densa? ¬øCu√°les ser√≠an las ventajas y desventajas?\n\nC√°lculo de probabilidades en base a la grilla (I)\nEn base al posterior obtenido en el ejercicio anterior mediante el m√©todo de la grilla calcule las siguientes probabilidades\n\n\\(P(\\theta < 0.7)\\)\n\\(P(\\theta > 0.05)\\)\n\\(P(0.05 < \\theta < 0.15)\\)\n\nDe ser necesario, obtenga el posterior mediante una grilla de mayor densidad.\nC√°lculo de probabilidades en base a la grilla (II)\nUtilice los valores de la grilla y sus probabilidades a posteriori para obtener muestras del posterior y calcular las mismas probabilidades que en el ejercicio anterior en base a muestras. Ayuda: Para obtener muestras utilice la funci√≥n sample().\nAproximaci√≥n de grilla en 2 dimensiones\nSean dos variables aleatorias continuas \\(X\\) e \\(Y\\) tales que \\((X, Y) \\in \\mathbb{R}^2\\), y sea el siguiente modelo de regresi√≥n lineal simple:\n\\[\n\\begin{aligned}\n\\alpha &\\sim \\text{Normal}(0, 1.5) \\\\\n\\beta  &\\sim \\text{Normal}(0, 2) \\\\\nY      &\\sim \\text{Normal}(\\alpha + \\beta X, 0.8)\n\\end{aligned}\n\\]\n\nObtenga el posterior conjunto del vector de par√°metros \\([\\alpha, \\beta]^T\\) mediante el m√©todo de la grilla. Elabore un gr√°fico que permita visualizar esta distribuci√≥n.\nObtenga el posterior marginal de \\(\\alpha\\) y graf√≠quelo.\nObtenga el posterior marginal de \\(\\beta\\) y graf√≠quelo.\nCalcule la probabilidad de que el intercepto sea mayor a 0.5.\nCalcule la probabilidad de que la pendiente sea menor a -3.\n\nPara responder las consignas utilice los datos simulados que se obtienen con el siguiente bloque de c√≥digo:\n\nset.seed(121195)\nalpha <- 1\nbeta <- -2\nsigma <- 0.8\nn <- 80\nx <- rnorm(n)\ny <- rnorm(n, alpha + beta * x, sigma)\ndf <- data.frame(x = x, y = y)\n\nBonus: ¬øC√≥mo podr√≠a responder las consignas (ii)-(v) utilizando muestras del posterior?\n\n\n\n\n\n\nEscalando la aproximaci√≥n de la grilla\nSuponga que se tiene que estimar un posterior utilizando la aproximaci√≥n mediante una grilla de 200 puntos en cada dimensi√≥n. Calcule c√∫antas veces se tiene que evaluar el posterior en cada uno de los siguientes escenarios:\n\n1 dimensi√≥n\n2 dimensiones\n3 dimensiones\n5 dimensiones\n10 dimensiones\n\nConcluya sobre las ventajas y desventajas de la aproximaci√≥n de la grilla teniendo en cuenta sus caracter√≠sticas conforme se incrementa el n√∫mero de dimensiones del posterior.\nBenchmark de la aproximaci√≥n de la grilla\nEl siguiente bloque de c√≥digo define una funci√≥n llamada create_and_eval_grid() que eval√∫a la funci√≥n de densidad normal en una cantidad arbitraria dimensiones. El argumento dimension_n indica la dimensionalidad de la distribuci√≥n normal, y grid_n indica la cantidad de puntos en la grilla de cada dimensi√≥n. Debajo, se utiliza la funci√≥n mark() del paquete bench para comparar el desempe√±o de la funci√≥n create_and_eval_grid() con diferentes n√∫meros de dimensiones.\n\ncreate_and_eval_grid <- function(dimension_n, grid_n = 100) {\n    grid <- seq(-3, 3, length.out = grid_n)\n    grids <- replicate(dimension_n, grid, simplify = FALSE)\n    df <- expand.grid(grids, KEEP.OUT.ATTRS = FALSE)\n    Mu <- rep(0, dimension_n)\n    Sigma <- diag(dimension_n)\n    mvtnorm::dmvnorm(df, mean = Mu, sigma = Sigma)\n}\nbench::mark(\n    create_and_eval_grid(1),\n    create_and_eval_grid(2),\n    check = FALSE,\n    max_iterations = 500\n)\n\nModifique el c√≥digo brindado para evaluar la funci√≥n de densidad en hasta un m√°ximo de 10 dimensiones. Concluya sobre el tiempo de ejecuci√≥n, el consumo de memoria, y otras cantidades que se encuentren en la salida y crea adecuadas para el an√°lisis.\nGrid approximation para una skew-normal. Estimar los par√°metros \\(\\xi\\) (posici√≥n), \\(\\omega\\) (escala) y \\(\\alpha\\) (asimetr√≠a).\n\\[\nf(x) = \\frac{2}{\\omega} \\phi\\left(\\frac{x-\\xi}{\\omega}\\right)\\Phi\\left( \\alpha \\frac{x-\\xi}{\\omega} \\right)\n\\]"
  },
  {
    "objectID": "practica/practica_03.html#sec-mh",
    "href": "practica/practica_03.html#sec-mh",
    "title": "Pr√°ctica - Unidad 3",
    "section": "Metropolis-Hastings",
    "text": "Metropolis-Hastings\n\n\n\nMuestreo utilizando el algoritmo de Metropolis-Hastings (I)\nUse el algoritmo de Metropolis-Hastings y una distribuci√≥n de propuesta \\(\\text{Normal}(0, 0.1)\\) para obtener 5000 muestras de las siguientes distribuciones de probabilidad:\n\n\\(\\text{Normal}(\\mu = 3, \\sigma = 6)\\)\n\\(\\text{StudentT}(\\nu = 5)\\)\n\\(\\frac{2}{3}\\text{Normal}(\\mu = 0, \\sigma = 0.5) + \\frac{1}{3}\\text{Normal}(\\mu = 3, \\sigma = 2)\\)\n\nGrafique las distribuciones obtenidas utilizando un histograma o una estimaci√≥n de densidad y superponga la funci√≥n de densidad verdadera para realizar una comparaci√≥n. Concluya sobre la similitud de las mismas y la aptitud de la distribuci√≥n de propuesta utilizada.\nSimplificando el algoritmo de Metropolis-Hastings\nLa distribuci√≥n de propuesta utilizada en el ejercicio anterior goza de una propiedad que permite simplificar el algoritmo de Metropolis-Hastings.\n\n¬øCu√°l es esta propiedad?\n¬øQu√© simplificaci√≥n se puede hacer?\n¬øQu√© nombre recibe la versi√≥n simplificada del algoritmo?\nImplemente la versi√≥n simplificada del algoritmo de Metropolis-Hastings y obtenga nuevamente 5000 muestras para las distribuciones presentadas en el ejercicio anterior utilizando la nueva implementaci√≥n.\n\nMuestreo utilizando el algoritmo de Metropolis-Hastings (II)\nUse el algoritmo de Metropolis-Hastings y una distribuci√≥n de propuesta que crea conveniente para obtener 5000 muestras de las siguientes distribuciones de probabilidad:\n\n\\(\\text{Beta}(\\alpha=4, \\beta=8)\\)\n\\(\\text{Gamma}(k = 3, \\theta = 2)\\)\n\\(\\frac{1}{2}\\text{Beta}(\\alpha=10, \\beta=3) + \\frac{1}{2}\\text{Beta}(\\alpha=3, \\beta=10)\\)\n\nRealice un an√°lisis similar al realizado en el Ejercicio 1.\nA jugar con la distribuci√≥n de propuesta!\nSuponga que se desea obtener muestras de una distribuci√≥n \\(\\text{Normal}(4, 1)\\) utilizando Metropolis-Hastings y la siguiente distribuci√≥n de propuesta:\n\\[\n\\mu' | \\mu \\sim \\text{Uniforme}(\\mu - w, \\mu + w)\n\\]\nObtenga \\(n=5000\\) muestras con \\(w \\in \\{0.01, 1, 100\\}\\) y compute la probabilidad de aceptaci√≥n. Luego, para cada \\(w\\), grafique la distribuci√≥n obtenida y visualice la cadena de Markov utilizando un traceplot.\n\n¬øC√≥mo se relaciona \\(w\\) con el desempe√±o del muestreo?\n¬øC√≥mo se relaciona \\(w\\) con la probabilidad de aceptaci√≥n? Justifique su respuesta utilizando la ecuaci√≥n del criterio de aceptaci√≥n.\n\nModelo Normal-Normal\nSe desea estudiar el tiempo promedio que los estudiantes de estad√≠stica dedican por semana a la materia Estad√≠stica Bayesiana. Para eso se propone utilizar un modelo Normal-Normal, con \\(\\sigma=1.2\\) conocido.\n\nElija una distribuci√≥n a priori para el par√°metro \\(\\mu\\).\nDescriba el modelo matem√°ticamente.\nDetermine una distribuci√≥n de propuesta adecuada para este problema. Explique.\nObtenga 2000 muestras del posterior de \\(\\mu\\). Ajuste los par√°metros de la distribuci√≥n de propuesta hasta que los resultados se vean adecuados.\nGrafique un histograma de las muestras obtenidas y concluya sobre el desempe√±o de la aproximaci√≥n.\n\nPara resolver este problema utilice los datos que se leen con el siguiente codigo:\n\nurl <- paste0(\n    \"https://raw.githubusercontent.com/estadisticaunr/\",\n    \"estadistica-bayesiana/main/datos/tiempo-estudio-eb.csv\"\n)\ndf_estudio <- readr::read_csv(url)\n\nModelo Beta-Binomial\nSe desea estimar el posterior del par√°metro \\(\\pi\\) en el siguiente modelo Beta-Binomial:\n\\[\n\\begin{aligned}\nY &\\sim \\text{Binomial}(n, \\pi) \\\\\n\\pi &\\sim \\text{Beta}(2, 3)\n\\end{aligned}\n\\]\nSe observan \\(n=10\\) ensayos de Bernoulli y se registran \\(y=3\\) √©xitos. Determine una distribuci√≥n de propuesta adecuada y obtenga muestras de la distribuci√≥n a posteriori del par√°metro \\(\\pi\\) utilizando el algoritmo de Metropolis-Hastings.\nDe ser necesario, ajuste los par√°metros de la distribuci√≥n de propuesta.\nModelo Poisson\nEn el ejercicio ¬°Ostras! ¬°Estoy haciendo inferencia bayesiana! de la Pr√°ctica 1 se report√≥ que la cantidad de especies marinas bivalvas descubiertas cada a√±o entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSea \\(Y_t\\) la cantidad de especies descubierta en el a√±o \\(2009 + t\\) (e.g.¬†\\(Y_1 = 64\\) es el conteo para el a√±o 2010) y el siguiente modelo:\n\\[\n\\begin{aligned}\nY_t        &\\sim \\text{Poisson}(\\lambda_t) \\\\\n\\lambda_t  &= \\exp (\\alpha + \\beta t) \\\\\n\\alpha     &\\sim \\text{Normal}(0, 10^2) \\\\\n\\beta      &\\sim \\text{Normal}(0, 10^2)\n\\end{aligned}\n\\]\nAjuste el siguiente modelo utilizando Metropolis-Hastings y verifique la convergencia de las cadenas de Markov. \nMetropolis-Hastings multivariado\nUse el algoritmo de Metropolis Hastings para obtener 1000 muestras de la distribuci√≥n \\(\\text{MVN}(\\pmb{\\mu}, \\pmb{\\Sigma})\\) donde\n\\[\n\\begin{array}{cc}\n    \\pmb{\\mu} = \\begin{bmatrix}1.2 \\\\ 0.8 \\end{bmatrix}, &\n    \\pmb{\\Sigma} = \\begin{bmatrix}3 & 0.2 \\\\ 0.2 & 2 \\end{bmatrix}\n\\end{array}\n\\]\nUtilice una distribuci√≥n de propuesta \\(\\text{MVN}(\\mathbf{0}_2, \\mathbf{I}_2\\sigma)\\) con \\(\\sigma = 0.2\\).\nMetropolis-Hastings para regresi√≥n\nRepita el ejercicio Aproximaci√≥n de grilla en 2 dimensiones pero utilice Metropolis-Hastings para obtener muestras del posterior en vez del m√©todo de la grilla.\nDemostrar que la distribuci√≥n estacionaria del algoritmo de Metropolis-Hastings es la distribuci√≥n objetivo \\(p(\\pmb{\\theta} | \\mathbf{y})\\)"
  },
  {
    "objectID": "practica/practica_03.html#hamiltonian-monte-carlo-hmc-y-el-not-u-turn-sampler-nuts",
    "href": "practica/practica_03.html#hamiltonian-monte-carlo-hmc-y-el-not-u-turn-sampler-nuts",
    "title": "Pr√°ctica - Unidad 3",
    "section": "Hamiltonian Monte Carlo (HMC) y el Not-U-Turn Sampler (NUTS)",
    "text": "Hamiltonian Monte Carlo (HMC) y el Not-U-Turn Sampler (NUTS)\nTenemos que completarlo‚Ä¶"
  },
  {
    "objectID": "practica/practica_03.html#diagn√≥sticos",
    "href": "practica/practica_03.html#diagn√≥sticos",
    "title": "Pr√°ctica - Unidad 3",
    "section": "Diagn√≥sticos",
    "text": "Diagn√≥sticos\n\nDescribir medidas de diagn√≥stico (I)\nEn sus propias palabras, explique que son \\(\\text{ESS}\\), \\(\\hat{R}\\) y \\(\\text{MCSE}\\). Considere:\n\n¬øQu√© miden?\n¬øQu√© potencial problema de MCMC detectan? \n\nDescribir medidas de diagn√≥stico (II)\nEn sus propias palabras, explique por qu√© las t√©cnicas de estimaci√≥n del posterior basadas en MCMC necesitan diagn√≥sticos de convergencia. En particular, contraste estos con los m√©todos conjugados descritos en la Unidad 2 que no necesitan esos diagn√≥sticos. ¬øQu√© es diferente entre los dos m√©todos de inferencia? \nProblemitas de MCMC\nPara cada escenario de simulaci√≥n mediante MCMC descrito a continuaci√≥n, explique c√≥mo el escenario podr√≠a afectar la aproximaci√≥n del posterior.\n\nLa cadena se mezcla muy lentamente\nLa cadena presenta alta auto-correlaci√≥n.\nLa cadena tiende a quedarse ‚Äútrabada‚Äù \n\nVamos de paseo\nElabore traceplots que le permitan visualizar la traza de la cadena de Markov utilizada en el ejercicio Modelo Normal-Normal de la secci√≥n Metropolis-Hastings.\nLuego, repita el ejercicio utilizando 4 cadenas independientes y grafique sus trazas en un mismo gr√°fico. ¬øQu√© puede concluir sobre la convergencia y la mezcla de las cadenas?\nPrimeros pasitos con \\(\\hat{R}\\)\nRepita lo realizado en el ejercicio Modelo Beta-Binomial de la secci√≥n Metropolis-Hastings utilizando 4 cadenas independientes. Luego:\n\nCalcule la varianza intra-cadenas \\(W\\)\nCalcule la varianza entre-cadenas \\(B\\)\nCalcule \\(\\hat{R}\\) y concluya sobre el resultado obtenido.\n\n\n\\(\\hat{R}\\) para un muestreo independiente\nEn un determinado problema se encuentra que el posterior del par√°metro \\(\\pi\\) de un modelo con verosimilitud binomial est√° dado por\n\\[\n\\pi | \\mathbf{y} \\sim \\text{Beta}(12, 6)\n\\]\n\nObtenga 4 conjuntos independientes de 1000 muestras independientes de esta distribuci√≥n.\nCalcule \\(W\\), \\(B\\), y \\(\\hat{R}\\) considerando que cada conjunto representa una cadena.\nExplique el resultado de \\(\\hat{R}\\).\n\nBonus\n\n¬øSe puede concluir que cada uno de los muestreos realizados representan realizaciones de una cadena de Markov? ¬øPor qu√©?\n¬øPor qu√© no fue necesario descartar un conjunto de muestras de warm-up?\n\nFunci√≥n de autocorrelaci√≥n\nUtilice las 4 cadenas obtenidas en el ejercicio Primeros pasitos con \\(\\hat{R}\\) y grafique la funci√≥n de autocorrelaci√≥n y calcule el coeficiente de autocorrelaci√≥n utilizando un rezago unitario. Concluya sobre la dependencia entre las muestras obtenidas.\nTama√±o de muestra efectivo\nUtilice las muestras obtenidas en el ejercicio anterior para calcular el tama√±o de muestra efectivo.\nExperimentos con el tama√±o de muestra efectivo\nSuponga una distribuci√≥n \\(\\text{Normal}(0, 1^2)\\). Obtenga \\(n\\) muestras independientes utilizando rnorm() y \\(n\\) muestras dependientes utilizando Metropolis-Hastings con \\(n \\in \\{10, 50, 100, 500, 1000, 10000\\}\\).\n\nCalcule el tema√±o de muestra efectivo en todos los escenarios simulados.\nDescriba el comportamiento del tama√±o de muestra efectivo conforme se incrementa el n√∫mero de muestras.\n¬øPor qu√© se observan los comportamientos descritos?\n\n¬°Rompan todo! Un caso simulado\nLos siguientes gr√°ficos muestran las trazas y las distribuciones que resultan al obtener muestras de un posterior utilizando dos cadenas de Markov independientes. Estos muestreos fueron realizados de manera que presenten algunos problemas. Describa cuales son los problemas que puede observar en los siguientes gr√°ficos y explique por qu√© no utilizar√≠a estas muestras para obtener conclusiones sobre el posterior.\n\n\n\n\n\n\n\n\nGr√°fico 1\n\n\n\n\n\n\n\n\n\nGr√°fico 2\n\n\n\n\n\n\n\n\n\nGr√°fico 3\n\n\n\n\n\n\n\n\n\nGr√°fico 4\n\n\n\n\n¬°Rompan todo! Un caso real\nAl igual que en el ejercicio anterior, se presentan traceplots donde el muestreo del posterior presenta problemas. En este caso, los gr√°ficos que se observan fueron obtenidos en el marco de un problema real, y se usan 4 cadenas en vez de 2. Nuevamente, describa cuales son los problemas que puede observar en los siguientes gr√°ficos y explique por qu√© no utilizar√≠a estas muestras para obtener conclusiones sobre el posterior.\n\n\n\n\n\nGr√°fico 1\n\n\n\n\n\n\n\n\n\nGr√°fico 2\n\n\n\n\nAdem√°s, responda:\n\n¬øCu√°l gr√°fico se asocia a un mayor tama√±o de muestra efectivo?\n¬øQu√© grafico muestra peor mezcla entre cadenas?\n¬øEn qu√© gr√°fico se puede observar que las cadenas convergen a la misma distribuci√≥n?"
  },
  {
    "objectID": "practica/practica_03.html#programaci√≥n-probabil√≠stica---stan-y-rstan",
    "href": "practica/practica_03.html#programaci√≥n-probabil√≠stica---stan-y-rstan",
    "title": "Pr√°ctica - Unidad 3",
    "section": "Programaci√≥n probabil√≠stica - Stan y RStan",
    "text": "Programaci√≥n probabil√≠stica - Stan y RStan\n\nMCMC con RStan: Precalentamiento (I)\nUtilice la informaci√≥n proporcionada para definir la estructura del modelo bayesiano utilizando RStan. No es necesario ejecutar nada, solo necesita proporcionar el c√≥digo correcto.\n\n\\(Y | \\pi \\sim \\text{Binomial}(\\pi, 20)\\) con \\(\\pi \\sim \\text{Beta}(1, 1)\\)\n\\(Y | \\lambda \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda \\sim \\text{Gamma}(4, 2)\\)\n\\(Y | \\mu \\sim \\text{Normal}(\\mu, 1^2)\\) con \\(\\mu \\sim \\text{Normal}(0, 10^2)\\) \n\nMCMC con RStan: Precalentamiento (II)\nUtilice la informaci√≥n proporcionada para (1) definir la estructura del modelo bayesiano y (2) obtener muestras del posterior utilizando RStan. No es necesario ejecutar nada, solo necesita proporcionar el c√≥digo correcto.\n\n\\(Y | \\pi \\sim \\text{Binomial}(\\pi, 20)\\) con \\(\\pi \\sim \\text{Beta}(1, 1)\\) e \\(y = 12\\)\n\\(Y | \\lambda \\sim \\text{Poisson}(\\lambda)\\) con \\(\\lambda \\sim \\text{Gamma}(4, 2)\\) e \\(y = 3\\).\n\\(Y | \\mu \\sim \\text{Normal}(\\mu, 1^2)\\) con \\(\\mu \\sim \\text{Normal}(0, 10^2)\\) e \\(y = 12.2\\). \n\nModelo Beta-Binomial con Rstan (I)\nConsidere el modelo Beta-Binomial para \\(\\pi\\) con \\(Y | \\pi \\sim \\text{Binomial}(\\pi, n)\\) y \\(\\pi \\sim \\text{Beta}(3, 8)\\). Suponga que en \\(n = 10\\) ensayos independientes observa \\(y = 2\\) √©xitos.\n\nObtenga muestras del posterior de \\(\\pi\\) con RStan utilizando 3 cadenas y 12000 iteraciones por cadena.\nGrafique la traza de cada una de las tres cadenas.\n¬øCu√°l es el rango de valores en el eje x del traceplot? ¬øPor qu√© el valor m√°ximo de este rango no es 12000?\nCree un gr√°fico que permita visualizar la funci√≥n de densidad de los valores obtenidos con cada una de las tres cadenas.\nUtilizando lo estudiado en la Unidad 2, especifique el posterior de \\(\\pi\\). ¬øC√≥mo se compara con la aproximaci√≥n mediante MCMC?\n\nModelo Beta-Binomial con Rstan (II)\nRepita el ejercicio anterior utilizando \\(\\pi \\sim \\text{Beta}(4, 3)\\), donde observa \\(y = 4\\) √©xitos en \\(n = 12\\) ensayos independientes.\nModelo Gamma-Poisson con Rstan (I)\nConsidere el modelo Gamma-Poisson para \\(\\lambda\\) con \\(Y_i | \\lambda \\sim \\text{Poisson}(\\lambda)\\) y \\(\\lambda \\sim \\text{Gamma}(20, 5)\\). Suponga que cuenta con \\(n = 3\\) observaciones independientes \\((y_1, y_2, y_3) = (0, 1, 0)\\)\n\nObtenga muestras del posterior de \\(\\lambda\\) con RStan utilizando 4 cadenas y 10000 iteraciones por cadena.\nGrafique la traza y la funci√≥n de densidad de cada una de las tres cadenas.\nA partir del gr√°fico de la funci√≥n de densidad, ¬øcu√°les suelen ser, a posteriori, los valores m√°s probables de \\(\\lambda\\)?\nUtilizando lo estudiado en la Unidad 2, especifique el posterior de \\(\\lambda\\). ¬øC√≥mo se compara con la aproximaci√≥n mediante MCMC?\n\nModelo Gamma-Poisson con Rstan (II)\nRepita el ejercicio anterior utilizando el prior \\(\\lambda \\sim \\text{Gamma}(5, 5)\\).\nModelo Normal-Normal con Rstan (I)\nRepita los mismos pasos del ejercicio Modelo Gamma-Poisson con Rstan (I) pero considere el modelo Normal-Normal para \\(\\mu\\) con \\(Y_i | \\mu \\sim \\text{Normal}(\\mu, 1.3^2)\\) y \\(\\mu \\sim \\text{Normal}(10, 1.2^2)\\). Suponga que cuenta con \\(n = 4\\) observaciones independientes \\((y_1, y_2, y_3, y_4) = (7.1, 8.9, 8.4, 8.6)\\)\nModelo Normal-Normal con Rstan (II)\nRepita el ejercicio anterior con el modelo Normal-Normal pero ahora considere \\(Y_i | \\mu \\sim \\text{Normal}(\\mu, 8^2)\\) y \\(\\mu \\sim \\text{Normal}(-15, 2^2)\\). Suponga que en \\(n = 5\\) observaciones independientes observa \\((y_1, y_2, y_3, y_4, y_5) = (‚àí10.1, 5.5, 0.1,‚àí1.4, 11.5)\\)\nUn modelo que es un poco ¬øcomplicado?\nConsidere el siguiente modelo\n\\[\n\\begin{aligned}\n\\text{mass}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2) \\\\\n\\mu_i         &= \\theta_1 + \\theta_2 + \\text{age}_i^{\\theta_3} \\\\\n\\theta_1      &\\sim \\text{Normal}(0, 100^2) \\\\\n\\theta_2      &\\sim \\text{Uniforme}(0, 20000) \\\\\n\\theta_3      &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma^2      &\\sim \\text{InvGamma}(0.01, 0.01)\n\\end{aligned}\n\\]\ny los siguientes datos\n\nedad <- c(2, 15, 14, 16, 18, 22, 28)\npeso <- c(29.9, 1761, 1807, 2984, 3230, 5040, 5654)\nn <- length(edad)\ndata_list <- data.frame(peso = peso, edad = edad, n = n)\n\n\nAjuste el modelo utilizando RStan\nObtenga una visualizaci√≥n de la edad versus el peso junto con una curva que indique la media a posteriori de \\(\\mu_i\\) para evaluar si el modelo ajusta bien.\nEstudie la convergencia de las cadenas de Markov.\nMencione tres medidas que podr√≠a tomar para mejorar la convergencia."
  },
  {
    "objectID": "practica/practica_03.html#otros",
    "href": "practica/practica_03.html#otros",
    "title": "Pr√°ctica - Unidad 3",
    "section": "Otros",
    "text": "Otros\n\nUna compa√±√≠a pesquera de Comodoro Rivadavia se encuentra probando un nuevo m√©todo para estimar el peso de los peces que extrae del Mar Argentino. El objetivo de este m√©todo es obtener una estimaci√≥n lo suficientemente buena del peso de cada pescado sin tener que pesarlos uno por uno, ya que es un proceso costoso en tiempo y labor. Para eso, seleccionaron una muestra de pescados, los pesaron y les midieron ciertos aspectos morfol√≥gicos (ancho, alto y largo). En el futuro, esperan recolectar estas mismas medidas morfol√≥gicas mediante una c√°mara especializada y utilizar un modelo para estimar el peso.\nEl modelo propuesto por el equipo de investigaci√≥n es el siguiente:\n\\[\n\\begin{aligned}\n\\log(\\text{Peso}_i) &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu_i               &= \\beta_0 + \\beta_1 \\log(\\text{Largo}_i) \\\\\n\\sigma              &\\sim \\text{Gamma}(k, \\theta)\n\\end{aligned}\n\\]\nEl peso se encuentra medido en gramos y la longitud en cent√≠metros. El equipo provee las muestras que obtuvieron del posterior. Las mismas se pueden leer en R utilizando el siguiente bloque de c√≥digo.\n\nurl <- paste0(\n    \"https://raw.githubusercontent.com/estadisticaunr/\",\n    \"estadistica-bayesiana/main/datos/fish-market-posterior.csv\"\n)\ndf_posterior <- readr::read_csv(url)\nhead(df_posterior)\n\n# A tibble: 6 √ó 3\n  intercepto pendiente sigma\n       <dbl>     <dbl> <dbl>\n1      -4.44      3.08 0.408\n2      -4.30      3.05 0.431\n3      -4.49      3.12 0.433\n4      -4.04      2.96 0.341\n5      -4.76      3.18 0.413\n6      -4.65      3.15 0.350\n\nAnalice de manera gr√°fica y anal√≠tica los posteriors marginales de los par√°metros del modelo. Realice las transformaciones de par√°metros que crea conveniente para facilitar la comprensi√≥n del an√°lisis.\nConsidere un pescado cuya longitud es de 30 cent√≠metros.\n\nObtenga y grafique la distribuci√≥n a posteriori del peso medio.\nObtenga y grafique la distribuci√≥n predictiva a posteriori del peso.\nInterprete los resultados.\n\nGrafique la curva de regresi√≥n junto a una banda de credibilidad del 95% en el plano de las variables originales y en el plano de las variables transformadas.\nAgregue a los gr√°ficos anteriores una banda de credibilidad del 95% para la distribuci√≥n predictiva a posteriori. Interprete los resultados.\n\nConsidere la siguiente familia de distribuciones normales en 2D\n\\[\nf(\\mathbf{x} | \\pmb{\\Sigma}, \\pmb{\\mu} = \\mathbf{0})\n= \\frac{1}{\\det(2\\pi\\pmb{\\Sigma})^{-\\frac{1}{2}}}\n\\exp[{-\\frac{1}{2} \\mathbf{x}^T \\pmb{\\Sigma}^{-1} \\mathbf{x}}]\n\\]\ny las siguientes matrices de covarianza\n\\[\n\\begin{array}{cc}\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix} 1 & 0.2 \\\\ 0.2 & 1 \\end{bmatrix}\n    \\\\ \\\\\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{bmatrix} &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n    \\\\ \\\\\n    \\pmb{\\Sigma}_1 = \\begin{bmatrix} 1 & 0.9 \\\\ 0.9 & 1 \\end{bmatrix} &\n    \\pmb{\\Sigma}_2 = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 1 \\end{bmatrix}\n\\end{array}\n\\]\nQue dan lugar a las siguientes funciones de densidad:\n\n\n\n\n\n\n\n\n\nParte 1: Metropolis-Hastings\n\nUtilice el algoritmo Metropolis-Hastings para obtener \\(n=10000\\) muestras de cada una de las distribuciones.\nCalcule la probabilidad de aceptaci√≥n.\nGrafique la funci√≥n de autocorrelaci√≥n y calcule la cantidad de muestras efectivas.\nAnalice como var√≠a la probabilidad de aceptaci√≥n y la cantidad de muestras efectivas seg√∫n las diferentes caracter√≠sticas de la distribuci√≥n objetivo.\n¬øCu√°les son las ventajas y desventajas del algoritmo de Metropolis-Hastings seg√∫n lo que puede concluir a partir de esta aplicaci√≥n? Comente dificultades con las que se haya encontrado.\n\nParte 2: Hamiltonian Monte Carlo\n\nUtilice el algoritmo HMC para obtener \\(n=10000\\) muestras de cada una de las distribuciones.\nCalcule la probabilidad de aceptaci√≥n.\nGrafique la funci√≥n de autocorrelaci√≥n y calcule la cantidad de muestras efectivas.\nAnalice como var√≠a la probabilidad de aceptaci√≥n y la cantidad de muestras efectivas seg√∫n las diferentes caracter√≠sticas de la distribuci√≥n objetivo.\n¬øCu√°les son las ventajas y desventajas del algoritmo de Metropolis-Hastings seg√∫n lo que puede concluir a partir de esta aplicaci√≥n? Comente dificultades con las que se haya encontrado.\n\n\n\n\nEjercicios que faltan\n\nUtilizar HMC para la normal multivariada con correlaci√≥n moderada y alta correlaci√≥n\nUtilizar HMC para los modelos donde se us√≥ MH\nAlgun caso donde los diagnosticos no den bien‚Ä¶\n\nPuede ser cuando el HMC no esta bien tuneado\nPensar algunos otros (deberia buscar en cosas que he hecho)\n\nAlgo con brms?\n\nNota: Para los que dicen ‚Äúutilizar HMC‚Äù estaria bueno que proveamos una funcion que use HMC, sin que tengan que usar Stan."
  },
  {
    "objectID": "practica/practica_05.html",
    "href": "practica/practica_05.html",
    "title": "Pr√°ctica - Unidad 5",
    "section": "",
    "text": "Descargar PDF\n\n\nConsidere un modelo para datos de conteo con un predictor \\(X\\) que toma valores entre -3 y 50\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Poisson}(\\lambda_i) \\\\\n\\log(\\lambda_i) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\lambda_i\\) y los de \\(Y_i\\). ¬øC√≥mo es \\(\\lambda\\) en funci√≥n de \\(X\\)? ¬øEs lineal la relaci√≥n entre \\(X\\) e \\(Y\\)? ¬øQu√© ocurre con la varianza de \\(Y\\) en funci√≥n de \\(X\\)? ¬øC√≥mo es la distribuci√≥n marginal de \\(Y\\)?\nAhora a√±ada incertidumbre al valor de \\(\\beta\\) (¬øc√≥mo se hace esto?) y simule nuevamente valores para \\(\\lambda_i\\) y \\(Y_i\\). Compare los resultados.\n\nConsidere un modelo de clasificaci√≥n con un predictor \\(X\\) que toma valores entre -30 y 10\n\\[\n\\begin{aligned}\nY_i   &\\sim \\mathrm{Bernoulli}(\\theta_i) \\\\\n\\log\\left(\\frac{\\theta_i}{1 - \\theta_i}\\right) &= \\beta X \\\\\n\\end{aligned}\n\\]\n\nGenere 1000 valores de \\(X\\), asuma un valor conocido (y fijo) para \\(\\beta\\), simule los correspondientes valores de \\(\\theta_i\\) y los de \\(Y_i\\). ¬øC√≥mo es \\(\\theta\\) en funci√≥n de \\(X\\)? ¬øEs lineal la relaci√≥n entre \\(X\\) e \\(Y\\)?\nAhora a√±ada incertidumbre al valor de \\(\\beta\\) (¬øc√≥mo se hace esto?) y simule nuevamente valores para \\(\\theta_i\\) y \\(Y_i\\). Compare los resultados.\n\nUtilice el conjunto de datos de las elecciones presidenciales de Estados Unidos del a√±o 2016 que se provee en Reich y Ghosh (2019) (rep_2012_2016). Elabore un modelo de regresi√≥n lineal bayesiano donde la variable respuesta es la diferencia porcentual entre el porcentaje de votos que obtuvo el candidato Republicano en el 2016 versus los que tuvo en el 2012 en cada condado y utilice todas las dem√°s variables como predictoras.\n\nUtilice distribuciones a priori normales no informativas. Interprete las distribuciones a posteriori marginales de los coeficientes de regresi√≥n.\nCalcule los residuos \\(\\mathbf{r} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}\\) donde \\(\\hat{\\boldsymbol{\\beta}}\\) es la media a posteriori del vector de coeficientes de regresi√≥n ¬øPuede concluir que los residuos siguen una distribuci√≥n normal? ¬øQu√© condados presentan los residuos m√°s grandes y m√°s peque√±os? ¬øQu√© puede indicar sobre estos condados?\nTo Do: Compartir datos de forma accesible \n\nUtilice el conjunto de datos sobre el control de armas en Estados Unidos. Estos datos provienen de un estudio transversal. Para el estado \\(i\\), sea \\(Y_i\\) el numero de homicios y \\(N_i\\) el tama√±o de la poblaci√≥n.\n\nAjuste el modelo \\(Y_i | \\boldsymbol{\\beta} \\sim \\text{Poisson}(N_i\\lambda_i)\\) donde \\(\\text{log}(\\lambda_i) = \\mathbf{X}_i\\boldsymbol{\\beta}\\). Use distribuciones a priori no informativas y \\(p = 7\\) de las covariables en \\(\\mathbf{X}_i\\): el intercepto, los cinco confounders \\(\\mathbf{Z}_i\\), y el n√∫mero de leyes relacionadas a armas. Justifique que el sampler ha convergido y explorado suficientemente la distribuci√≥n a posteriori y resuma la distribuci√≥n a posteriori de \\(\\boldsymbol{\\beta}\\).\nTo Do: No puse los puntos (b) y (c) porque no se si estan dentro del plan\nTo Do: Ver como presentamos el tema de las variables a incorporar en el modelo\n\nDescargue el conjunto de datos babynames en R y calcule el log-odds de un beb√© llamado ‚ÄúSophia‚Äù en cada a√±o luego de 1950.\n\nlibrary(babynames)\ndat <- babynames\ndat <- dat[dat$name == \"Sophia\" & dat$sex == \"F\" & dat$year > 1950, ]\nyr <- dat$year\np <- dat$prop\nt <- dat$year - 1950\nY <- log(p / (1 - p))\n\nSea \\(Y_t\\) el log-odds muestral en el a√±o \\(t + 1950\\). Ajuste el siguiente modelo auto-regresivo de orden 1:\n\\[\n\\begin{aligned}\nY_t   &= \\mu_t + \\rho(Y_{t - 1} + \\mu_{t - 1}) + \\varepsilon_t \\\\\n\\mu_t &= \\alpha + \\beta t \\\\\n\\varepsilon &\\underset{iid}{\\sim} \\text{Normal}(0, \\sigma^2) \\\\\n\\alpha, \\beta &\\sim \\text{Normal}(0, 100^2) \\\\\n\\rho &\\sim \\text{Uniforme}(-1, 1) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nInterprete los par√°metros del modelo (\\(\\alpha\\), \\(\\beta\\), \\(\\rho\\) y \\(\\sigma^2\\))\nAjuste el modelo utilizando RStan para \\(t > 1\\). Verifique la convergencia y reporte la media a posteriori e intervalos del 95% para los par√°metros.\nGrafique la distribuci√≥n predictiva a posteriori para \\(Y_t\\) en el a√±o 2020. \n\nEn este ejercicio se llevar√° a cabo un meta-an√°lisis, es decir, un an√°lisis que combina el resultado de varios estudios. Los datos provienen del paquete rmeta en R.\n\nlibrary(rmeta)\ndata(cochrane)\ncochrane\n\n          name ev.trt n.trt ev.ctrl n.ctrl\n1     Auckland     36   532      60    538\n2        Block      1    69       5     61\n3        Doran      4    81      11     63\n4        Gamsu     14   131      20    137\n5     Morrison      3    67       7     59\n6 Papageorgiou      1    71       7     75\n7      Tauesch      8    56      10     71\nLos datos provienen de siete ensayos aleatorizados que eval√∫an el efecto de la terapia con corticosteroides en la muerte neonatal. Para el ensayo \\(i \\in \\{1, \\dots, 7 \\}\\) \\(Y_{i0}\\) representa el n√∫mero de eventos que ocurren en el grupo de control de tama√±o \\(N_{i0}\\) y \\(Y_{i1}\\) representa el n√∫mero de eventos que ocurren en el grupo tratado de tama√±o \\(N_{i1}\\).\n\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con \\(\\theta_0, \\theta_1 \\sim \\text{Uniforme}(0, 1)\\). ¬øSe puede concluir que el tratamiento est√° asociado a una reducci√≥n de la tasa de muerte?\nAjuste el modelo \\(Y_{ij} | \\theta_j \\underset{indep}{\\sim} \\text{Binomial}(N_{ij}, \\theta_j)\\) con\n\n\\(\\text{logit}(\\theta_{ij}) = \\alpha_{ij}\\)\n\\(\\boldsymbol{\\alpha}_i = (\\alpha_{i0}, \\alpha_{i1})^T \\underset{iid}{\\sim} \\text{Normal}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\)\n\\(\\boldsymbol{\\mu} \\sim \\text{Normal}(0, 10^2I_2)\\)\n\\(\\boldsymbol{\\Sigma} \\sim \\text{InvWishart}(3, I_2)\\)\n\nInterprete los resultados indicando si estos sugieren que el tratamiento est√° asociado a una reducci√≥n en la tasa de muerte.\nDibuje un DAG para ambos modelos.\nDiscuta las ventajas y desventajas de ambos modelos.\n¬øCu√°l modelo es el preferido para estos datos? \n\nUtilice el conjuto de datos airquality que viene con el paquete datasets que se carga autom√°ticamente al crear una sesi√≥n de R.\n\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\nCompare los siguientes modelos utilizando 5-fold cross-validation:\n\\[\n\\begin{array}{l}\n\\mathcal{M}_1: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i, \\sigma^2) \\\\\n\\mathcal{M}_2: \\text{Ozone}_i \\sim \\text{Normal}(\\beta_1 + \\beta_2 \\text{Solar.R}_i + \\beta_3 \\text{Temp}_i + \\beta_4 \\text{Wind}_i, \\sigma^2)\n\\end{array}\n\\]\nElija priors para ambos modelos explicando su elecci√≥n. \nAccidente del Challenger\nEl 28 de enero de 1986, el vuelo n√∫mero veinticinco del programa estadounidense de trasbordadores espaciales acab√≥ en un desastre cuando uno de los propulsores del Challenger explot√≥ poco despu√©s del despegue. En el accidente murieron los siete tripulantes. La comisi√≥n que investig√≥ el accidente concluy√≥ que el accidente fue causado por una falla en un o-ring en una juntura de uno de los propulsores. Esta falla se debi√≥ a un dise√±o defectuoso que volvi√≥ al o-ring excesivamente sensible a factores externos, entre ellos la temperatura. De los veinticuatro vuelos previos, exist√≠a informaci√≥n de fallas de o-rings para veintitr√©s de ellos (el otro se perdi√≥ en el oc√©ano). Estos datos fueron discutidos la noche previa al incidente. No obstante, los datos de los siete vuelos en los que hubo fallas llevaron a la conclusi√≥n de que no hab√≠a una evidencia clara.\n\n\n\n\n\n\n \n  \n    T (¬∞F) \n    Falla \n  \n \n\n  \n    66 \n    0 \n  \n  \n    70 \n    1 \n  \n  \n    69 \n    0 \n  \n  \n    68 \n    0 \n  \n  \n    67 \n    0 \n  \n  \n    72 \n    0 \n  \n  \n    73 \n    0 \n  \n  \n    70 \n    0 \n  \n  \n    57 \n    1 \n  \n  \n    63 \n    1 \n  \n  \n    70 \n    1 \n  \n  \n    78 \n    0 \n  \n  \n    67 \n    0 \n  \n  \n    53 \n    1 \n  \n  \n    67 \n    0 \n  \n  \n    75 \n    0 \n  \n  \n    70 \n    0 \n  \n  \n    81 \n    0 \n  \n  \n    76 \n    0 \n  \n  \n    79 \n    0 \n  \n  \n    75 \n    1 \n  \n  \n    76 \n    0 \n  \n  \n    58 \n    1 \n  \n\n\n\n\n\n\nCurvas de crecimiento de tiranos√°uridos\nSe analizan datos de 20 f√≥siles de tiranos√°uridos para estimar las curvas de crecimiento de cuatro especies: Albertosaurio, Daspletosaurio, Gorgosaurio y Tiranosaurio. Los datos se toman de la Tabla 1 de Erickson et¬†al. (2004) y se muestran en la Figura¬†1. El objetivo es determinar la curva de crecimiento, esto es, determinar el peso esperado por edad para todas las especies.\nEn el panel izquierdo de la Figura¬†1 se puede observar que hay una relaci√≥n no lineal entre la edad y el peso. Tambi√©n se observan ciertos patrones comunes a las especies. Por ejemplo, la relaci√≥n positiva entre las variables o el decrecimiento en la tasa de cambio conforme la edad es mayor.\n\n\n\n\n\nFigura¬†1: (Izquierda) Edad (a√±os) vs Peso (kilogramos). (Derecha) Los mismos datos luego de aplicar la transformaci√≥n logar√≠tmica a ambas variables.\n\n\n\n\nSea \\(Y_{ij}\\) el peso y \\(X_{ij}\\) y la edad de la muestra \\(i\\) de la especie \\(j\\), con \\(j = 1, 2, 3, 4\\). Se propone el siguiente modelo:\n\\[\nY_{ij} = f_j(X_{ij}) \\epsilon_{ij}\n\\]\ndonde \\(f_j\\) es la verdadera curva de crecimiento para la especie \\(j\\) y \\(\\epsilon_{ij} > 0\\) es un error multiplicativo.\n\n¬øPor qu√© tiene sentido proponer un error multiplicativo?\n¬øCu√°l es un valor sensato para la media de la distribuci√≥n del error?\nUtilice una distribuci√≥n log-normal para el error, \\(\\log (\\epsilon_{ij}) \\sim \\text{Normal}\\). Proponga valores para la media y la varianza de forma tal que satisfagan la condici√≥n del punto anterior.\n\nEsto da lugar un al siguiente modelo log-normal para \\(Y_{ij}\\):\n\\[\n\\log (Y_{ij}) \\sim \\text{Normal}\n(\\log [f_j(X_{ij})] + \\mu_{\\log \\epsilon}, \\sigma^2_{\\log \\epsilon})\n\\]\ncon \\(\\mathbb{E}(Y_{ij}) = f_j(X_{ij})\\).\nA continuaci√≥n se proponen cuatro modelos que var√≠an seg√∫n la relaci√≥n funcional que se propone para \\(f_j\\) y la naturaleza de las distribuciones a priori que se utilizan.\nModelo 1\nObservando el panel derecho de la Figura¬†1 se puede concluir que luego de transformar ambas variables con la funci√≥n logaritmo la relaci√≥n se ve aproximadamente lineal. Por lo tanto, se propone el siguiente modelo log-lineal:\n\\[\n\\log [f_j(X)] = a_j + b_j \\log(X)\n\\]\ndonde \\(a_j\\) y \\(b_j\\) representan al intercepto y pendiente de la especie \\(j\\). La curva de crecimiento en la escala original resulta \\(f_j(X) = \\exp (a_j)X^{b_j}\\). Considere los siguientes priors:\n\\[\n\\begin{aligned}\na_j &\\sim \\text{Normal}(0, 10) \\\\\nb_j &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Realice gr√°ficos que permitan observar la curva ajustada y su incertidumbre para cada especie.\n\nModelo 2\nEste modelo es el mismo que el Modelo 1, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresi√≥n son modelados de manera jer√°rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_a    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_a &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\mu_b    &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma_b &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\na_j      &\\sim \\text{Normal}(\\mu_a, \\sigma^2_a) \\\\\nb_j      &\\sim \\text{Normal}(\\mu_b, \\sigma^2_b) \\\\\n\\sigma^2 &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los coeficientes del modelo y las curvas de crecimiento. Genere gr√°ficos similares a los producidos en el punto anterior. Describa similitudes y diferencias respecto del modelo 1. Justifique su respuesta.\n¬øQu√© problemas detecta los modelos 1 y 2? Considere como evoluciona el peso conforme la edad seg√∫n el modelo.\n\nModelo 3\nComo alternativa al componente log-lineal anterior, se propone la siguiente curva de crecimiento log√≠stico:\n\\[\nf_j(X) = a_j + b_j \\frac{\\exp [d_j (\\log(X) - c_j)]}{1 + \\exp [d_j(\\log(X) - c_j)]}\n\\]\nEste modelo tiene cuatro par√°metros:\n\n\\(a_j\\) es el peso esperado cuando la edad es 0\n\\(b_j\\) es el peso m√°ximo esperado (o la cota superior del peso)\n\\(\\log (c_j)\\) es la edad a la que la especie \\(j\\) alcanza la mitad del peso m√°ximo\n\\(d_j > 0\\) determina la tasa de crecimiento del peso conforme aumenta la edad\n\nPara que la curva sea positiva y creciente para todas las edades, se debe cumplir que \\(a_j > 0\\), \\(b_j > a_j\\) y \\(d_j > 0\\). Se pueden satisfacer estas restricciones expresando los par√°metros en funci√≥n de par√°metros cuyo dominio es \\(\\mathbb{R}\\).\n\n\\(a_j = \\exp (\\alpha_{j1})\\)\n\\(b_j = \\exp (\\alpha_{j2})\\)\n\\(c_j = \\alpha_{j3}\\)\n\\(d_j = \\exp (\\alpha_{j4})\\)\n\nConsidere las siguientes distribuciones a priori para los par√°metros del modelo:\n\\[\n\\begin{aligned}\n\\alpha_{jk} &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_j  &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los diagn√≥sticos de la inferencia realizada.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados.\n\nModelo 4\nEste modelo es el mismo que el Modelo 3, excepto que las especies tienen la misma varianza, \\(\\sigma^2_j = \\sigma^2\\) y los coeficientes de regresi√≥n son modelados de manera jer√°rquica. Utilice los siguientes priors:\n\\[\n\\begin{aligned}\n\\mu_k             &\\sim \\text{Normal}(0, 10) \\\\\n\\sigma^2_k        &\\sim \\text{InvGamma}(0.1, 0.1) \\\\\n\\log(\\alpha_{jk}) &\\sim \\text{Normal}(\\mu_k, \\sigma^2_k) \\\\\n\\sigma^2          &\\sim \\text{InvGamma}(0.1, 0.1)\n\\end{aligned}\n\\]\n\nEscriba un programa en Stan que implemente el modelo y obtenga el posterior con RStan.\nAnalice los diagn√≥sticos de la inferencia y compare con los resultados del modelo 3.\nGrafique las curvas estimadas para cada especie junto a sus intervalos de credibilidad e interprete los resultados. Compare con los resultados del modelo 3. ¬øQu√© diferencias observa? ¬øPor qu√© se dan?\nEscriba una s√≠ntesis comparando todos los modelos desarrollados. Comente ventajas y desventajas de cada uno de ellos, explicando a que se deben en cada caso ¬øQu√© modelo resulta m√°s conveniente para estimar la curva de crecimiento de los tiranos√°uridos? Justifique su respuesta.\n\nNota: Queremos usar los priors del libro? O mejor usamos otra cosa? Estoy mirando los InvGamma por ejemplo. √çdem con la notaci√≥n de varianza vs desv√≠o est√°ndar. \n\n\n\n\n\nReferencias\n\nDavidson-Pilon, Cameron. 2015. Bayesian Methods for Hackers: Probabilistic Programming and Bayesian Inference. 1st edition. Addison-Wesley Data; Analytics Series.\n\n\nErickson, Gregory M, Peter J Makovicky, Philip J Currie, Mark A Norell, Scott A Yerby, y Christopher A Brochu. 2004. ¬´Gigantism and comparative life-history parameters of tyrannosaurid dinosaurs¬ª. Nature 430: 772-75.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "practica/practica_04.html",
    "href": "practica/practica_04.html",
    "title": "Pr√°ctica - Unidad 4",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_04.html#regresi√≥n-lineal",
    "href": "practica/practica_04.html#regresi√≥n-lineal",
    "title": "Pr√°ctica - Unidad 4",
    "section": "Regresi√≥n lineal",
    "text": "Regresi√≥n lineal\n\nMi primer regresi√≥n bayesiana\nEl conjunto de datos sales contiene los montos semanales de inversi√≥n en publicidad y de ingresos de una determinada compa√±√≠a. Considere el siguiente modelo de regresi√≥n lineal simple:\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{publicidad}_i \\\\\n\\text{ventas}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\n\nAjuste el modelo utilizando {brms} y sus priors por defecto.\nConstruya un gr√°fico que muestre las ventas en funci√≥n de la inversi√≥n en publicidad y superponga la recta de regresi√≥n estimada.\n\nMejorando mi regresi√≥n bayesiana\nConsidere la siguiente versi√≥n del modelo del ejercicio anterior que propone distribuciones a priori para los par√°metros del modelo: \\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{publicidad}_i \\\\\n\\text{ventas}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2) \\\\\n\\beta_0 &\\sim \\text{Normal}(\\overline{\\text{ventas}}, 10) \\\\\n\\beta_1 &\\sim \\text{Normal}(0, 0.5) \\\\\n\\sigma^2 &\\sim \\text{Normal}^+(5)\n\\end{aligned}\n\\]\n\nAjuste el modelo utilizando {brms} y los priors sugeridos.\nConstruya un gr√°fico que muestre las ventas en funci√≥n de la inversi√≥n en publicidad, superponga la recta de regresi√≥n estimada, y el intervalo de credibilidad del 95% para la recta de regresi√≥n.\n\nComparando de lm() y brm()\nUtilice datos simulados para comparar la estimaci√≥n por m√≠nimos cuadrados con la estimaci√≥n Bayesiana en modelos de regresi√≥n.\n\nSimule 100 observaciones del modelo \\(Y = 2 + 3X + \\varepsilon\\) donde los valores del predictor \\(X\\) se obtienen de una distribuci√≥n \\(\\text{Uniforme}(0, 20)\\) y los errores son obtenidos de manera independiente de una distribuci√≥n \\(\\text{Normal}(0, 5^2)\\).\nAjuste el modelo de regresi√≥n utilizando lm() y brm() del paquete {brms} utilizando priors por defecto.\nVerifique que ambos m√©todos arrojan resultados similares.\nRepresente gr√°ficamente los datos y las dos rectas de regresi√≥n.\nIntente repetir la simulaci√≥n, pero esta vez cree las condiciones para que ambos enfoques den resultados diferentes. \n\nLa altura‚Ä¶ ¬øse hereda?\nEl conjunto de datos de las alturas (heights) contiene las alturas (en pulgadas) de 5524 pares de madres e hijas registradas en un estudio realizado por Karl Pearson y Alice Lee en 1903.\n\nElabore un gr√°fico que permita ver la relaci√≥n entre las alturas de las madres y las hijas. Aplique las t√©cnicas que crea necesaria para obtener una visualizaci√≥n informativa y fidedigna.\n¬øPor qu√© es adecuado utilizar un modelo de regresi√≥n lineal?\nAjuste el siguiente modelo de regresi√≥n lineal utilizando {brms} y priors por defecto:\n\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{altura\\_madre}_i \\\\\n\\text{altura\\_hija}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\n\nCalcule la media, el desv√≠o est√°ndar y el intervalo de credibilidad del 95% para los par√°metros del modelo utilizando el posterior.\nInterprete los coeficientes del modelo.\nSuperponga la recta de regresi√≥n en el gr√°fico donde se visualiza la relaci√≥n entre las variables.\nObtenga el posterior del peso medio de una hija cuya madre mide 58 pulgadas. \n\nClima en Australia\nEl conjunto de datos weather_WU datos clim√°ticos correspondientes a 100 d√≠as en dos ciudades de Australia: Uluru y Wollongong. Se intentar√° predecir la temperatura a las 3 de la tarde, utilizando otras variables.\nConsidere los siguientes cuatro modelos:\n\n\\(m_1\\): temp3pm ~ temp9am\n\\(m_2\\): temp3pm ~ location\n\\(m_3\\): temp3pm ~ temp9am + location\n\\(m_4\\): temp3pm ~ .\n\n\nAjuste cada uno de los modelos y construya gr√°ficas para mostrar los par√°metros obtenidos\nRealice pruebas predictivas a posteriori para comparar los modelos\nCompare los ELPD de cada modelo utilizando LOO \n\n\n\n\n\n\nParque Nacional Ulu·πüu-Kata Tju·πØa en Uluru, Australia. Foto de Snowscat en Unsplash\n\n\n\n\nPing√ºinos\nConsidere el dataset de ping√ºinos de Palmer (penguins) y los siguientes modelos:\n\n\\(m_1\\): body_mass_g ~ flipper_length_mm\n\\(m_2\\): body_mass_g ~ species\n\\(m_3\\): body_mass_g ~ flipper_length_mm + species\n\\(m_4\\): body_mass_g ~ flipper_length_mm + species + flipper_length_mm:species\n\\(m_5\\): body_mass_g ~ flipper_length_mm + bill_length_mm + bill_depth_mm\n\n\nAjuste cada uno de los modelos y construya gr√°ficas para mostrar los par√°metros obtenidos\nRealice pruebas predictivas a posteriori para comparar los modelos\nCompare los ELPD de cada modelo utilizando LOO \n\nDe tal palo‚Ä¶\nEl dataset child_iq contiene informaci√≥n de los resultados de tests de coeficiente intelectual de ni√±os de 3 a√±os, educaci√≥n de la madre, y edad de la madre cuando dio a luz.\n\nAjuste un modelo de regresi√≥n del puntaje del beb√© a los 3 a√±os en funci√≥n de la edad de la madre\nConsidere ahora un modelo que incluya la educaci√≥n de la madre\n\nLa pinta es lo de menos‚Ä¶\nHamermesh y Parker estudiaron la relaci√≥n entre los resultados de los estudiantes en un curso y la belleza de los instructores. La determinaci√≥n de la belleza se hizo a partir de las opiniones de seis estudiantes que no participaron de los cursos y no conoc√≠an las notas. Los datos se encuentran en el archivo beauty.\n\nConsidere un modelo de regresi√≥n courseevaluation ~ btystdave\nTo Do?\n\nIngresos\nEl dataset earnings contiene los resultados de la encuesta realizada por Ross sobre Trabajo, Familia y Bienestar.\n\nAjuste un modelo que prediga ingreso en funci√≥n de altura. ¬øQu√© transformaci√≥n ser√≠a necesaria para interpretar el intercepto como el ingreso promedio de una persona con altura promedio?\n\n!Kung\nLos !Kung son un pueblo que habita en el desierto de Kalahari entre Botsuana, Namibia y Angola. Hablan la lengua !Kung, que se destaca por su amplio uso de consonantes clic (chasquido conson√°ntico). El !K del nombre «ÉKung es un sonido como cuando sale un corcho de una botella.\nEl archivo Howell1 contiene datos de un censo parcial realizado por Dobe Howell acerca de la poblaci√≥n !Kung.\nConsidere un modelo de altura en funci√≥n del peso.\n\nDetermine e interprete las distribuciones a posteriori de los par√°metros\nConstruya un gr√°fico de altura en funci√≥n del peso, incluya las observaciones de los individuos, la recta de regresi√≥n MAP, el intervalo del 80% para la media y y el intervalo del 80% para la altura predicha.\nRealice predicciones para individuos cuyos pesos son: 46.95, 43.72, 64.78, 32.59 y 54.63. Calcule la altura esperada y el intervalo del 89%.\n\nZorros urbanos\nConsidere del conjunto de datos sobre zorros urbanos (foxes). Ajuste tres modelos:\n\n\\(m_1\\): weight ~ area\n\\(m_2\\): weight ~ groupsize\n\\(m_3\\): weight ~ area + groupsize\n\n\nPara los modelos \\(m_1\\) y \\(m_2\\), represente gr√°ficamente los resultados, incluyendo la recta de regresi√≥n MAP, su intervalo del 89% y el intervalo de predicci√≥n del 89%. ¬øEs alguna de las dos variables importantes para predecir la masa de un zorro?\nRepresentar gr√°ficamente las predicciones del modelo para cada predictor, dejando el otro constante en su valor medio. ¬øQu√© puede decirse sobre la importancia de las variables para predecir la masa de un zorro?\n\nUn prior informativo marca la diferencia\nConsidere el conjunto de datos sobre belleza y proporci√≥n de sexos (sexratio) . Estos datos provienen de un estudio de adolescentes estadounidenses cuyo atractivo en una escala de cinco puntos fue evaluado por entrevistadores en una encuesta cara a cara. A√±os m√°s tarde, muchos de estos encuestados tuvieron hijos y se registraron ciertos atributos entre los cuales se incluy√≥ el sexo. El objetivo del an√°lisis es comparar la proporci√≥n de sexos de los hijos seg√∫n la belleza de los padres. Para ello considere el siguiente modelo de regresi√≥n:\n\\[\n\\begin{aligned}\n\\mu_i &= \\beta_0 + \\beta_1 \\text{belleza}_i \\\\\n\\text{pf}_i &\\sim \\text{Normal}(\\mu_i, \\sigma^2)\n\\end{aligned}\n\\]\nDonde \\(\\text{pf}\\) representa la proporci√≥n de beb√©s de sexo femenino y \\(\\text{belleza}\\) representa el grupo de belleza de los padres.\n\nAjuste el modelo utilizando m√≠nimos cuadrados.\nAjuste el modelo con brm() y sus priors por defecto.\nCompare el ajuste de ambos modelos.\nExplore los priors utilizados por {brms} y la distribuci√≥n predictiva a priori. ¬øQu√© puede concluir?\nProponga distribuciones a priori informativas.\nAjuste el modelo utilizando brm() y los priors informativos.\nCompare el resultado con los obtenidos anteriormente y concluya.\n\n¬°A la pesca de priors!\nEl conjunto de datos fish-market contiene mediciones morfol√≥gicas realizadas sobre pescados de diferentes especies. El objetivo es construir un modelo de regresi√≥n lineal que permita predecir el peso de los pescados en base a sus otros atributos.\nUno de los modelos propuestos es el siguiente:\n\\[\n\\begin{aligned}\n\\log(\\text{Weight}_i) &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i  &= \\beta_{0, j[i]} + \\beta_{1, j[i]} \\log(\\text{Length1}_i)\n\\end{aligned}\n\\]\n\\(\\text{Weight}_i\\) es el peso del i-√©simo pescado en gramos y \\(\\text{Length1}_i\\) es la longitud del i-√©simo pescado en cent√≠metros. La letra \\(j\\) indexa las especies de los pescados. Por lo tanto, en este modelo cada especie tiene su propio intercepto y pendiente.\n\nImplemente el modelo utilizando {brms} y los siguientes priors no informativos \\[\n\\begin{aligned}\n\\beta_{0, j[i]} &\\sim \\text{Normal}(0, 10) \\\\\n\\beta_{1, j[i]} &\\sim \\text{Normal}(0, 5)\n\\end{aligned}\n\\]\nObtenga y visualice la distribuci√≥n predictiva a priori.\nElabore un gr√°fico y describa la funci√≥n de densidad a priori de los par√°metros \\(\\beta_{0, j[i]}\\) y \\(\\beta_{1, j[i]}\\).\nProponga priors m√°s adecuados en base a la interpretaci√≥n de los par√°metros del modelo y la informaci√≥n que tenga del problema.\nNuevamente, obtenga y visualice la distribuci√≥n predictiva a priori y compare con el resultado obtenido anteriormente.\nAjuste el modelo, obtenga la distribuci√≥n predictiva a posteriori y graf√≠quela.\n\n\n\n\n\n\nEspecies de peces de todas variedades y tama√±os.\n\n\n\n\nEn b√∫squeda del modelo adecuado\nContinuando con los datos del ejercicio anterior, El objetivo es construir un modelo de regresi√≥n lineal que permita predecir el peso de los pescados en base a sus otros atributos.\nConsidere los siguientes modelos\n\n\\(m_1\\): log(Weight) ~ 0 + Species\n\\(m_2\\): log(Weight) ~ 0 + Species + log(Length1)\n\\(m_3\\): log(Weight) ~ 0 + Species + log(Length1):Species\n\\(m_4\\): log(Weight) ~ 0 + Species + log(Length1):Species + log(Height)\n\\(m_5\\): log(Weight) ~ 0 + Species + log(Length1):Species + log(Height):Species\n\n\nAjuste cada uno de los modelos.\nEstime el ELPD de cada modelo utilizando LOO y seleccione el modelo m√°s adecuado de acuerdo a este criterio.\nExplique el resultado.\n\nComparaci√≥n de modelos\nSe recopilaron datos (mesquite) con el fin de desarrollar un m√©todo para estimar la producci√≥n total (biomasa) de hojas de mesquite utilizando par√°metros f√°cilmente medibles de la planta, antes de que se realice la cosecha real. Se tomaron dos conjuntos separados de mediciones, uno en un grupo de 26 arbustos de mesquite y otro en un grupo diferente de 20 arbustos de mesquite medidos en un momento diferente del a√±o. Todos los datos se obtuvieron en la misma ubicaci√≥n geogr√°fica, pero ninguno constituy√≥ una muestra estrictamente aleatoria. La variable de resultado es el peso total (en gramos) de material fotosint√©tico obtenido de la cosecha real del arbusto. Las variables de entrada son:\n\n\n\n\n\n\n\nNombre\nDescripci√≥n\n\n\n\n\ndiam1\nDi√°metro de la copa medido a lo largo del eje m√°s largo del arbusto (metros)\n\n\ndiam2\nDi√°metro de la copa medido a lo largo del eje m√°s corto (metros)\n\n\ncanopy_height\nAltura de la copa\n\n\ntotal_height\nAltura total del arbusto\n\n\ndensity\nN√∫mero de tallos primarios por planta\n\n\ngroup\nGrupo de mediciones (0 para el primer grupo, 1 para el segundo)\n\n\n\n\nRealice un an√°lisis exploratorio de los datos.\nAjuste el modelo weight ~ diam1 + diam2 + canopy_height + total_height + density + group.\nExplore y describa el posterior.\nEstime ELPD mediante PSIS-CV con la funci√≥n loo(), analice los valores de las estimaciones del par√°metro \\(k\\) de la distribuci√≥n generalizada de Pareto y otros valores de la salida que crea relevant, ¬øqu√© puede concluir?\nEstime ELPD mediante K-fold cross validation con \\(K=10\\). Compare la estimaci√≥n con el resultado obtenido mediante PSIS-CV y concluya.\nAjuste el modelo transformando todas las variables num√©ricas con la funci√≥n logar√≠tmica. ¬øC√≥mo afecta esta transformaci√≥n la interpretaci√≥n de los coeficientes?\nEstime ELPD mediante PSIS-CV con la funci√≥n loo(). Concluya acerca de la estabilidad del c√≥mputo. ¬øEs posible comparar la la estimaci√≥n con la obtenida en el inciso iv? ¬øPor qu√©?\nCon ambos modelos, obtenga y grafique la distribuci√≥n predictiva a posteriori compar√°ndola con los datos observados ¬øCu√°l de los modelos representa mejor a los datos?\n\n\n\n\n\n\nUn √°rbol de mesquite.Foto de Sergei Bogomyakov, Alamy Stock Photo.\n\n\n\n\n\n\nSecundarios en Portugal\nSe cuenta con un conjunto de datos sobre 343 estudiantes de secundaria de Portugal (portugal) y se desea predecir la calificaci√≥n final en matem√°ticas del √∫ltimo a√±o en base a un gran n√∫mero de predictores potencialmente relevantes.\nEl listado de variables se compone por: escuela del estudiante, sexo del estudiante, edad del estudiante, tipo de domicilio del estudiante, tama√±o de la familia, estado de convivencia de los padres, educaci√≥n de la madre, educaci√≥n del padre, tiempo de viaje del hogar a la escuela, tiempo de estudio semanal, n√∫mero de fracasos escolares pasados, apoyo educativo adicional, clases pagadas adicionales dentro de la materia del curso, actividades extracurriculares, si el estudiante asisti√≥ a una guarder√≠a, si el estudiante desea cursar estudios superiores, acceso a Internet en el hogar, si el estudiante tiene una relaci√≥n rom√°ntica, calidad de las relaciones familiares, tiempo libre despu√©s de la escuela, si el estudiante sale con amigos, consumo de alcohol entre semana, consumo de alcohol los fines de semana, estado de salud actual y n√∫mero de ausencias escolares.\nPriors d√©bilmente informativos\n\nAjuste un modelo de regresi√≥n lineal utilizando todos los predictores luego de estandarizarlos y con los siguientes priors \\[\n\\begin{aligned}\n\\beta_k &\\sim \\text{Normal}(0, 2.5) \\\\\n\\sigma  &\\sim \\text{Exponential}(1 / \\text{std}(y))\n\\end{aligned}\n\\]\nElabore un gr√°fico para visualizar los posteriors marginales y comp√°relos. ¬øQu√© puede concluir acerca de su incertidumbre?\nCalcule y compare la mediana del \\(R^2\\) bayesiano y del \\(R^2\\) calculado mediante LOO ¬øQu√© conclusi√≥n puede extraer de esta comparaci√≥n?\n¬øCu√°l es el n√∫mero efectivo de par√°metros seg√∫n LOO? ¬øQu√© indica?\nObtenga muestras del prior y del posterior del \\(R^2\\) bayesiano, comp√°relos utilizando una visualizaci√≥n y concluya considerando la elecci√≥n de los priors d√©bilmente informativos sobre \\(\\beta_k\\) y \\(\\sigma\\).\n\nPriors alternativos (I)\nSi se asume que muchos predictores pueden tener poca relevancia, se pueden escalar los priors independientes para que la suma de la varianza de los priors se encuentre alrededor de un valor razonable. En este caso, se cuenta con 26 predictores y se podr√≠a suponer que la proporci√≥n de la varianza explicada por los predictores est√° alrededor de 0.3. Entonces, un enfoque simple consiste en asignar priors independientes a los coeficientes de regresi√≥n con media 0 y desviaci√≥n est√°ndar \\(\\sqrt{0.3/26}\\text{sd}(y)\\) y un prior exponencial con media \\(\\sqrt{0.7}\\text{sd}(y)\\) para \\(\\sigma\\).\n\nAjuste el modelo nuevamente utilizando los siguientes priors \\[\n\\begin{aligned}\n\\beta_k &\\sim \\text{Normal}(0, \\sqrt{\\frac{0.3}{26}}\\text{sd}(y)) \\\\\n\\sigma  &\\sim \\text{Exponential}(1 / \\sqrt{0.7}\\text{sd}(y))\n\\end{aligned}\n\\]\nExplore la distribuci√≥n a priori sobre \\(R^2\\) y comp√°rela con la distribuci√≥n obtenida con los priors d√©bilmente informativos.\nCalcule ELPD mediante LOO y compare este modelo con el anterior.\nElabore un gr√°fico para visualizar los posteriors marginales. Compare este resultado con el obtenido con los priors d√©bilmente informativos.\n\nPriors alternativos (II)\nOtra alternativa es asumir que solo algunos de los predictores tienen alta relevancia y que el resto de los predictores tienen una relevancia insignificante. Una posibilidad para modelar bajo este supuesto es el horseshoe prior regularizado1. Este prior utiliza distribuciones normales independientes con media 0 y varianza \\(\\tau^2\\lambda_k^2\\) para los coeficientes de regresi√≥n \\(\\beta_k\\) y se describe a continuaci√≥n:\n\\[\n\\begin{aligned}\n\\beta_k   &\\sim \\text{Normal}(0, \\tau^2\\tilde{\\lambda}_k^2) \\\\\n\\tilde{\\lambda}_k^2 &= \\frac{c^2\\lambda_k^2}{c^2 + \\tau^2\\lambda_k^2} \\\\\nc & = \\sqrt{c'} \\text{SS} \\\\\nc' &\\sim \\text{InvGamma}(0.5 \\cdot SDF, 0.5 \\cdot SDF) \\\\\n\\lambda_k &\\sim \\text{StudentT}^+(\\text{df} = 1, \\mu = 0, \\sigma = 1 ) \\\\\n\\tau      &\\sim \\text{StudentT}^+(\\text{df} = 1, \\mu = 0, \\sigma = \\text{GS})\n\\end{aligned}\n\\]\ncon \\[\n\\begin{aligned}\n\\text{GS} = \\frac{p_0}{p - p_0} \\frac{\\sigma}{\\sqrt{n}} \\\\\n\\text{SS} = \\sqrt{\\frac{0.3}{p_0}} \\text{sd}(y) \\\\\n\\text{SDF} = 4\n\\end{aligned}\n\\]\ndonde \\(\\text{GS}\\), \\(\\text{SS}\\) y \\(\\text{SDF}\\) representan global scale, slab scale y slab degrees of freedom, respectivamente. Adem√°s, \\(p\\) representa la cantidad de predictores, 26, y \\(p_0\\) la cantidad de predictores que se espera que sean relevantes.\nIntuitivamente, el par√°metro global \\(\\tau\\) empuja todos los \\(\\beta_k\\) hacia el 0, mientras que los par√°metros locales \\(\\lambda_k\\) contribuyen a que algunos de los \\(\\beta_k\\) escapen del 0.\n\nUtilice \\(p_0 = 6\\) para ajustar el modelo con todos los predictores y grafique y analice los posteriors marginales.\nCompare este modelo con los ajustados anteriormente en base a sus ELPD estimados con LOO y concluya.\n\nPriors d√©bilmente informativos con menos predictores\nAjuste el modelo de regresi√≥n con un subconjunto de predictores que crea conveniente y los priors d√©bilmente informativos que se utilizaron inicialmente.\n\nVisualice los posteriors marginales.\nNuevamente, calcule y compare la mediana del \\(R^2\\) bayesiano y del \\(R^2\\) calculado mediante.\nCompare este modelo con el ajustado anteriormente en base a sus ELPD estimados con LOO y concluya sobre la capacidad predictiva de este modelo."
  },
  {
    "objectID": "practica/practica_00.html",
    "href": "practica/practica_00.html",
    "title": "Pr√°ctica - Unidad 0",
    "section": "",
    "text": "Descargar PDF\n\n\nDe las siguientes expresiones cual(es) se corresponde(n) con el enunciado ‚Äúla probabilidad de que Argentina gane la copa del mundo el 18 de Diciembre de 2022‚Äù?\n\n\\(P(\\text{18 de Diciembre de 2022} | \\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon})\\)\n\\(P(\\text{Argentina campeon}, \\text{18 de Diciembre de 2022}) / P(\\text{18 de Diciembre de 2022})\\)\n\\(P(\\text{Argentina campeon} | \\text{Diciembre})\\)\n\\(P(\\text{Argentina campeon} | \\text{18 de Diciembre de 2022})\\) \n\nEnuncie con palabras cada una de las expresiones del punto anterior. \nSeg√∫n la definici√≥n de probabilidad condicional\n\n¬øCu√°l es el valor de \\(P(A | A)\\)?\n¬øCu√°l es la probabilidad de \\(P(A, B)\\)?\n¬øCu√°l es la probabilidad de \\(P(A, B)\\) en el caso que \\(A\\) y \\(B\\) sean independientes?\nCuando se cumple que \\(P(A | B) = P(A)\\)?\nEs posible que \\(P(A | B) > P(A)\\)? Cuando?\nEs posible que \\(P(A | B) < P(A)\\)? Cuando? \n\nSea \\(X\\) una variable aleatoria con soporte \\(X \\in \\mathcal{S} = [1, \\infty)\\). Encuentre la constante \\(c\\), en funci√≥n de \\(\\theta\\), que haga que \\(f(x) = c \\exp(-x / \\theta)\\) sea una funci√≥n de densidad de probabilidad v√°lida. \nSuponga \\(X \\sim \\text{Uniforme}(a, b)\\). Su soporte es \\(\\mathcal{S} = [a, b]\\) y su funci√≥n de densidad de probabilidad es \\(f(x) = 1 / (b - a)\\) para todo \\(x \\in \\mathcal{S}\\).\n\nPruebe que \\(f(x)\\) es una funci√≥n de densidad de probabilidad v√°lida.\nEncuentre la media y la varianza de \\(X\\). \n\nSeg√∫n personas expertas en un problema determinado, se indica que el valor de un par√°metro debe ser positivo y su distribuci√≥n a priori debe tener media igual a 5 y varianza igual a 3. Encuentre una distribuci√≥n que satisfaga estas condiciones. \nSean \\(X_1\\) y \\(X_2\\) dos variables aleatorias con funci√≥n de probabilidad conjunta dada por la siguiente tabla\n\n\n\n\n\n\\(X_1\\) / \\(X_2\\)\n\\(X_2=0\\)\n\\(X_2=1\\)\n\n\n\n\n\\(X_1=0\\)\n\\(0.15\\)\n\\(0.15\\)\n\n\n\\(X_1=1\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\\(X_2=2\\)\n\\(0.15\\)\n\\(0.20\\)\n\n\n\n\n\ndonde la celda de la primer fila y primer columna se lee \\(P(X_1=0, X_2=0)=0.15\\)\n\nObtenga la distribuci√≥n marginal de \\(X_1\\).\nObtenga la distribuci√≥n marginal de \\(X_2\\).\nObtenga la distribuci√≥n condicional de \\(X_1\\) dado \\(X_2\\).\nObtenga la distribuci√≥n condicional de \\(X_2\\) dado \\(X_1\\). \n\nSean \\(X_1\\) y \\(X_2\\) tales que \\((X_1, X_2)\\) siguen una distribuci√≥n normal bivariada con \\(\\mathbb{E}(X_1) = \\mathbb{E}(X_1)\\) = 0, \\(\\text{Var}(X_1) = \\text{Var}(X_2 = 1)\\) y \\(\\text{cor}(X_1, X_2) = \\rho\\)\n\nEncuentre la distribuci√≥n marginal de \\(X_1\\).\nEncuentre la distribuci√≥n condicional de \\(X_1\\) dado \\(X_2\\). \n\nSuponga una urna \\(S\\) contiene un 40% de bolas verdes y un 60% de bolas rojas, y otra urna \\(E\\) contiene un 60% de bolas verdes y un 40% de bolas rojas. Una persona arroja una moneda de un peso argentino y selecciona una bola de una de las dos urnas dependiendo de si la moneda en sol o escudo. Si la moneda cae en sol, saca una bola de la urna \\(S\\) y si la moneda cae en escudo, saca una bola de la urna \\(E\\).\nConsidere las siguientes variables aleatorias:\n\\[\n\\begin{aligned}\nX &=\n    \\begin{cases}\n    1 & \\text{Si la moneda cae en sol} \\\\\n    0 & \\text{Si la moneda cae en escudo}\n    \\end{cases}\n\\\\\n\\\\\nY &=\n    \\begin{cases}\n    1 & \\text{Si la bola es verde} \\\\\n    0 & \\text{Si la bola es roja}\n    \\end{cases}\n\\end{aligned}\n\\]\n\nEncuentre la distribuci√≥n conjunta de \\(X\\) e \\(Y\\) en una tabla.\nEncuentre \\(\\mathbb{E}(Y)\\). ¬øCu√°l es la probabilidad de que la bola sea verde?\nEncuentre \\(\\text{Var}(Y | X = 0)\\), \\(\\text{Var}(Y | X = 1)\\) Y \\(\\text{Var}(Y)\\). Considerando a la varianza como una medida de incertidumbre, explique de manera intuitiva por que algunas variancias son mas grandes que otras.\nSuponga que observa que la bola es verde. ¬øCu√°l es la probabilidad de que la moneda haya caido en escudo? \n\n\n\n\n\n\nMoneda de un peso argentino acu√±ada en 1995\n\n\n\n\nLas luces de giro en los autom√≥viles se utilizan para indicar que se va a realizar alguna acci√≥n determinada. La acci√≥n depende del escenario donde se conduzca (urbano, ruta, rotonda, etc.) y la luz que se encienda (izquierda o derecha). En el uso urbano, se debe colocar la luz de giro correspondiente para indicar que se va a girar en un sentido determinado. Sin embargo, esto no siempre se realiza. Muchas veces sucede que un veh√≠culo no muestra luz de giro, y sin embargo gira. Aunque menos frecuente, tambi√©n se da que el veh√≠culo colca la luz de giro, pero no gira. La probabilidad de girar dado que se colca la luz de giro es 0.87 y la probabilidad de girar dado que no se coloca la luz de giro es 0.21. Si observa que un veh√≠culo coloca la luz de giro, ¬øcu√°l es la probabilidad de que efectivamente doble?\nProblema del cumplea√±os\nHay \\(k\\) personas en una sala. Suponga que el cumplea√±os de cada persona tiene la misma probabilidad de ocurrir en cualquiera de los 365 d√≠as del a√±o (se excluye el 29 de Febrero) y que los cumplea√±os de las personas son independientes entre si. ¬øCu√°l es la probabilidad de que al menos un par de personas en el grupo cumplan los a√±os el mismo d√≠a? \nProblema de concordancia de de Montmort\nConsidere un mazo de \\(n\\) cartas bien mezcladas, etiquetadas con n√∫meros del 1 a \\(n\\). Se seleccionan las cartas de a una y se la da vuelta, diciendo en voz alta el n√∫mero de cartas dadas vueltas desde 1 a \\(n\\). Para ganar el juego tiene que coincidir el n√∫mero que se dice en voz alta con el n√∫mero de la carta que se est√° dando vuelta ‚Äì por ejemplo, si la s√©ptima carta dada vuelta contiene el n√∫mero 7. ¬øCu√°l es la probabilidad de ganar? ¬øDepende de \\(n\\)? \nProblema de los dos sobres\nSupongamos que te presentan dos sobres con dinero. Un sobre contiene el doble de dinero que el otro, pero a simple vista son indistinguibles. Se te pide que escogas uno de los sobres. Antes de abrirlo se te ofrece la posibilidad de cambiarlo por el otro. ¬øCambiar√≠as el sobre? ¬øPor qu√©?   \n\n\n\n\n\nReferencias\n\nHoff, Peter D. 2009. A First Course in Bayesian Statistical Methods. 1st edition. Springer.\n\n\nMartin, Osvaldo A., Ravin Kumar, y Junpeng Lao. 2021. Bayesian Modeling and Computation in Python. 1st edition. Chapman; Hall/CRC.\n\n\nReich, Brian J., y Sujit K. Ghosh. 2019. Bayesian Statistical Methods. 1st edition. Chapman; Hall/CRC."
  },
  {
    "objectID": "practica/practica_02.html",
    "href": "practica/practica_02.html",
    "title": "Pr√°ctica - Unidad 2",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "href": "practica/practica_02.html#modelos-de-distribuciones-conjugadas",
    "title": "Pr√°ctica - Unidad 2",
    "section": "Modelos de Distribuciones Conjugadas",
    "text": "Modelos de Distribuciones Conjugadas\nEsta secci√≥n contiene ejercicios para trabajar con modelos basados en distribuciones conjugadas. En general, los ejercicios requieren c√°lculos o derivaciones que se pueden realizar a mano. Sin embargo, se promueve fuertemente el uso de la computadora y el lenguaje R para verificar los resultados, mostrar soluciones alternativas y ejercitar el uso de una herramienta que ser√° de suma utilidad a lo largo de todo el curso y de la vida profesional.\n\n¬øQui√©n domina el posterior?\nPara cada una de las situaciones siguientes, se da una distribuci√≥n a priori Beta para el par√°metro \\(\\pi\\) de un ensayo binomial. Para cada escenario, identificar cu√°l de estos se cumple: el prior tiene mayor influencia en el posterior, los datos tienen m√°s influencia en el posteriori, o la creencia a priori y los datos influyen de manera similar en la creencia a posteriori\n\nPrior: \\(\\pi \\sim \\text{Beta}(1,4)\\), observaciones: \\(y=8\\) √©xitos en \\(n=10\\) ensayos\nPrior: \\(\\pi \\sim \\text{Beta}(20,3)\\), observaciones: \\(y=0\\) √©xitos en \\(n=1\\) ensayos\nPrior: \\(\\pi \\sim \\text{Beta}(4,2)\\), observaciones: \\(y=1\\) √©xitos en \\(n=3\\) ensayos\nPrior: \\(\\pi \\sim \\text{Beta}(3,10)\\), observaciones: \\(y=10\\) √©xitos en \\(n=13\\) ensayos\nPrior: \\(\\pi \\sim \\text{Beta}(20,2)\\), observaciones: \\(y=10\\) √©xitos en \\(n=200\\) ensayos\n\nM√°s o menos certeza\nSea \\(\\theta\\) la proporci√≥n de personas que prefieren los perros a los gatos. Suponga que se elige una distribuci√≥n \\(\\text{Beta}(7,2)\\) para representar la creencia a priori\n\nDe acuerdo al prior ¬øcu√°les son valores razonables para \\(\\theta\\)?\nSe observa en una encuesta que \\(y=19\\) de \\(n=20\\) personas prefieren perros, ¬øc√≥mo cambia eso el conocimiento acerca de \\(\\theta\\)? Comenta en t√©rminos de la evoluci√≥n de la credibilidad media y del grado de certidumbre acerca de \\(\\theta\\).\nSi, en lugar de eso, se determina que \\(y=1\\) de \\(n=20\\) personas prefieren perros, ¬øc√≥mo cambia ahora el grado de credibilidad de los diferentes valores de \\(\\theta\\)?\nSi, en lugar de eso, se determina que \\(y=10\\) de \\(n=20\\) personas prefieren perros, ¬øc√≥mo cambia ahora el grado de credibilidad de los diferentes valores de \\(\\theta\\)?\n\nPasito a pasito\nSea \\(\\theta\\) la probabilidad de √©xito de un evento de inter√©s. Sea \\(\\text{Beta}(2,3)\\) la distribuci√≥n a priori para \\(\\theta\\). Actualiza la distribuci√≥n a posteriori para \\(\\theta\\) secuencialmente:\n\nPrimera observaci√≥n: √©xito\nSegunda observaci√≥n: √©xito\nTercera observaci√≥n: fracaso\nCuarta observaci√≥n: √©xito\n\nPasitos tras pasitos\nSea \\(\\theta\\) la probabilidad de √©xito de un evento de inter√©s. Sea \\(\\text{Beta}(2,3)\\) la distribuci√≥n a priori para \\(\\theta\\). Actualiza la distribuci√≥n a posteriori para \\(\\theta\\) secuencialmente dados conjuntos de cinco observaciones:\n\nPrimeras observaciones: tres √©xitos\nSegundas observaciones: un √©xito\nTerceras observaciones: un √©xito\nCuartas observaci√≥nes: dos √©xitos\n\nDiferentes observaciones, diferentes posteriors\nUna empresa que fabrica zapatillas est√° dise√±ando una publicidad para Instagram. Tres empleados comparten que la creencia a priori para \\(\\pi\\), la probabilidad de que un cliente haga clic en el anuncio cuando lo ve, puede expresarse con una distribuci√≥n \\(\\text{Beta}(4, 3)\\). No obstante, los tres empleados realizan tres experimentos distintos y por ende tienen acceso a datos diferentes. El primer empleado prueba el anuncio en una persona, que no cliquea el anuncio. El segundo lo prueba en 10 personas, de las cuales 3 cliquean el anuncio. El √∫ltimo lo prueba en 100 personas, 20 de las cuales cliquean el anuncio.\n\nDescriba el entendimiento a priori que los empleados tienen sobre \\(\\pi\\)\nEspecifique la distribuci√≥n a posteriori de cada uno de los empleados\nCompare las distribuciones a posteriori de cada empleado\n\n¬øGalletitas o masitas?\nLa UNR re√∫ne cada a√±o a estudiantes provenientes de diferentes localidades. Cu√°ntas cuadras constituyen una distancia ‚Äúcaminable‚Äù suele ser motivo de discusi√≥n, entre otros. Pero la verdadera grieta est√° entre la denominaci√≥n galletitas versus masitas. Un rosarino pone un prior \\(\\text{Beta}(20,2)\\) a la proporci√≥n de personas que dicen galletitas, mientras que un oriundo de una localidad del interior dir√° que la credibilidad a priori es \\(\\text{Beta}(2,8)\\).\n\nResuma ambas distribuciones a priori y explique con sus palabras lo que implican\nCon la informaci√≥n de sus compa√±erxs de curso, actualice ambas distribuciones a priori. ¬øEs suficiente esa informaci√≥n para acercar ambas posturas?\n\nMi primera huerta\nEn un campamento de verano para infantes se realizaron actividades que promueven el contacto con la naturaleza. Una de las tareas consisti√≥ en germinar semillas de tomate. Josefina plant√≥ 18 semillas en su almaciguera. Al cabo de 5 d√≠as, 8 de ellas germinaron. Sea \\(\\theta\\) la probabilidad de que una semilla de tomate germine y sea \\(\\text{Beta}(1, 1)\\) su distribuci√≥n a priori.\n\n¬øQu√© informaci√≥n implica el prior sobre la probabilidad de germinaci√≥n?\nCalcule la media y el desv√≠o est√°ndar a posteriori de \\(\\theta\\) a mano.\nVerifique el c√°lculo utilizando R.\nObtenga un intervalo de credibilidad del 95% para \\(\\theta\\).\n\nA mano\nUsando R\n\n\n\n\n\n\n\nFoto de Markus Spiske en Unsplash\n\n\n\n\n¬øQui√©n dijo que el f√∫tbol siempre da revancha?\nEn la final del 2018 de la Copa del Mundo de la FIFA, Francia le gan√≥ a Croacia por 4 a 2. En funci√≥n de este resultado,\n\n¬øQu√© probabilidad hay de que Francia fuera un mejor equipo que Croacia?\nSi el mismo partido se jugara de nuevo (cosa que los franceses en aquella oportunidad no pidieron), ¬øcu√°l es la probabilidad de que Francia ganara de nuevo? \n\nMir√° si me va a pasar a mi‚Ä¶\nDurante el desarrollo de las vacunas contra el COVID-19, un medio anunci√≥ para una determinada vacuna una eficacia del 100%.\n\nEn la fase 3 de un ensayo en adolescentes de entre 12 y 15 a√±os, la vacuna BNT162b2 de Pfizer-BioNTech para el COVID-19 demostr√≥ una eficacia del 100% y una respuesta robusta de anticuerpos. El ensayo cl√≠nico involucr√≥ 2260 j√≥venes estadounidenses. En el ensayo, 18 casos de COVID-19 fueron observados en el grupo placebo (\\(n=1129\\)) y ninguno en el grupo vacunado (\\(n=1131\\))\n\nEs de esperar que, en un ensayo m√°s grande, aparezca alg√∫n caso de COVID-19 en el grupo que recibi√≥ el tratamiento. ¬øC√≥mo se estima la probabilidad de algo que a√∫n no ocurri√≥? \nLa regla del tres\nUna estudiante de Licenciatura en Estad√≠stica est√° releyendo su tesina antes de entregarla. Si en 20 p√°ginas encontrara 5 typos, ser√≠a razonable estimar \\(\\frac{5}{20} = \\frac{1}{4}\\) typos por p√°gina. ¬øPero qu√© ocurre si en 20 p√°ginas no encuentra ning√∫n error?\nVerifcar que, partiendo de un prior uniforme, \\(\\frac{3}{N}\\) es una estimaci√≥n razonable para \\(\\tau\\) (la tasa de typos por p√°gina), siendo \\(N\\) el n√∫mero de p√°ginas. Para ello, hallar la probabilidad de que \\(\\tau > \\frac{3}{N}\\) para diferentes valores de \\(N\\). \n¬øTen√©s alguien para recomendar?\nUna colega quiere comprar un producto por Internet. Tres vendedores ofrecen el mismo producto al mismo precio. Un vendedor tiene 100% de evaluaciones positivas, con 10 reviews. Otro tiene 96% de evaluaciones positivas, con 50 reviews. El √∫ltimo tiene 90% de comentarios positivos, con 200 evaluaciones. ¬øCu√°l de los tres vendedores le recomendar√≠as? \nBichos\nUn bi√≥logo quiere determinar la densidad de un insecto en su regi√≥n. Su conocimiento a priori del n√∫mero promedio de insectos por unidad de √°rea (\\(\\text{m}^2\\)) se puede representar con una distribuci√≥n Gamma de media 0.50 y desv√≠o est√°ndar 0.25. En una investigaci√≥n en 20 \\(\\text{m}^2\\) de √°rea, se hallan 3, 2, 5, 1 y 2 insectos en los primeros 5 \\(\\text{m}^2\\) y ninguno en la fracci√≥n de tierra restante.\n\nHalle la distribuci√≥n a posteriori del n√∫mero medio de insectos por unidad de √°rea\nHalle la distribuci√≥n predictiva a posteriori del n√∫mero de insectos que se espera encontrar en una exploraci√≥n de un √°rea de 10 \\(\\text{m}^2\\)\n\nAlter-ego\nEl profesor Caprista y el profesor Evangetto est√°n dando sus primeros cursos de Estad√≠stica Bayesiana. Sus colegas les dijeron que el puntaje promedio en un examen final, \\(\\mu\\), var√≠a normalmente a√±o a a√±o con media 8 y desv√≠o est√°ndar 0.4. Y adem√°s, que los puntajes individuales de lxs estudiantes \\(Y\\) var√≠an normalmente alrededor de \\(\\mu\\) con una desviaci√≥n est√°ndar de 0.4\n\n¬øCu√°l es la probabilidad a priori de que un estudiante se saque m√°s de 9 en un examen final?\nEl profesor Caprista toma el examen final y observa que sus 20 estudiantes obtuvieron una nota media de 8.6. Halle la distribuci√≥n a posteriori de \\(\\mu\\).\nEl profesor Evangetto toma el examen final y observa que sus 20 estudiantes obtuvieron una nota media de 8.2. Halle la distribuci√≥n a posteriori de \\(\\mu\\).\nCombine las notas de ambos ex√°menes para obtener la distribuci√≥n a posteriori de \\(\\mu\\)\n¬øCu√°l es la probabilidad a posteriori de que un estudiante se saque m√°s de 9 en un examen final?\n\nInferencia sobre una distribuci√≥n de Poisson\nLa distribuci√≥n de masa de probabilidad Poisson se define como\n\\[\n\\begin{array}{lcr}\n\\displaystyle p(x | \\lambda) = \\frac{e^{-\\lambda}\\lambda^x}{x!} &\n\\text{con} &\nx \\in \\{0, 1, 2, \\cdots \\}\n\\end{array}\n\\]\ndonde \\(\\lambda > 0\\) es la cantidad promedio de veces que ocurre el evento de inter√©s en un periodo o espacio determinado.\n\nDerive el estimador de m√°xima verosimilitud del par√°metro \\(\\lambda\\).\nDerive el posterior \\(p(\\lambda|D)\\) suponiendo que el prior sobre \\(\\lambda\\) es \\(p(\\lambda) = \\text{Gamma}(\\lambda | a, b) \\propto \\lambda^{\\alpha-1}e^{-\\lambda b}\\).\nAyuda: El posterior tambi√©n es una distribuci√≥n Gamma.\n¬øA qu√© valor tiende la media a posteriori cuando \\(a \\to 0\\) y \\(b \\to 0\\)?\nRecuerde que la media de una distribuci√≥n \\(\\text{Gamma}(a, b)\\) es \\(a/b\\). \n\nEl modelo Gamma-Poisson\nSea \\(\\lambda\\) la tasa de mensajes de WhatsApp que una persona recibe en una hora. Suponga inicialmente que se cree que la tasa de mensajes por hora tiene media 5 con desv√≠o est√°ndar de 0.25 mensajes.\n\nElija una distribuci√≥n Gamma que represente adecuadamente lo que se cree acerca de \\(\\lambda\\)\n¬øCu√°l es la probabilidad a priori de que la tasa de mensajes sea mayor a 10?\n¬øCu√°ntos mensajes se espera que reciba una persona en promedio en una hora?\n\nSe sondea a un grupo de seis personas que recibieron 7, 3, 8, 9, 10 y 12 mensajes en la √∫ltima hora.\n\nGraficar la verosimilitud de \\(\\lambda\\)\nDeterminar la distribuci√≥n a posteriori de \\(\\lambda\\)\n¬øCu√°l es la probabilidad a posteriori de que la tasa de mensajes sea mayor a 10?\n¬øCu√°ntos mensajes se espera ahora que reciba una persona en promedio en una hora?\n\nInferencia sobre una distribuci√≥n Uniforme\nConsidere una distribuci√≥n uniforme crentrada en \\(0\\) y rango \\(2a\\). La funci√≥n de densidad de probabilidad es\n\\[\np(x) = \\frac{1}{2a}I(x \\in [-a, a])\n\\]\nSea \\(\\mathbf{X} = (X_1,..., X_n)\\) un vector de \\(n\\) variables aleatorias independientes e id√©nticamente distribuidas seg√∫n \\(p(x)\\)\nInferencia m√°ximo-veros√≠mil\n\n¬øCu√°l es el estimador m√°ximo veros√≠mil de \\(a\\) (ll√°melo \\(\\hat{a}\\))?\n¬øQu√© probabilidad le asigna el modelo a una nueva observaci√≥n \\(x_{n + 1}\\) usando \\(\\hat{a}\\)?\n¬øObserva alg√∫n problema con el resultado anterior? Si es as√≠, sugiera una alternativa mejor.\n\nInferencia Bayesiana\nEl prior conjugado de la distribuci√≥n uniforme es la distribuci√≥n de Pareto.\nSi \\(X \\sim \\text{Pareto}(\\alpha, m)\\), luego\n\\[\nf(x| \\alpha, m) = \\frac{\\alpha m^\\alpha}{x^{\\alpha+1}} \\mathbb{I}(x \\ge m)\n\\]\nSi el prior es una distribuci√≥n de Pareto, la distribuci√≥n conjunta de \\(\\theta\\) y \\(\\mathbf{X} = (X_1,..., X_n)\\) es\n\\[\nf(\\theta, \\mathbf{X})\n    = \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n    \\mathbb{I}(\\theta \\ge \\text{max}(\\mathbf{X}))\n\\]\nLlamando \\(M_x = \\text{max}(\\mathbf{X})\\). La evidencia es\n\\[\n\\begin{aligned}\np(\\mathbf{X}) &= \\int_{M_x}^\\infty\n                 \\frac{\\alpha m^\\alpha}{\\theta^{n + \\alpha + 1}}\n                 d\\theta \\\\\n&=  \\begin{cases}\n    \\frac{\\alpha}{(n+\\alpha)m^n} & \\text{Si } M_x \\le m \\\\\n    \\frac{\\alpha m^\\alpha}{(n+\\alpha)m^{n+\\alpha}} & \\text{Si } M_x > m \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDerive el posterior y muestre que puede ser expresado como una distribuci√≥n de Pareto.  \nInferencia sobre una distribuci√≥n Exponencial\nEl tiempo de vida de una m√°quina en a√±os \\(X\\) es modelado con una distribuci√≥n exponencial con par√°metro \\(\\theta\\) desconocido. La funci√≥n de densidad es\n\\[\n\\begin{array}{lcrr}\nf(x | \\theta) = \\theta e^{-\\theta x} & \\text{con} & x \\ge 0, & \\theta \\ge 0\n\\end{array}\n\\]\n\nMuestre que el estimador m√°ximo veros√≠mil (MV) es \\(\\hat{\\theta} = 1/\\bar{x}\\)\n\nSuponga que se observan los siguientes tiempos de vida de tres m√°quinas independientes \\(x_1 = 5\\), \\(x_2 = 6\\), \\(x_3 = 4\\). ¬øCu√°l es el valor del estimador MV?\nUna experta del √°rea sugiere que \\(\\theta\\) debe tener una distribuci√≥n a priori que tambi√©n sea exponencial. \\[\n\\begin{aligned}\n\\theta &\\sim \\text{Exp}(\\lambda) \\\\\nf(\\theta | \\lambda) &= \\lambda e^{-\\lambda \\theta}\n\\end{aligned}\n\\] Elija un valor para el hiperpar√°metro \\(\\lambda\\) de la distribuci√≥n a priori tal que \\(\\mathbb{E}(\\theta) = 1/3\\). Utilice \\(\\hat{\\lambda}\\) para representar al valor.\n¬øCu√°l es el posterior \\(f(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)?\n¬øEs la distribuci√≥n exponencial conjugada con un likelihood exponencial?\nEncuentre la media del posterior, \\(\\mathbb{E}(\\theta | \\mathbf{X}, \\hat{\\lambda})\\)\nExplique por que difieren el estimador MV de la media a posteriori. ¬øCu√°l es m√°s razonable en este ejemplo? \n\nOtras distribuciones conjugadas (I)\nConsidere el siguiente modelo:\n\\[\n\\begin{array}{l}\nY\\mid\\theta \\sim \\text{Geom}(\\theta) \\\\\n\\theta \\sim \\text{Beta}(\\alpha,\\beta)\n\\end{array}\n\\] donde la funci√≥n de densidad de la distribuci√≥n geom√©trica es \\(p(y\\mid\\theta) = \\theta(1-\\theta)^{y-1}\\) para \\(y \\in {1,2,\\dots}\\)\n\n¬øQu√© deber√≠a ocurrir con la distribuci√≥n a posteriori de \\(\\theta\\) para poder afirmar que la distribuci√≥n geom√©trica es conjugada de la beta?\nDerive la distribuci√≥n a posteriori de \\(\\theta\\) y concluya.\n\nOtras distribuciones conjugadas (II)\nConsidere el siguiente modelo:\n\\[\n\\begin{array}{l}\nY\\mid\\theta \\sim \\text{BinomialNeg}(\\theta,m) \\\\\n\\theta \\sim \\text{Beta}(\\alpha,\\beta)\n\\end{array}\n\\]\ndonde la funci√≥n de densidad de la distribuci√≥n binomial negativa es\n\\[p(y\\mid \\theta, m) = {y+m-1 \\choose y} \\theta^{m} (1-\\theta)^y\\]\nObtenga la distribuci√≥n a posteriori de \\(\\theta\\).\nOtras distribuciones conjugadas (III)\nConsidere el siguiente modelo:\n\\[\n\\begin{array}{l}\nY\\mid\\theta \\sim \\text{Exp}(\\theta) = \\text{Gamma}(1,\\theta)\n\\end{array}\n\\]\ndonde la funci√≥n de densidad exponencial es \\(f(y\\mid\\theta) = \\theta e^{-\\theta y}\\).\nElija una distribuci√≥n a priori conjugada de la verosimilitud propuesta y obtenga la expresi√≥n para la distribuci√≥n de probabilidad a posteriori"
  },
  {
    "objectID": "practica/practica_02.html#simulaciones",
    "href": "practica/practica_02.html#simulaciones",
    "title": "Pr√°ctica - Unidad 2",
    "section": "Simulaciones",
    "text": "Simulaciones\nA diferencia de la secci√≥n anterior, que requiere resolver los ejercicios a mano y promueve el uso de la computadora y R de manera complementaria, esta secci√≥n contiene ejercicios que deben ser resueltos mediante t√©cnicas de simulaci√≥n implementadas en R. Es posible que en algunos casos tambi√©n se pueda obtener una soluci√≥n anal√≠tica. En estos casos, puede resultar de utilidad obtener tambi√©n una soluci√≥n a mano para comparar resultados, niveles de dificultad y ver que tan intuitivo resultan ambos enfoques.\n\nEntrada en calor\nPara cada una de las siguientes situaciones, hallar los intervalos centrales de credibilidad\n\nIntervalo del 95% para \\(\\pi\\) siendo \\(\\pi\\mid \\mathbf{y} \\sim \\text{Beta}(4,5)\\)\nIntervalo del 60% para \\(\\pi\\) siendo \\(\\pi\\mid \\mathbf{y} \\sim \\text{Beta}(4,5)\\)\nIntervalo del 89% para \\(\\lambda\\) siendo \\(\\lambda\\mid \\mathbf{y} \\sim \\text{Gamma}(1,8)\\)\nIntervalo del 95% para \\(\\lambda\\) siendo \\(\\lambda\\mid \\mathbf{y} \\sim \\text{Gamma}(2,5)\\)\nIntervalo del 81% para \\(\\mu\\) siendo \\(\\mu\\mid \\mathbf{y} \\sim \\mathcal{N}(10,2^2)\\)\nIntervalo del 99% para \\(\\pi\\) siendo \\(\\mu\\mid \\mathbf{y} \\sim \\mathcal{N}(-3,1^2)\\)\n\nPropiedades frecuentistas de inferencias bayesianas (!!)\nSea una variable \\(Y\\) tal que \\(Y | \\theta \\sim \\text{Binomial}(n, \\theta)\\) y \\(\\theta \\sim \\text{Beta}(1/2, 1/2)\\). Mediante un estudio de simulaci√≥n calcule la cobertura emp√≠rica del intervalo de credibilidad del 95% para \\(n \\in \\{1, 5, 10, 25\\}\\) y \\(\\theta \\in \\{0.05, 0.10, \\dots, 0.50 \\}\\). Describa las propiedades frecuentistas del intervalo de credibilidad bayesiano. \n¬øTe preguntaste alguna vez cu√°l es la distribuci√≥n de un p-value?\nConsidere un problema conocido. Se desean comparar dos muestras independientes de tama√±o 5 utilizando un test t y utilizando el test de Mann-Whitney.\n\nConsidere el caso en que las dos muestras provienen de poblaciones con igual media y desv√≠o est√°ndar (supongamos normal de media nula y varianza unitaria). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, ¬øqu√© distribuci√≥n tendr√°n los p-values obtenidos para cada test?\nConsidere ahora el caso en que las dos muestras provienen de poblaciones con diferente media e igual desv√≠o est√°ndar (\\(\\mathcal{N}(0,1)\\) y \\(\\mathcal{N}(1,1)\\)). Si se repitiera muchas veces el proceso de tomar las muestras y realizar los tests, ¬øqu√© distribuci√≥n tendr√°n los p-values obtenidos para cada test?"
  },
  {
    "objectID": "practica/practica_02.html#elecci√≥n-de-distribuciones-a-priori",
    "href": "practica/practica_02.html#elecci√≥n-de-distribuciones-a-priori",
    "title": "Pr√°ctica - Unidad 2",
    "section": "Elecci√≥n de distribuciones a priori",
    "text": "Elecci√≥n de distribuciones a priori\nEsta √∫tima secci√≥n de la pr√°ctica tiene como prop√≥sito ejercitar el uso de distribuciones de probabilidad como herramienta para reflejar informaci√≥n de un problema determinado.\n\nEsbozar la distribuci√≥n de las siguientes variables\n\nEl n√∫mero de personas que compran caf√© en el bar de la facultad asumiendo distribuci√≥n de Poisson.\nEl peso de perros adultos en kilogramos asumiendo una distribuci√≥n Uniforme.\nEl peso de elefantes adultos en kilogramos asumiendo una distribuci√≥n Normal.\nEl peso de humanos adultos en libras asumiendo una distribuci√≥n asim√©trica hacia la derecha.\n\nVerificar los resultados de manera computacional\nPara cada uno cada uno de los ejemplos del ejercicio anterior, graficar la distribuci√≥n usando R. Seleccionar los par√°metros que creas razonable, tomar una muestra aleatoria de tama√±o 1000 y graficar la distribuci√≥n en base a las muestras. ¬øSe refleja tu conocimiento del problema en la distribuci√≥n graficada? Si no, ajustar los par√°metros y repetir el proceso hasta que el resultado tenga concuerde con el conocimiento del problema.\nHay que amigarse con de la distribuci√≥n Beta\nComparar las siguientes distribuciones a priori.\n\n\\(\\text{Beta}(0.5, 0.5)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 1)\\)\n\\(\\text{Beta}(1, 4)\\)\n\\(\\text{Beta}(5, 1.5)\\)\n\n\n¬øEn qu√© se diferencian?\n¬øCu√°l de ellas es m√°s informativa?\n¬øC√≥mo lo determinaste?\n\nElicitaci√≥n de priors\nEn cada una de la situaciones que se describen debajo, ajustar manualmente los par√°metros de una distribuci√≥n \\(\\text{Beta}\\) para que reflejen la informaci√≥n brindada. No siempre existe una √∫nica respuesta correcta.\n\nUn amigo se postul√≥ para un empleo en LinkedIn y te dijo: ‚ÄúDir√≠a que tengo una chance del 40% de que me den el trabajo, pero no estoy seguro‚Äù. Cuando le preguntamos un poco mas, dijo que estima sus chances entre un 20% y un 60%.\nUn grupo de investigaci√≥n del CONICET desarroll√≥ una nueva prueba para una enfermedad bastante rara. El grupo espera que esta prueba arroje resultados correctos el 80% de las veces, con una varianza de 0.05.\nEl primo de un amigo es un apasionado de la pesca, lo practica muy seguido, y se dice ser muy bueno. Seg√∫n comenta tu amigo, en el asado de los Jueves el pescador dijo lo siguiente:\n\n\nSi tengo que hacer un promedio, 9 de cada 10 veces que salgo, vuelvo con algo. Pero √∫ltimamente te dir√≠a que siempre es 10 de 10. Estoy infalible. La verdad es que soy un crack de la pesca.\n\nAnte el descreimiento de algunos de los comensales supo reconocer que no siempre le fue tan bien:\n\nTuve mis malas rachas, pero nunca menos de 8 pescas de cada 10 salidas.\n\nEfecto de la parametrizaci√≥n\nSea \\(\\theta\\) la probabilidad de √©xito en un experimento binomial y sea \\(\\gamma = \\frac{\\theta}{1-\\theta}\\) la chance de √©xito. Utilizar simulaciones para explorar los efectos de las siguientes elecciones de distribuciones a priori\n\nSi \\(\\theta \\sim \\text{Uniforme}(0,1)\\), ¬øcu√°l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\theta \\sim \\text{Beta}(0,1)\\), ¬øcu√°l es el prior inducido para \\(\\gamma\\)?\nSi \\(\\gamma \\sim \\text{Uniforme}(0,100)\\), ¬øcu√°l es el prior inducido para \\(\\theta\\)?\nSi \\(\\gamma \\sim \\text{Gamma}(1,1)\\), ¬øcu√°l es el prior inducido para \\(\\theta\\)?"
  },
  {
    "objectID": "practica/practica_02.html#teor√≠a-de-la-decisi√≥n",
    "href": "practica/practica_02.html#teor√≠a-de-la-decisi√≥n",
    "title": "Pr√°ctica - Unidad 2",
    "section": "Teor√≠a de la Decisi√≥n",
    "text": "Teor√≠a de la Decisi√≥n\n\nDada la distribuci√≥n a posteriori \\(p(\\theta \\mid y)\\), probar que el estimador de Bayes que minimiza la funci√≥n de p√©rdida \\(L_1\\) es la mediana de \\(p(\\theta \\mid y)\\). \nSuponga que la distribuci√≥n a posteriori de \\(\\pi\\), \\(p(\\pi \\mid y)\\), es \\(\\text{Beta}(12,4)\\). Determine mediante simulaci√≥n el estimador que minimiza la p√©rdida de Huber: \\[\n\\mathcal{L}(\\delta,\\pi) =\n\\begin{cases}\n\\frac{1}{2} (\\pi - \\delta)^2 \\text{ si } |\\pi - \\delta| \\leq \\alpha \\\\\n\\alpha \\cdot (|\\pi - \\delta|-\\frac{1}{2}\\alpha) \\text{ en cualquier otro caso}\n\\end{cases}\n\\]\nTo Do Problema de rankear cinco tratamientos. Se tienen los puntajes de diez tratamientos, \\({\\theta_1,\\theta_2,\\dots,\\theta_10}\\). Se dan muestras de las distribuciones a posteriori, \\(p(\\theta_i\\mid y)\\). ¬øCu√°l de los tratamientos es mejor?"
  },
  {
    "objectID": "practica/practica_01.html",
    "href": "practica/practica_01.html",
    "title": "Pr√°ctica - Unidad 1",
    "section": "",
    "text": "Descargar PDF"
  },
  {
    "objectID": "practica/practica_01.html#regla-de-bayes",
    "href": "practica/practica_01.html#regla-de-bayes",
    "title": "Pr√°ctica - Unidad 1",
    "section": "Regla de Bayes",
    "text": "Regla de Bayes\nEl prop√≥sito de esta secci√≥n de la pr√°ctica es resolver situaciones que impliquen la aplicaci√≥n de la Regla de Bayes como se presenta tradicionalmente en un curso de Probabilidad.\n\nDemostraci√≥n\nDemuestra la validez de la siguiente expresi√≥n de la Regla de Bayes\n\\[\nP(B_j | A) = \\frac{P(A | B_j) P(B_j)}{\\sum_{k=1}^{K}P(A | B_k) P(B_k)}\n\\]\ndonde \\(A\\) es un evento cualquiera y \\(\\{B_1, \\cdots, B_K\\}\\) forman una partici√≥n. Para ello siga los siguientes pasos\n\nDemuestre que \\(P(B_j | A) P(A) = P(A | B_j) P(B_j)\\).\nDemuestre que \\(P(A) = P(A \\cap B_1) + P(A \\cap \\{\\cup_{k=2}^{K}B_j\\})\\).\nDemuestre que \\(P(A) = \\sum_{k=1}^{K} P(A \\cap B_j)\\).\nJunte las partes para formar la Regla de Bayes.  \n\nEl test infalible\nEn una poblaci√≥n dada, una de cada mil personas tiene una enfermedad. Se toma una persona al azar de la poblaci√≥n, se le aplica un test para detectar dicha enfermedad, y el resultado es positivo. El test se caracteriza por dar positivo el 99% de las veces que una persona tiene la enfermedad. Adem√°s, dicho test tiene una tasa de falsos positivos del 5%.\n\n¬øCu√°l es la probabilidad de que la persona tenga efectivamente la enfermedad?\nSi realizamos el mismo an√°lisis una segunda vez sobre el mismo paciente y obtenemos nuevamente positivo\n\n¬øCu√°l seria la probabilidad que el paciente est√© enfermo?\n¬øY si diera negativo?\n¬øEs el prior el mismo para el segundo an√°lisis que para el primero? \n\n\n¬øEs verdad que existen los vampiros? Versi√≥n Crep√∫sculo\nEdward quiere probarle a Bella que los vampiros existen. Seg√∫n Bella, hay una probabilidad del 5% de que los vampiros existan. Tambi√©n cree que la probabilidad de que exista alguien con la piel brillante dado que los vampiros existen es del 70%, y que la probabilidad de que alguien tenga la piel rillante si los vampiros no existen es del 3%. Edward lleva a Bella al bosque y le muestra que de hecho su piel brilla como un üíé ¬øCu√°l es la probabilidad que existan los vampiros? \n\n\n\n\n\nRobert Pattinson como Edward en Crep√∫sculo\n\n\n\n\n√Årboles enfermos\nUn vivero de la ciudad se destaca por vender una variedad de √°rboles nativos, incluyendo al jacarand√°, ceibo, omb√∫, entre otros. Lamentablemente, el 18% de los √°rboles del vivero estan infectados con moho. Los √°rboles enfremos se componen en un 15% por jacarand√°s, 80% de ceibos, y 5% de otras especies. Los √°rboles sanos se componen por un 20% de jacarand√°s, 10% de ceibos, y 70% de otras especies. Con el objetivo de monitorear cuanto se propag√≥ la enfermedad, una de las personas que trabaja en el vivero selecciona al azar uno de los √°rboles para testear.\n\n¬øCu√°l es la probabilidad a priori de que el √°rbolo tenga moho?\nResulta que el √°rbol seleccionado es un ceibo. ¬øCu√°l es la probabilidad de haber seleccionado un ceibo?\n¬øCu√°l es la probabilidad a posteriori de que el ceibo seleccionado tenga moho?\nCompare las probabilidades a priori y a posteriori de que el √°rbol tenga moho. ¬øC√≥mo afecta el an√°lisis el saber que el √°rbol es un ceibo? \n\n\n\n\n\n\nFlor del Ceibo, la flor nacional\n\n\n\n\nTransporte ‚ÄúEl Impuntual‚Äù\nUna cierta empresa de transporte regional, que decidimos llamar ‚ÄúEl Impuntual‚Äù, tiene servicios que van desde Rosario hasta Wheelwright varias veces al d√≠a, todos los d√≠as de la semana. Un 30% de los viajes salen a la ma√±ana, otro 30% salen a la tarde, y el restante 40% salen a la noche. Los pasajeros suelen estar muy frustrados ya que un 25% de los viajes salen tarde. De estos viajes demorados, el 40% corresponden a la ma√±ana, un 50% suceden a la tarde, y el 10% restante ocurre a la noche1.\nLucio y Franco son dos amigos del pueblo, y se volvieron a sus casas en colectivos diferentes.\n\nLucio se fue en uno de los colectivos de la ma√±ana. ¬øCu√°l es la probabilidad que su viaje est√© demorado?\nEl colectivo de Franco no est√° demorado. ¬øCu√°l es la probabilidad de que est√© viajando en uno de los colectivos de la ma√±ana? \n\n\n\n\n\n\nFoto de Markus Winkler en Unsplash\n\n\n\n\nBeb√© panda\nSupongamos que hay dos especies de osos panda. Ambas especies son igual de frecuentes y viven en la misma regi√≥n. Es m√°s, lucen de la misma forma y comen la misma comida. A√∫n no existe una prueba gen√©tica que pueda diferenciarlos. Lo √∫nico que los diferencia es la cantidad de cr√≠as que suelen tener. Las madres de la especie A dan luz a mellizos el 10% del tiempo. Y las madres de la especie B dan a luz mellizos el 20% del tiempo. En todos los otros casos, estas madres dan a luz un solo beb√© panda.\nUsando un poco la imaginaci√≥n, supongamos que somos la persona encargada de un programa de reproducci√≥n de pandas. Tenemos una panda femenina que acaba de dar a luz a un par de mellizos, pero no sabemos a que especie pertenece.\n\n¬øCu√°l es la probabilidad que la mam√° panda sea de la especie A?\n¬øCu√°l es la probabilidad que vuelva a tener mellizos en la pr√≥xima parici√≥n?\nUn tiempo despu√©s sos encontramos con que en la segunda parici√≥n da a luz a un √∫nico beb√© panda. ¬øCu√°l es la probabilidad de que este panda sea de la especie A? \n\n\n\n\n\n\nFoto de Stone Wang en Unsplash\n\n\n\n\nParaguas\nEst√°s a punto de subir a un avi√≥n rumbo a Mendoza. Quer√©s saber si ten√©s que llevar un paraguas o no. Llam√°s a tres amigos que viven en Mendoza y les pregunt√°s si est√° lloviendo. Cada uno de ellos tiene una probabilidad de 2/3 de decirte la verdad y 1/3 de mentirte para hacerte una broma. Los tres responden que s√≠ est√° lloviendo. ¬øCu√°l es la probabilidad de que realmente est√© lloviendo en las Mendoza? Se puede asumir que en Mendoza llueve en 1 de cada 10 d√≠as. \nSherlock\nDos personas dejaron rastros de sangre en la escena del crimen. La sangre de Guido, un sospechoso, es analizada y resulta ser de tipo ‚Äò0‚Äô. Los rastros de sangre de la escena son de tipo ‚Äò0‚Äô (un tipo com√∫n en la poblaci√≥n, presente en el 60% de las personas) y de tipo ‚ÄòAB‚Äô (un tipo raro, con una frecuencia del 1% en la poblaci√≥n). ¬øEstos datos representan evidencia de que Guido estaba presente en la escena del crimen? \nHijxs de la probabilidad\nNos encontramos con alguien en la calle y nos dice que tiene dos hijxs. Le preguntamos si algunx de ellxs es mujer y nos responde que s√≠. ¬øCu√°l es la probabilidad de que ambxs sean ni√±as? \nLos Reyes del Rock\nElvis Presley ten√≠a un hermano var√≥n que naci√≥ en el mismo parto pero que muri√≥ al poco tiempo. ¬øCu√°l es la probabilidad de que Elvis tuviera un gemelo? Alguna informaci√≥n adicional: en 1935, cuando Elvis naci√≥, 1/3 de los hermanxs del mismo parto eran gemelxs y 2/3 mellizxs; adem√°s, la probabilidad de que dos mellizxs sean del mismo sexo biol√≥gico puede estimarse en 50%, mientras que dos gemelxs son siempre del mismo sexo biol√≥gico. \n¬øAlguien ordena las medias?\nDos cajones contienen medias. Uno de ellos tiene igual cantidad de medias blancas y negras. El otro contiene un n√∫mero igual de medias rojas, verdes y azules. Se elige un caj√≥n al azar, se sacan dos medias sin mirar y resultan ser las dos iguales. ¬øCu√°l es la probabilidad de que las medias sean blancas? Sup√≥ngase que sacar la primera media no altera las proporciones. \nLa Falacia del Fiscal\nSally Clark era una abogada brit√°nica que fue err√≥neamente sentenciada a prisi√≥n perpetua en 1999 por la muerte de sus dos hijos beb√©s. Su hijo mayor, Christopher, muri√≥ con 11 semanas en diciembre de 1996 y su hijo m√°s joven, Harry, con 8 semanas en enero de 1998. Durante el juicio, la defensa argument√≥ que las muertes se debieron al s√≠ndrome de muerte s√∫bita del lactante (SIDS). Clark fue condenada a partir del testimonio del pediatra Sir Roy Meadow, quien argument√≥ en la corte lo siguiente:\n\nEn familias sanas, la chance de muerte por SIDS es de \\(\\frac{1}{8500}\\)\nLa probabilidad de dos muertes por SIDS en la misma familia es aproximadamente \\(\\frac{1}{8500^2} \\approx \\frac{1}{73000000}\\)\nEs, por ende, muy poco probable que Clark sea inocente\n\nLuego de pasar 3 a√±os en prisi√≥n, Clark fue liberada en 2003 luego de que se determinara que el testimonio experto de Meadows era equivocado. Dos mujeres, a las cuales el testimonio de Meadows hab√≠a enviado a prisi√≥n, tambi√©n fueron liberadas.\n\nIdentifica una falla en la probabilidad de \\(\\frac{1}{73000000}\\) dada por Meadows\nIncluso aceptando el n√∫mero anterior como correcto, ¬øcu√°l es el problema de interpretar esa probabilidad como la probabilidad de inocencia de Clark?"
  },
  {
    "objectID": "practica/practica_01.html#inferencia-bayesiana",
    "href": "practica/practica_01.html#inferencia-bayesiana",
    "title": "Pr√°ctica - Unidad 1",
    "section": "Inferencia Bayesiana",
    "text": "Inferencia Bayesiana\nEn esta parte de la pr√°ctica, se le otorga un significado a las cantidades que aparecen en la Regla de Bayes modificando conceptualmente el enfoque de las situaciones problem√°ticas. Ahora los problemas se tratan de realizar inferencias sobre posibles causas de ciertos datos observados. Se incrementa el rigor matem√°tico, aparecen distribuciones de probabilidad y la necesidad de dejar ciertos c√°lculos en manos de la computadora.\n\nEl lenguaje de las probabilidades\nEscribir la expresi√≥n matem√°tica para cada una de las siguientes descripciones verbales:\n\nProbabilidad de un par√°metro dados los datos observados\nLa distribuci√≥n de probabilidad de los par√°metros antes de ver los datos\nLa verosimilitud de los datos para un valor dado de los par√°metros\nLa probabilidad de una observaci√≥n nueva luego de observar los datos\nLa probabilidad de una observaci√≥n antes de ver los datos \n\nQu√© datazo me tiraste, rey\nLos M&Ms azul fueron introducidos en el a√±o 1995 (antes hab√≠a dos tipos de marr√≥n)\n\nAntes de 1995, la mezcla de colores en una bolsa de M&Ms era: 30% marron, 20% amarillo, 20% rojo, 10% verde, 10% naranja y 10% marr√≥n bronceado.\nLuego de 1995, la mezcla pas√≥ a ser: 24% azul, 20% verde, 16% naranja, 14% amarillo, 13% rojo y 13% marr√≥n.\n\nUn amigo tiene dos bolsas de M&M y nos dice que una bolsa es de 1994 y la otra es de 1996, pero no nos dice cu√°l es cu√°l. Nos da un M&M de cada bolsa: uno es amarillo y el otro es verde (ambos posiblemente est√©n vencidos). ¬øCu√°l es la probabilidad de que el amarillo venga de la bolsa de 1994?\nLa Gran Estafa\nHay dos monedas en una caja. Una de ellas es una moneda com√∫n y la otra es una moneda que tiene dos caras.\n\nSe elige una moneda al azar, se arroja, y se obtiene cara. ¬øCu√°l es la probabilidad de que la moneda elegida sea la falsa?\nSe elige una moneda al azar y se arroja al aire tres veces, obteni√©ndose tres caras. ¬øCu√°l es la probabilidad de que la moneda elegida sea la falsa?\n\nVocabulario limitado\nSupongamos que existe un idioma con seis palabras:\n\\[\n\\text{\\{perro, parra, farra, carro, corro, tarro\\}}\n\\]\nUn an√°lisis ling√º√≠stico exhaustivo de esta lengua ha descubierto que todas las palabras son igualmente probables, excepto por ‚Äòperro‚Äô, que es \\(\\alpha\\) veces m√°s probable que las otras.\nAdem√°s:\n\nCuando se tipean, un caracter se introduce err√≥neamente con probabilidad \\(\\theta\\)\nTodas las letras tienen la misma probabilidad de producir un error de tipeo\nSi una letra se tipe√≥ mal, la probabilidad de cometer un error en otro caracter no cambia\nLos errores son independientes a lo largo de una palabras.\n\n\n¬øCu√°l es la probabilidad de escribir correctamente ‚Äòtarro‚Äô?\n¬øCu√°l es la probabilidad de tipear ‚Äòcerro‚Äô o ‚Äòcurro‚Äô al querer escribir ‚Äòcarro‚Äô?\nUtilizando la Regla de Bayes, desarrollar un corrector gramatical para esta lengua. Para las palabras tipeadas ‚Äòfarra‚Äô, ‚Äòbirra‚Äô y ‚Äòlocos‚Äô, hallar la probabilidad de que cada palabra del diccionario sea la palabra que se hab√≠a querido escribir. Utilizar las siguientes combinaciones de par√°metros:\n\n\\(\\alpha = 2\\) y \\(\\theta = 0.1\\)\n\\(\\alpha = 50\\) y \\(\\theta = 0.1\\)\n\\(\\alpha = 2\\) y \\(\\theta = 0.9\\)\n\n\nBosque\nSea \\(X_1 \\sim \\text{Bernoulli}(\\theta)\\) una variable que indica si una especie de √°rboles se halla en un determinado bosque y \\(\\theta \\in [0, 1]\\) representa la probabilidad a priori de que la especie se encuentre en el bosque. Una investigadora selecciona una muestra de \\(n\\) √°rboles del bosque y encuentra que \\(X_2\\) de ellas pertenecen a la especie de inter√©s.\nEl modelo luego es\n\\[\n\\begin{array}{lc}\nX_2|X_1 \\sim \\text{Binomial}(n, \\lambda X_1) & \\text{con} \\ \\lambda \\in [0, 1]\n\\end{array}\n\\]\n\\(\\lambda\\) representa la probabilidad de detectar la especie, dado que la especie se encuentra en el bosque.\nEncuntre expresiones matem√°ticas en t√©rmino de \\(n\\), \\(\\theta\\) y \\(\\lambda\\) para las siguientes probabilidades:\n\n\\(P(X_1 = 0, X_2 = 0)\\)\n\\(P(X_1 = 0)\\)\n\\(P(X_2 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 0)\\)\n\\(P(X_2 = 0 | X_1 = 0)\\)\n\\(P(X_1 = 0 | X_2 = 1)\\)\n\\(P(X_2 = 0 | X_1 = 1)\\)\nExplique de manera intuitiva c√≥mo es que las probabilidades calculadas en (iv)-(vii) cambian seg√∫n \\(n\\), \\(\\theta\\) y \\(\\lambda\\).\nAsuma \\(\\theta=0.5\\), \\(\\lambda=0.1\\) y \\(X_2 = 0\\) ¬øCu√°n grande debe ser \\(n\\) para que se puede concluir con 95% de confianza que la especie no se encuentra en el bosque? \n\n¬°Ostras! ¬°Estoy haciendo inferencia bayesiana!\nEn un estudio que utiliza m√©todos de la Estad√≠stica Bayesiana para predecir el n√∫mero de especies que ser√°n descubiertas en el futuro se reporta que la cantidad de especies marinas bivalvas2 descubiertas cada a√±o entre 2010 y 2015 fue 64, 13, 33, 18, 30 y 20.\nSi se representa con \\(Y_t\\) a la cantidad de especies descubierta en el a√±o \\(t\\), y asumiendo:\n\\[\n\\begin{aligned}\nY_t | \\lambda &\\underset{iid}{\\sim} \\text{Poisson}(\\lambda) \\\\\n\\lambda       &\\sim \\text{Uniforme}(0, 100)\n\\end{aligned}\n\\]\nGraficar la distribuci√≥n a posteriori de \\(\\lambda\\). \nEs negocio‚Ä¶\nSea \\(n\\) la cantidad desconocida de clientes que visitan una tienda en un dia cualquiera. El n√∫mero de clientes que realizan una compra es \\(Y\\) y se cumple que\n\\[\nY | n \\sim \\text{Binomial}(n, \\theta)\n\\]\ndonde \\(\\theta\\) es la probabilidad de compra, dado que se produce la visita a la tienda. La distribuci√≥n a priori de \\(n\\) es \\(n \\sim \\text{Poisson}(5)\\). Bajo el supuesto que \\(\\theta\\) es conocido y que \\(n\\) es desconocido, graficar la distribuci√≥n a posteriori de \\(n\\) para todas las combinaciones de \\(Y \\in \\{0, 5, 10 \\}\\) y \\(\\theta \\in \\{0.2, 0.5\\}\\). Explique cual es del efecto de cambiar \\(Y\\) y \\(\\theta\\) sobre la distribuci√≥n a posteriori.  \nCon amigos as√≠, qui√©n necesita enemigos\nUn amigo arroja un dado y anota en secreto el n√∫mero que sale (llam√©moslo \\(T\\)). A continuaci√≥n, nosotros, con los ojos vendados, arrojamos el dado varias veces. No podemos ver el n√∫mero que sale pero nuestro amigo nos dice si el n√∫mero que sacamos es mayor, menor o igual a \\(T\\).\nSupongamos que nos da la secuencia: \\(G,\\ G,\\ C,\\ I,\\ C,\\ C,\\ C, I,\\ G,\\ C\\) (siendo \\(G\\) m√°s grande, \\(C\\) m√°s chico e \\(I\\) igual). ¬øCu√°l es la distribuci√≥n a posteriori de los valores de \\(T\\)? \nOrden en la sala\nEn las Jornadas Rosarinas de Ciencia de Datos, una expositora est√° dando una charla en un sal√≥n cuando el personal de seguridad la interrumpe porque cree que puede haber m√°s de 1000 personas en la sala, superando el m√°ximo permitido.\nLa expositora piensa que hay menos de 1000 personas y se ofrece a demostrarlo, aunque piensa que contarlas podr√≠a llevar mucho tiempo. Decide hacer un experimento:\n\nPregunta cu√°ntas personas nacieron el 11 de mayo. Dos personas levantan la mano.\nPregunta cu√°ntas personas nacieron el 23 de mayo. Una persona levanta la mano.\nPregunta cu√°ntas personas nacieron el 1 de agosto. Nadie levanta la mano.\n\n¬øCu√°ntas personas hay en la sala? O, mejor dicho, ¬øcu√°l es la probabilidad de que haya m√°s de 1000 personas en la sala? \nHouse of Cards\nHay 538 miembros en el Congreso de Estados Unidos. Supongamos que se auditan sus inversiones y se encuentra que 312 de ellos obtuvieron rendimientos por encima del mercado. Asumamos que un miembro honesto del Congreso tiene solo una probabilidad del 50% de tener rendimientos por encima del mercado, pero uno deshonesto que opera con informaci√≥n confidencial tiene una chance del 90% de hacerlo. ¬øCu√°ntos miembros del Congreso son honestos? \nPuede fallar‚Ä¶\nCansada de los experimentos de arrojar una moneda cientos de veces al aire, una estudiante dise√±a un sistema de reconocimiento de im√°genes que determina si sali√≥ cara o ceca y registra el resultado.\nL√≥gicamente, el sistema dise√±ado no es perfecto sino que presenta una tasa de error. En particular, la probabilidad de que clasificar mal es de 0.2 (20% de las veces que sale cara, el sistema dice ceca, y viceversa).\nSe arroja la moneda 250 veces y el sistema detecta 140 caras,\n\n¬øCu√°l es la distribuci√≥n a posteriori de \\(\\theta\\), la probabilidad de obtener cara?\n¬øQu√© ocurre a medida que la probabilidad de clasificar mal var√≠a? \n\n¬°Saludos a los cubos con puntos! (‚Ä¶) Ser√°n dados\nDos dados de seis caras son arrojados. Se sabe que la suma de los dos puntajes obtenidos es 9. ¬øCu√°l es la distribuci√≥n a posteriori de los puntajes de los dados?"
  },
  {
    "objectID": "practica/practica_01.html#conceptuales",
    "href": "practica/practica_01.html#conceptuales",
    "title": "Pr√°ctica - Unidad 1",
    "section": "Conceptuales",
    "text": "Conceptuales\nEn esta secci√≥n, se nos invita a pensar sobre las caracter√≠sticas de la Estad√≠stica Bayesiana. En lugar de encontrar una respuesta √∫nica mediante c√°lculos matem√°ticos, se necesita comprender en profundidad tanto el enfoque frecuentista como el bayesiano para interpretar estas visiones en diferentes escenarios.\n\nVoy a conseguir esa pasant√≠a\nLa empresa de tecnolog√≠a en la que todo el mundo quiere trabajar tiene varias vacantes para pasantes en ciencia de datos. Luego de leer la descripci√≥n de la b√∫squeda, te das cuenta que sos una persona calificada para el puesto: estos son tus datos. Tu objetivo es averiguar si te van a ofrecer el puesto: esta es tu hip√≥tesis.\n\nDesde la perspectiva de una persona con un razonamiento frecuentista, ¬øQu√© es lo que se responde al evaluar la hip√≥tesis de que te ofrecen el puesto?\nRepita el punto anterior considerando la perspectiva de una persona con un razonamiento Bayesiano.\n¬øQu√© pregunta tiene m√°s sentido responder: la frecuentista o la Bayesiana? Justifica tu respuesta. \n\nBeneficios de la Estad√≠stica Bayesiana\nUna amiga te cuenta que est√° interesada en aprender m√°s sobre Estad√≠stica Bayesiana. Expl√≠cale lo siguiente:\n\n¬øPor qu√© es √∫til el enfoque Bayesiano?\n¬øCu√°les son las similitudes entre el enfoque frecuentista y el Bayesiano?"
  },
  {
    "objectID": "teoria/teoria_01.html",
    "href": "teoria/teoria_01.html",
    "title": "Teor√≠a - Unidad 1",
    "section": "",
    "text": "Instrucciones para guardar como PDF\n\nHacer click ac√°\nAbrir la ventana de impresi√≥n del navegador con CTRL+P\nSi es necesario, cambia el Destino a Guardar como PDF\nClick en Guardar\nEleg√≠ el nombre del archivo de destino\nListo! üéâ"
  },
  {
    "objectID": "presentaciones/01_clase1.html#getting-up",
    "href": "presentaciones/01_clase1.html#getting-up",
    "title": "Estad√≠stica Bayesiana",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed\n\n\n\n\n\nPay Attention\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\n\n\n\nPay Attention\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\n\nSpeaker notes go here."
  }
]