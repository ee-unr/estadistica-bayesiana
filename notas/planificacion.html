<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Estadística Bayesiana - Contenidos detallados</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../utils/imgs/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Estadística Bayesiana</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../info/programa.html">
 <span class="menu-text">Información</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../teoria/u1_teoria_01.html">
 <span class="menu-text">Teoría</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../practica/practica_00.html">
 <span class="menu-text">Práctica</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../trabajos_practicos/descripcion.html">
 <span class="menu-text">Trabajos Prácticos</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../recursos/codigo/index.html">
 <span class="menu-text">Recursos</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/estadisticaunr/estadistica-bayesiana"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Contenidos detallados</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<ul>
<li>Actividad Rocklets</li>
</ul>
<section id="repaso" class="level1">
<h1>Repaso</h1>
<ul>
<li>Repaso de probabilidad, distribuciones conjuntas, distribuciones marginales</li>
<li>Práctica 0 (ver qué ejercicios)</li>
</ul>
</section>
<section id="introducción" class="level1">
<h1>Introducción</h1>
<ul>
<li>Probabilidad para cuantificar la incertidumbre
<ul>
<li>Definiciones de probabilidad
<ul>
<li>Clasica</li>
<li>Frecuentista</li>
<li>Bayesiana (subjetiva)</li>
</ul></li>
<li>Probabilidades subjetivas</li>
<li>Lógica y razonamiento plausible (ver Jaynes)</li>
<li>Dutch book</li>
</ul></li>
<li>Regla de Bayes
<ul>
<li>Historia: Bayes, Price, Laplace</li>
<li>Presentación tradicional de la Regla de Bayes
<ul>
<li>Ley de la probabilidad total</li>
</ul></li>
<li>Práctica 1 (ver qué ejercicios)</li>
</ul></li>
<li>Inferencia bayesiana: problema original de Bayes, problema de la percepción del suelo mojado, problema de las bolas (¿hecho en vivo con Sugus?), problema del globo terráqueo (¿hecho en vivo?), problema de detección de gluten (ver Downey), problema de detección de una explosión (ver Barber).
<ul>
<li>Discutir modelos generativos (probabilidad hacia adelante e inversa).</li>
<li>Práctica 1 (ver qué ejercicios)</li>
<li>Idea intuitiva: ¿qué es el <em>prior</em>? ¿qué es la función de verosimilitud? ¿qué es el <em>posterior</em>?</li>
</ul></li>
</ul>
</section>
<section id="modelos-de-distribuciones-conjugadas" class="level1">
<h1>Modelos de distribuciones conjugadas</h1>
<ul>
<li><p>Modelo beta-binomial</p>
<ul>
<li>Demostración
<ul>
<li>Beta(a,b) siendo a y b “pseudocuentas”</li>
</ul></li>
<li>Definición de “distribuciones conjugadas” (ver BDA 2.4)</li>
<li>Enfoque intuitivo</li>
<li>Distribución a posteriori como compromiso entre <em>likelihood</em> y <em>prior</em>
<ul>
<li>ver caso particular y luego generalidad 2.2 de BDA</li>
</ul></li>
<li>Razonamiento secuencial</li>
<li>Resumen de la distribución <em>a posteriori</em>: media, moda, intervalos de credibilidad. Cálculos a mano, cálculos exacto con funciones de R. Simulaciones (vamos a introducir la idea de utilizar simulaciones para resolver problemas)
<ul>
<li>Podemos resolver algunos ejercicios de Simulación de la Práctica 2</li>
</ul></li>
<li>Predicciones: simulaciones. Problema del amanecer.</li>
<li>Estimación por máxima verosimilitud</li>
<li>Práctica 2</li>
</ul></li>
<li><p>Elección de la distribución a priori</p>
<ul>
<li>Práctica 2</li>
</ul></li>
<li><p>Modelo normal-normal</p>
<ul>
<li>Demostración</li>
<li>Enfoque intuitivo</li>
<li>Distribución a posteriori como compromiso entre <em>likelihood</em> y <em>prior</em></li>
<li>Razonamiento secuencial</li>
<li>Predicciones: distribución predictiva. Incertidumbre propia del sampleo + incertidumbre (ver BDA 2.5 y <em>posterior predictive distribution</em>). <em>Plugin approximation</em> vs <em>posterior predictive distribution</em> (3.1.5.2 de Murphy)</li>
<li>Modelo normal con <em>prior</em> uniforme (ver Devinderjit y Skilling, Sección 2.3 – Example 2)</li>
<li>(¿) Modelo normal con media conocida y varianza desconocida (?) (ver BDA 2.6)</li>
</ul></li>
<li><p>Modelo Gamma-Poisson</p></li>
<li><p>Otros modelos de distribuciones conjugadas para una variable (ver Práctica 2)</p></li>
<li><p><strong>Presentación TP1 – Conjugación Dirichlet-Multinomial</strong></p></li>
<li><p>Modelos de varias variables</p>
<ul>
<li><p>Normal con media y desvío desconocido: modelo normal – normal-gamma-inversa (ver Ejemplo 2.8 de Carlin y Louis, BDA Sección 3.3 y 3.2.3.3 de Murphy)</p></li>
<li><p>Normal con con media y desvío desconocido: <em>prior</em> uniforme (ver Devinderjit y Skilling, Sección 3.3 – Example 5 y ver BDA Sección 3.2). Relación con máxima verosimilitud (ver Devinderjit y Skilling, Sección 3.5 – Approximations)</p></li>
<li><p>(¿) Distribuciones marginales de los parámetros (?)</p></li>
</ul></li>
</ul>
</section>
<section id="nociones-de-teoría-de-la-decisión" class="level1">
<h1>Nociones de Teoría de la Decisión</h1>
<ul>
<li><p>El resultado de la inferencia bayesiana es la distribución <em>a posteriori…</em> aún así, a veces podemos querer resumirla</p></li>
<li><p>¿Por qué tiene sentido resumir la distribución <em>a posteriori</em> usando la media?</p></li>
<li><p>Funciones de pérdida (ver <a href="https://nbviewer.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC2.ipynb">Davidson-Pilon, Capítulo 5</a>)</p></li>
<li><p><em>Posterior expected loss</em> (ver Robert, Sección 2.3: Utility and loss)</p>
<ul>
<li>Ejemplo de COVID-19 de Murphy (3.8.2)</li>
</ul></li>
<li><p>Demostración de que la media minimiza la pérdida cuadrática (ver Robert, Proposición 2.5.1)</p></li>
<li><p>Ejercicios (Práctica 2)</p></li>
</ul>
</section>
<section id="métodos-computacionales" class="level1">
<h1>Métodos Computacionales</h1>
<ul>
<li>Problemas: determinación de probabilidades, cálculo de integrales, determinación de la distribución <em>a posteriori</em> (dos problemas: integrales analíticas y dimensiones de esa integral)</li>
<li>Me gustaría hablar algo más de la maldición de dimensionalidad (ver Theoridis o MacKay)</li>
<li>Determinación de probabilidades (ya lo hemos trabajado en la Práctica 2)</li>
<li>Ejercicios Simulación (Práctica 3)</li>
<li>Integración por Montecarlo</li>
<li>Grid approximation
<ul>
<li><p>Un parámetro</p></li>
<li><p>Dos parámetros</p></li>
<li><p>Caso discreto ((¿)grid approximation de un problema para estimar N y theta(?)) y caso continuo</p></li>
</ul></li>
<li>Ejercitación grid approximation (Práctica 3)</li>
<li>Determinación de la distribución <em>a posteriori</em> (aka sampling) por métodos de MCMC
<ul>
<li><p>Presentar rejection sampling</p></li>
<li><p>(¿) Importance sampling (?)</p></li>
<li><p>Metropolis-Hastings</p></li>
</ul></li>
<li>Presentación TP2 – Metropolis-Hastings (trabajo en clase)</li>
<li>Diagnóstico de métodos de MCMC</li>
<li>Hamiltonian Montecarlo</li>
<li>Práctica HMC</li>
<li>Programación probabilística: Stan</li>
<li>Componentes de un modelo en Stan</li>
<li>Implementación de un modelo ya trabajado.
<ul>
<li><p>Diagnósticos</p></li>
<li><p>Manipulación de muestras de MCMC.</p></li>
<li><p>Visualizaciones de resultados (estimaciones de parámetros y predicciones). Uso del paquete ggdist.</p></li>
</ul></li>
</ul>
</section>
<section id="modelos-lineales" class="level1">
<h1>Modelos lineales</h1>
<ul>
<li><p>Estimación por mínimos cuadrados. Estimación por máxima verosimilitud.</p>
<ul>
<li>Ver ROS 8.1</li>
</ul></li>
<li><p>Estimación bayesiana. <em>Priors</em> conjugados para varianza conocida y varianza desconocida.</p>
<ul>
<li>Centrado de variables (ver Murphy y 12.3 de ROS)</li>
</ul></li>
<li><p>Distribución predictiva.</p></li>
<li><p>Implementación en Stan y brms (comparación de brms con lm en R, ¿cómo obtenemos los mismos resultados? ver ROS 8.4).</p></li>
<li><p>Manipulación de resultados.</p></li>
<li><p>Predicciones probabilísitas (predicciones basadas en distribuciones de probabilidad). Propagación de incertidumbre. Interpretación.</p>
<ul>
<li><p>Predicción puntual vs predicción de la media (predictor lineal) vs distribución predictiva</p></li>
<li><p><em>We have a set of posterior simulations rather than a single point estimate because we have uncertainty about these parameters.</em> (ROS 9.1)</p></li>
<li><p><em>As sample size approaches infinity, the coefficients a and b are estimated more and more precisely, and the uncertainty in the linear predictor approaches zero, but the uncertainty in the predictive distribution for a new observation does not approach zero; it approaches the residual standard deviation σ.</em> (ROS 9.2)</p></li>
</ul></li>
<li><p><em>Parameter recovery</em></p>
<ul>
<li>(ver ROS 7.2 Checking the model-fitting procedure using fake-data simulation)</li>
</ul></li>
<li><p>Pruebas predictivas <em>a posteriori</em>. Comparación de los datos disponibles con réplicas generadas por el modelo ajustado (lo que en ROS llaman <strong>validación interna</strong>)</p>
<ul>
<li>Ver ROS 11.4</li>
</ul></li>
<li><p>Elección de una distribución <em>a priori</em>. Pruebas predictivas <em>a</em> <em>priori</em>.</p></li>
<li><p>Problemas con la estimación de mínimos cuadrados. Regularización ridge (<span class="math inline">\(L_2\)</span>) y lasso (<span class="math inline">\(L_1\)</span>). Distribuciones <em>a priori</em> para regularizar.</p>
<!--# http://cms.dm.uba.ar/academico/materias/1ercuat2019/modelo_lineal/ridgeclase2.pdf --></li>
<li><p>Selección de variables con <em>horseshoe prior</em> (ver ROS 12.7)</p></li>
<li><p><strong>Validación externa</strong> y criterios de información (ver 3.7.4 de Murphy Advanced, McElreath y BDA aunque está medio confuso)</p>
<ul>
<li><p>lppd (<em>log pointwise predictive density)</em>: promedio del <em>score</em>&nbsp;predictivo a través de los posibles valores de <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[
lppd = \sum_{i=1}^{N} \log \left( \int p\left(y_i\mid\theta\right) p_{post}(\theta) d\theta \right)
\]</span></p>
<p><span class="math display">\[
lppd = \sum_{i=1}^{N} \log \left( \frac{1}{S} \sum_{i=1}^{S} p\left(y_i\mid\theta^{(s)}\right) \right)
\]</span></p></li>
<li><p>PSIS</p></li>
</ul></li>
</ul>
</section>
<section id="regresión-logística" class="level1">
<h1>Regresión Logística</h1>
<ul>
<li><p>Modelo para clasificación (creo que podemos trabajarlo bien siguiendo Bayes Rules!)</p></li>
<li><p>Simulación</p></li>
<li><p>Interpretación de coeficientes</p></li>
<li><p>Exceso de ceros (ver ejemplo de Bayes Rules! y Negative Binomial)</p></li>
</ul>
</section>
<section id="regresión-poisson" class="level1">
<h1>Regresión Poisson</h1>
<ul>
<li><p>Modelo para datos de conteo (creo que podemos trabajarlo bien siguiendo Bayes Rules!)</p></li>
<li><p>Simulación</p></li>
</ul>
</section>
<section id="enfoque-multinivel" class="level1">
<h1>Enfoque multinivel</h1>
<ul>
<li><p>Modelo beta-binomial jerárquico (ver Kruschke)</p></li>
<li><p><em>Shrinkage</em> de parámetros</p></li>
<li><p>Ejemplo de uranio de Gelman: <em>no pooling</em> vs <em>complete pooling</em> vs <em>partial pooling</em></p></li>
<li><p>Ejemplo de las ranas de McElreath:</p></li>
<li><p>Ejemplo de las canciones (Bayes Rules!)</p></li>
<li><p>Ejemplo de la carrera de Washington (Bayes Rules!)</p></li>
<li><p>Modelos jerárquicos con predictores (Capítulo 17 de Bayes Rules)</p>
<ul>
<li><p>Variación en el intercepto</p></li>
<li><p>Variación en la pendiente</p></li>
</ul></li>
<li><p>Problemas de estimación</p></li>
<li><p>Opcional: regresión logística jerárquica y regresión Poisson jerárquica (ver ejemplo de Bayes Rules! y de un paper de Paul Burkner sobre pesca (?))</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-right">Esta página es hecha con ❤️ y <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>



</body></html>