---
title: "15 - Regresión lineal con `{RStan}` (Clima en Australia)"
execute:
    message: false
    warning: false
---

En este artículo se muestra como implementar en `R` y `{RStan}` algunos de los modelos
necesarios en el ejercicio **Clima en Australia** de la Práctica 4.

Comenzamos cargando las liberías que vamos a usar.

```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(rstan)

c_orange_dark <- "#e76f51"
c_orange_light <- "#f4a261"
c_yellow <- "#e9c46a"
c_green_blue <-"#2a9d8f"
c_blue_dark <- "#264653"
c_lightblue <- "#219ebc"
```


```{r}
#| fig-align: center
#| fig-width: 7
df <- read_csv(
    "https://raw.githubusercontent.com/estadisticaunr/estadistica-bayesiana/main/datos/weather_WU.csv"
)

# Explorar los datos
ggplot(df) +
  geom_point(aes(x = temp9am, y = temp3pm, color = location), alpha = 0.7, size = 2) +
  scale_color_manual(values = c(c_orange_dark, c_green_blue)) +
  labs(
    x = "Temperatura a las 9 a.m. (C°)", 
    y = "Temperatura a las 3 p.m. (C°)",
    color = "Ciudad"
  ) +
  theme_bw()
```

## Modelos

A continuación se presentan los modelos que se consideran en el ejercicio. En todos los 
casos se tiene:

* $Y_i$: temperatura a las 3 p.m. de la observación i-ésima.
* $X_i$: temperatura a las 9 a.m. de la observacion i-ésima.

### Modelo 1

$$
\begin{aligned}
Y_i \mid \mu_i, \sigma &\underset{iid}{\sim} \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 x_i \\
\beta_0 &\sim \text{Normal}(15, 8^2)\\
\beta_1 &\sim \text{Normal}(0, 3^2)\\
\sigma &\sim \text{Normal}^+(0, 12^2)\\
\end{aligned}
$$

### Modelo 2

$$
\begin{aligned}
Y_i \mid \mu_i, \sigma &\underset{iid}{\sim}\text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_{0, j[i]} \\
\beta_{0, j} &\sim \text{Normal}(20, 10^2) \quad \forall j = 1, 2  \\
\sigma &\sim \text{Normal}^+(0, 15^2) \\
\end{aligned}
$$

donde $j$ indexa a las diferentes ciudades.

**Para pensar:** ¿qué indican $\beta_{0, 1}$ y $\beta_{0, 2}$?

### Modelo 3

$$
\begin{aligned}
Y_i \mid \mu_i, \sigma &\underset{iid}{\sim} \text{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_{0, j[i]} + \beta_1 x_i \\
\beta_{0, j} &\sim \text{Normal}(15, 8^2) \quad \forall j = 1, 2  \\
\beta_1 &\sim \text{Normal}(0, 3^2) \\
\sigma &\sim \text{Normal}^+(0, 12^2) \\
\end{aligned}
$$

**Para pensar:** ¿en qué difieren los $\beta_{0, 1}$ y $\beta_{0, 2}$ de este modelo
con los del modelo 2? ¿Y en qué difiere $\beta_1$ de este modelo con el del modelo 1?


## Implementación

### Modelo 1

```{stan}
#| echo: true
#| eval: false 
#| file: stan/australia/modelo_1.stan
#| output.var: modelo_01
```

```{r}
# Datos que pasamos a Stan
stan_data_1 <- list(
    N = nrow(df), 
    temp9am = df$temp9am, 
    temp3pm = df$temp3pm
)

ruta_modelo_1 <- here::here(
  "recursos", "codigo", "stan", "australia", "modelo_1.stan"
)

# Muestreamos del posterior con Stan
fit_1 <- stan( 
    file = ruta_modelo_1,
    data = stan_data_1,
    model_name = "modelo 1",
    chains = 2,
    refresh = 0,
    seed = 121195
)

# Convertimos las muestras a data.frame, conservando solo los parámetros de interés
df_draws_1 <- as.data.frame(extract(fit_1, c("beta0", "beta1", "sigma")))    
```

Graficamos la distribución _a posteriori_ marginal de los parámetros.

```{r}
#| fig-align: center
#| fig-width: 10
df_draws_long_1 <- df_draws_1 |>
  tidyr::pivot_longer(c("beta0", "beta1", "sigma"), names_to = "parametro")

ggplot(df_draws_long_1) +
  geom_histogram(
    aes(x = value, y = after_stat(density)), 
    bins = 30, 
    fill = c_orange_light, 
    color = c_orange_light
) +
  facet_wrap(~ parametro, scales = "free") +
  labs(x = "Valor", y = "Densidad") +
  theme_bw()
```

La recta de regresión está dada por un intercepto y una pendiente. 
Al contar con múltiples valores de interceptos y pendientes, es posible pensar que se 
tienen múltiples muestras de rectas de regresión. 
Para graficar algunas de estas rectas simplemente seleccionamos algunos de los pares de
`(beta0, beta1)` que se obtuvieron del _posterior_.

```{r}
#| fig-align: center
#| fig-width: 7
ggplot(df) +
  geom_point(aes(x = temp9am, y = temp3pm, color = location), alpha = 0.7, size = 2) +
  geom_abline(
    aes(intercept = beta0, slope = beta1),
    alpha = 0.3,
    color = "gray30",
    data = df_draws_1[sample(4000, 40), ]
  ) +
  scale_color_manual(values = c(c_orange_dark, c_green_blue)) +
  labs(
      x = "Temperatura a las 9 a.m. (C°)", 
      y = "Temperatura a las 3 p.m. (C°)",
      color = "Ciudad"
  ) +
  theme_bw()
```


### Modelo 2

```{stan}
#| echo: true
#| eval: false 
#| file: stan/australia/modelo_2.stan
#| output.var: modelo_02
```

Este modelo incorpora la ubicación. Una forma de implementarlo es utilizando índices que
indiquen a que ubicación pertence cada observación.

```{r}
as.factor(df$location)
as.integer(as.factor(df$location))
```

```{r}
stan_data_2 <- list(
    N = nrow(df), 
    location_idx = as.integer(as.factor(df$location)),
    temp3pm = df$temp3pm
)

ruta_modelo_2 <- here::here(
  "recursos", "codigo", "stan", "australia", "modelo_2.stan"
)

fit_2 <- stan( 
    file = ruta_modelo_2,
    data = stan_data_2,
    model_name = "modelo 2",
    chains = 2,
    refresh = 0,
    seed = 121195
)

# Extraemos las muestras del posterior y renombramos la columnas de beta0
df_draws_2 <- as.data.frame(extract(fit_2, c("beta0", "sigma")))
colnames(df_draws_2) <- c("beta0[Uluru]", "beta0[Wollongong]", "sigma")
```

El código para visualizar los _posteriors_ marginales es análogo.

```{r}
#| fig-align: center
#| fig-width: 10
df_draws_long_2 <- df_draws_2 |>
  tidyr::pivot_longer(
    c("beta0[Uluru]", "beta0[Wollongong]", "sigma"), 
    names_to = "parametro"
)

ggplot(df_draws_long_2) +
  geom_histogram(
    aes(x = value, y = after_stat(density)), 
    bins = 30, 
    fill = c_orange_light, 
    color = c_orange_light
) +
  facet_wrap(~ parametro, scales = "free") +
  labs(x = "Valor", y = "Densidad") +
  theme_bw()
```

En este segundo modelo se tienen dos interceptos, uno para cada ciudad, 
y una pendiente nula. 

```{r}
#| fig-align: center
#| fig-width: 7
data_lines <- data.frame(
    beta0 = c(df_draws_2[["beta0[Uluru]"]], df_draws_2[["beta0[Wollongong]"]]),
    location = rep(c("Uluru", "Wollongong"), each = nrow(df_draws_2))
)

ggplot(df) +
  geom_point(aes(x = temp9am, y = temp3pm, color = location), alpha = 0.7, size = 2) +
  geom_abline(
    aes(intercept = beta0, slope = 0, color = location),
    alpha = 0.3,
    data = data_lines[sample(nrow(data_lines), 80), ]
  ) +
  scale_color_manual(values = c(c_orange_dark, c_green_blue)) +
  labs(
    x = "Temperatura a las 9 a.m. (C°)", 
    y = "Temperatura a las 3 p.m. (C°)",
    color = "Ciudad"
  ) +
  theme_bw()
```

El modelo predice una temperatura única para cada ciudad a las 3 p.m., independiente de la
temperatura a las 9 a.m.

### Modelo 3

```{stan}
#| echo: true
#| eval: false 
#| file: stan/australia/modelo_3.stan
#| output.var: modelo_03
```

Este último modelo presenta un intercepto distinto para cada ciudad y una pendiente común
a ambas. Por lo tanto, es necesario pasarle a Stan el vector de índices para las ciudades
y la temperatura a las 9 a.m.

```{r}
stan_data_3 <- list(
    N = nrow(df), 
    location_idx = as.integer(as.factor(df$location)),
    temp9am = df$temp9am, 
    temp3pm = df$temp3pm
)

ruta_modelo_3 <- here::here(
  "recursos", "codigo", "stan", "australia", "modelo_3.stan"
)

fit_3 <- stan( 
    file = ruta_modelo_3,
    data = stan_data_3,
    model_name = "modelo 3",
    chains = 2,
    refresh = 0,
    seed = 121195
)

df_draws_3 <- as.data.frame(extract(fit_3, c("beta0", "beta1", "sigma")))
colnames(df_draws_3) <- c("beta0[Uluru]", "beta0[Wollongong]", "beta1", "sigma")
```

```{r}
#| fig-align: center
#| fig-width: 10
df_draws_long_3 <- df_draws_3 |>
  tidyr::pivot_longer(
    c("beta0[Uluru]", "beta0[Wollongong]", "beta1", "sigma"), 
    names_to = "parametro"
)

ggplot(df_draws_long_3) +
  geom_histogram(
    aes(x = value, y = after_stat(density)), 
    bins = 30, 
    fill = c_orange_light, 
    color = c_orange_light
) +
  facet_wrap(~ parametro, scales = "free") +
  labs(x = "Valor", y = "Densidad")
```

```{r}
#| fig-align: center
#| fig-width: 7
data_lines <- data.frame(
    beta0 = c(df_draws_3[["beta0[Uluru]"]], df_draws_3[["beta0[Wollongong]"]]),
    beta1 = rep(df_draws_3[["beta1"]], 2),
    location = rep(c("Uluru", "Wollongong"), each = nrow(df_draws_3))
)

ggplot(df) +
  geom_abline(
    aes(intercept = beta0, slope = beta1, color = location),
    alpha = 0.3,
    data = data_lines[sample(nrow(data_lines), 80), ]
  ) +
  geom_point(aes(x = temp9am, y = temp3pm, color = location), alpha = 0.7, size = 2) +
  scale_color_manual(values = c(c_orange_dark, c_green_blue)) +
  labs(
    x = "Temperatura a las 9 a.m. (C°)", 
    y = "Temperatura a las 3 p.m. (C°)",
    color = "Ciudad"
  ) +
  theme_bw()
```

De manera cuantitativa, es posible ver que este modelo es el que mejor ajusta a la nube
de puntos.

## Comparación

### _Posterior predictive checks_

La librería `{bayesplot}` nos permite realizar pruebas predictivas _a posteriori_ mediante
el uso de `ppc_dens_overlay()`. El gráfico que se obtiene permite comparar la distribución
empírica de los datos (marginal) con distribuciones estimadas a partir de valores de 
la distribución predictiva _a posteriori_. 

Para crear este gráfico es necesario haber obtenido muestras de la distribución predictiva
_a posteriori_ con Stan. En nuestro caso, las guardamos en `y_rep`.

```{r}
library(bayesplot)

# Notar que solo se muestran 200 muestras para que el gráfico quede menos cargado.
y_rep_1 <- extract(fit_1, "y_rep")$y_rep
ppc_dens_overlay(df$temp3pm, y_rep_1[sample(2000, 200), ]) +
  labs(x = "Temperatura a las 3 p.m. (C°)", y = "Densidad") + 
  theme_bw()

y_rep_2 <- extract(fit_2, "y_rep")$y_rep
ppc_dens_overlay(df$temp3pm, y_rep_2[sample(2000, 200), ]) +
  labs(x = "Temperatura a las 3 p.m. (C°)", y = "Densidad") + 
  theme_bw()

y_rep_3 <- extract(fit_3, "y_rep")$y_rep
ppc_dens_overlay(df$temp3pm, y_rep_3[sample(2000, 200), ]) +
  labs(x = "Temperatura a las 3 p.m. (C°)", y = "Densidad") + 
  theme_bw()
```

Las distribuciones generadas con los modelos 1 y 2 no replican fielmente la distribución
empírica de la variable respuesta, mientras que las distribuciones generadas con el 
modelo 3 proveen una mejor aproximación.

### LOO

En esta sección utilizamos la función `loo()` de la librería `{loo}` para estimar 
el ELPD (_Expected log pointwise predictive density for a new dataset_) mediante una
aproximación a la validación cruzada conocido como PSIS-LOO CV.

Lo único que necesitamos es el objeto que obtuvimos al muestrear del _posterior_ e indicar
el nombre de la variable donde guardamos el cómputo del log-likelihood punto a punto 
(`log_likelihood` en todos los casos).

```{r}
library(loo)

loo_1 <- loo(fit_1, pars = "log_likelihood")
loo_1

loo_2 <- loo(fit_2, pars = "log_likelihood")
loo_2

loo_3 <- loo(fit_3, pars = "log_likelihood")
loo_3
```

`loo()` devuelve un objeto con varias métricas asociadas al ELPD. 
Para entender mejor cada una de ellas, se puede echar un vistazo al 
[glosario de loo](https://mc-stan.org/loo/reference/loo-glossary.html). `elpd_loo` es
la estimación de ELPD mediante el método PSIS-LOO CV, para la cual también se tiene
una medida de la variabilidad con un error estándar.

`{loo}` también provee la función `loo_compare()` que toma objetos devueltos por `loo()` 
y los ordena de mejor a peor según este criterio. En este caso se obtiene una estimación
de la diferencia de ELPDs y un error estándar de la misma.

```{r}
loo_compare(loo_1, loo_2, loo_3)
```

Según este criterio, el mejor modelo es el modelo 3. La diferencia de ELPD entre el modelo
3 y el modelo 2 es -107.3 y el error estándar de la misma es 19,2. Si se construye un 
intervalo aproximado del 95% restando y sumando 2 desvíos estándar de la estimación
puntual, el mismo no cubre el 0 y se puede concluir que la diferencia de ELPDs 
entre el modelo 3 y el 2 es significativa.
